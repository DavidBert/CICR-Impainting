<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 12.1.0"/>
    <title>impaintingLib.model.layer.model_utils API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent }nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--code);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../layer.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;impaintingLib.model.layer</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



        <h2>API Documentation</h2>
            <ul class="memberlist">
            <li>
                    <a class="class" href="#conv2DBatchNorm">conv2DBatchNorm</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#conv2DBatchNorm.__init__">conv2DBatchNorm</a>
                        </li>
                        <li>
                                <a class="function" href="#conv2DBatchNorm.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#conv2DGroupNorm">conv2DGroupNorm</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#conv2DGroupNorm.__init__">conv2DGroupNorm</a>
                        </li>
                        <li>
                                <a class="function" href="#conv2DGroupNorm.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#deconv2DBatchNorm">deconv2DBatchNorm</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#deconv2DBatchNorm.__init__">deconv2DBatchNorm</a>
                        </li>
                        <li>
                                <a class="function" href="#deconv2DBatchNorm.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#conv2DBatchNormRelu">conv2DBatchNormRelu</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#conv2DBatchNormRelu.__init__">conv2DBatchNormRelu</a>
                        </li>
                        <li>
                                <a class="function" href="#conv2DBatchNormRelu.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#conv2DGroupNormRelu">conv2DGroupNormRelu</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#conv2DGroupNormRelu.__init__">conv2DGroupNormRelu</a>
                        </li>
                        <li>
                                <a class="function" href="#conv2DGroupNormRelu.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#deconv2DBatchNormRelu">deconv2DBatchNormRelu</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#deconv2DBatchNormRelu.__init__">deconv2DBatchNormRelu</a>
                        </li>
                        <li>
                                <a class="function" href="#deconv2DBatchNormRelu.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#unetConv2">unetConv2</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#unetConv2.__init__">unetConv2</a>
                        </li>
                        <li>
                                <a class="function" href="#unetConv2.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#unetUp">unetUp</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#unetUp.__init__">unetUp</a>
                        </li>
                        <li>
                                <a class="function" href="#unetUp.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#segnetDown2">segnetDown2</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#segnetDown2.__init__">segnetDown2</a>
                        </li>
                        <li>
                                <a class="function" href="#segnetDown2.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#segnetDown3">segnetDown3</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#segnetDown3.__init__">segnetDown3</a>
                        </li>
                        <li>
                                <a class="function" href="#segnetDown3.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#segnetUp2">segnetUp2</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#segnetUp2.__init__">segnetUp2</a>
                        </li>
                        <li>
                                <a class="function" href="#segnetUp2.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#segnetUp3">segnetUp3</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#segnetUp3.__init__">segnetUp3</a>
                        </li>
                        <li>
                                <a class="function" href="#segnetUp3.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#residualBlock">residualBlock</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#residualBlock.__init__">residualBlock</a>
                        </li>
                        <li>
                                <a class="variable" href="#residualBlock.expansion">expansion</a>
                        </li>
                        <li>
                                <a class="function" href="#residualBlock.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#residualBottleneck">residualBottleneck</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#residualBottleneck.__init__">residualBottleneck</a>
                        </li>
                        <li>
                                <a class="variable" href="#residualBottleneck.expansion">expansion</a>
                        </li>
                        <li>
                                <a class="function" href="#residualBottleneck.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#linknetUp">linknetUp</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#linknetUp.__init__">linknetUp</a>
                        </li>
                        <li>
                                <a class="function" href="#linknetUp.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#FRRU">FRRU</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#FRRU.__init__">FRRU</a>
                        </li>
                        <li>
                                <a class="function" href="#FRRU.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#RU">RU</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#RU.__init__">RU</a>
                        </li>
                        <li>
                                <a class="function" href="#RU.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#residualConvUnit">residualConvUnit</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#residualConvUnit.__init__">residualConvUnit</a>
                        </li>
                        <li>
                                <a class="function" href="#residualConvUnit.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#multiResolutionFusion">multiResolutionFusion</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#multiResolutionFusion.__init__">multiResolutionFusion</a>
                        </li>
                        <li>
                                <a class="function" href="#multiResolutionFusion.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#chainedResidualPooling">chainedResidualPooling</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#chainedResidualPooling.__init__">chainedResidualPooling</a>
                        </li>
                        <li>
                                <a class="function" href="#chainedResidualPooling.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#pyramidPooling">pyramidPooling</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#pyramidPooling.__init__">pyramidPooling</a>
                        </li>
                        <li>
                                <a class="function" href="#pyramidPooling.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#bottleNeckPSP">bottleNeckPSP</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#bottleNeckPSP.__init__">bottleNeckPSP</a>
                        </li>
                        <li>
                                <a class="function" href="#bottleNeckPSP.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#bottleNeckIdentifyPSP">bottleNeckIdentifyPSP</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#bottleNeckIdentifyPSP.__init__">bottleNeckIdentifyPSP</a>
                        </li>
                        <li>
                                <a class="function" href="#bottleNeckIdentifyPSP.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#residualBlockPSP">residualBlockPSP</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#residualBlockPSP.__init__">residualBlockPSP</a>
                        </li>
                        <li>
                                <a class="function" href="#residualBlockPSP.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#cascadeFeatureFusion">cascadeFeatureFusion</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#cascadeFeatureFusion.__init__">cascadeFeatureFusion</a>
                        </li>
                        <li>
                                <a class="function" href="#cascadeFeatureFusion.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="function" href="#get_interp_size">get_interp_size</a>
            </li>
            <li>
                    <a class="function" href="#interp">interp</a>
            </li>
            <li>
                    <a class="function" href="#get_upsampling_weight">get_upsampling_weight</a>
            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../../../impaintingLib.html">impaintingLib</a><wbr>.<a href="./../../model.html">model</a><wbr>.<a href="./../layer.html">layer</a><wbr>.model_utils    </h1>

                
                        <input id="model_utils-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="model_utils-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a><span class="k">class</span> <span class="nc">conv2DBatchNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a>    <span class="p">):</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DBatchNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a>        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cb_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)))</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cb_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">)</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a><span class="k">class</span> <span class="nc">conv2DGroupNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a>        <span class="n">n_groups</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a>    <span class="p">):</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DGroupNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cg_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> 
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a>                                     <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">n_groups</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)))</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cg_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a><span class="k">class</span> <span class="nc">deconv2DBatchNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">deconv2DBatchNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dcb_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a>                <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a>            <span class="p">),</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a>        <span class="p">)</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dcb_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a><span class="k">class</span> <span class="nc">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a>    <span class="p">):</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DBatchNormRelu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a>
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a>        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> 
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a>                                          <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span> 
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a>                                          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cbr_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a><span class="k">class</span> <span class="nc">conv2DGroupNormRelu</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a>        <span class="n">n_groups</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a>    <span class="p">):</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DGroupNormRelu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cgr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> 
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a>                                      <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">n_groups</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span> 
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a>                                      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cgr_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a><span class="k">class</span> <span class="nc">deconv2DBatchNormRelu</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">deconv2DBatchNormRelu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dcbr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a>                <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a>            <span class="p">),</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a>        <span class="p">)</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dcbr_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a><span class="k">class</span> <span class="nc">unetConv2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="p">):</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">unetConv2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a>
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a>        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">),</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a>            <span class="p">)</span>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">),</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a>            <span class="p">)</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a>            <span class="p">)</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a>        <span class="c1">#print (outputs.shape)</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a>        <span class="c1">#print (outputs.shape)</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a><span class="k">class</span> <span class="nc">unetUp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">is_deconv</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="p">):</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">unetUp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">unetConv2</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="p">)</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a>        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UpsamplingBilinear2d</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs1</span><span class="p">,</span> <span class="n">inputs2</span><span class="p">):</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a>        <span class="n">outputs2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up</span><span class="p">(</span><span class="n">inputs2</span><span class="p">)</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a>        <span class="n">offset</span> <span class="o">=</span> <span class="n">outputs2</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">inputs1</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a>        <span class="n">padding</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">[</span><span class="n">offset</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">offset</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>           
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a>        <span class="n">outputs1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos">220</span></a>               
</span><span id="L-221"><a href="#L-221"><span class="linenos">221</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">outputs1</span><span class="p">,</span> <span class="n">outputs2</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos">222</span></a>
</span><span id="L-223"><a href="#L-223"><span class="linenos">223</span></a>
</span><span id="L-224"><a href="#L-224"><span class="linenos">224</span></a><span class="k">class</span> <span class="nc">segnetDown2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos">225</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos">226</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetDown2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos">227</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos">228</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos">229</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos">230</span></a>
</span><span id="L-231"><a href="#L-231"><span class="linenos">231</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos">232</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos">233</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos">234</span></a>        <span class="n">unpooled_shape</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos">235</span></a>        <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos">236</span></a>        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">unpooled_shape</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos">237</span></a>
</span><span id="L-238"><a href="#L-238"><span class="linenos">238</span></a>
</span><span id="L-239"><a href="#L-239"><span class="linenos">239</span></a><span class="k">class</span> <span class="nc">segnetDown3</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos">240</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos">241</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetDown3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos">242</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos">243</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos">244</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos">245</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-246"><a href="#L-246"><span class="linenos">246</span></a>
</span><span id="L-247"><a href="#L-247"><span class="linenos">247</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos">248</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos">249</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos">250</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos">251</span></a>        <span class="n">unpooled_shape</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos">252</span></a>        <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos">253</span></a>        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">unpooled_shape</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos">254</span></a>
</span><span id="L-255"><a href="#L-255"><span class="linenos">255</span></a>
</span><span id="L-256"><a href="#L-256"><span class="linenos">256</span></a><span class="k">class</span> <span class="nc">segnetUp2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos">257</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos">258</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetUp2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos">259</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxUnpool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos">260</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-261"><a href="#L-261"><span class="linenos">261</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos">262</span></a>
</span><span id="L-263"><a href="#L-263"><span class="linenos">263</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">):</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos">264</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos">265</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos">266</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos">267</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos">268</span></a>
</span><span id="L-269"><a href="#L-269"><span class="linenos">269</span></a>
</span><span id="L-270"><a href="#L-270"><span class="linenos">270</span></a><span class="k">class</span> <span class="nc">segnetUp3</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-271"><a href="#L-271"><span class="linenos">271</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos">272</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetUp3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos">273</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxUnpool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos">274</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos">275</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos">276</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos">277</span></a>
</span><span id="L-278"><a href="#L-278"><span class="linenos">278</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">):</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos">279</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos">280</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos">281</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos">282</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="L-283"><a href="#L-283"><span class="linenos">283</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span><span id="L-284"><a href="#L-284"><span class="linenos">284</span></a>
</span><span id="L-285"><a href="#L-285"><span class="linenos">285</span></a>
</span><span id="L-286"><a href="#L-286"><span class="linenos">286</span></a><span class="k">class</span> <span class="nc">residualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-287"><a href="#L-287"><span class="linenos">287</span></a>    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos">288</span></a>
</span><span id="L-289"><a href="#L-289"><span class="linenos">289</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos">290</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos">291</span></a>
</span><span id="L-292"><a href="#L-292"><span class="linenos">292</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos">293</span></a>            <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos">294</span></a>        <span class="p">)</span>
</span><span id="L-295"><a href="#L-295"><span class="linenos">295</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span><span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos">296</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos">297</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos">298</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos">299</span></a>
</span><span id="L-300"><a href="#L-300"><span class="linenos">300</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos">301</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos">302</span></a>
</span><span id="L-303"><a href="#L-303"><span class="linenos">303</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-304"><a href="#L-304"><span class="linenos">304</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos">305</span></a>
</span><span id="L-306"><a href="#L-306"><span class="linenos">306</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos">307</span></a>            <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-308"><a href="#L-308"><span class="linenos">308</span></a>
</span><span id="L-309"><a href="#L-309"><span class="linenos">309</span></a>        <span class="n">out</span> <span class="o">+=</span> <span class="n">residual</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos">310</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos">311</span></a>        <span class="k">return</span> <span class="n">out</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos">312</span></a>
</span><span id="L-313"><a href="#L-313"><span class="linenos">313</span></a>
</span><span id="L-314"><a href="#L-314"><span class="linenos">314</span></a><span class="k">class</span> <span class="nc">residualBottleneck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos">315</span></a>    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos">316</span></a>
</span><span id="L-317"><a href="#L-317"><span class="linenos">317</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos">318</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualBottleneck</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos">319</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2DBatchNorm</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-320"><a href="#L-320"><span class="linenos">320</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2DBatchNorm</span><span class="p">(</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos">321</span></a>            <span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos">322</span></a>        <span class="p">)</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos">323</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2DBatchNorm</span><span class="p">(</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos">324</span></a>            <span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos">325</span></a>        <span class="p">)</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos">326</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos">327</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos">328</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
</span><span id="L-329"><a href="#L-329"><span class="linenos">329</span></a>
</span><span id="L-330"><a href="#L-330"><span class="linenos">330</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-331"><a href="#L-331"><span class="linenos">331</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos">332</span></a>
</span><span id="L-333"><a href="#L-333"><span class="linenos">333</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos">334</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="L-335"><a href="#L-335"><span class="linenos">335</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="L-336"><a href="#L-336"><span class="linenos">336</span></a>
</span><span id="L-337"><a href="#L-337"><span class="linenos">337</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos">338</span></a>            <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos">339</span></a>
</span><span id="L-340"><a href="#L-340"><span class="linenos">340</span></a>        <span class="n">out</span> <span class="o">+=</span> <span class="n">residual</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos">341</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="L-342"><a href="#L-342"><span class="linenos">342</span></a>
</span><span id="L-343"><a href="#L-343"><span class="linenos">343</span></a>        <span class="k">return</span> <span class="n">out</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos">344</span></a>
</span><span id="L-345"><a href="#L-345"><span class="linenos">345</span></a>
</span><span id="L-346"><a href="#L-346"><span class="linenos">346</span></a><span class="k">class</span> <span class="nc">linknetUp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos">347</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">):</span>
</span><span id="L-348"><a href="#L-348"><span class="linenos">348</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">linknetUp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos">349</span></a>
</span><span id="L-350"><a href="#L-350"><span class="linenos">350</span></a>        <span class="c1"># B, 2C, H, W -&gt; B, C/2, H, W</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos">351</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-352"><a href="#L-352"><span class="linenos">352</span></a>            <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos">353</span></a>        <span class="p">)</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos">354</span></a>
</span><span id="L-355"><a href="#L-355"><span class="linenos">355</span></a>        <span class="c1"># B, C/2, H, W -&gt; B, C/2, H, W</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos">356</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">deconvbnrelu2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">deconv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-357"><a href="#L-357"><span class="linenos">357</span></a>            <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos">358</span></a>        <span class="p">)</span>
</span><span id="L-359"><a href="#L-359"><span class="linenos">359</span></a>
</span><span id="L-360"><a href="#L-360"><span class="linenos">360</span></a>        <span class="c1"># B, C/2, H, W -&gt; B, C, H, W</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos">361</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu3</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-362"><a href="#L-362"><span class="linenos">362</span></a>            <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
</span><span id="L-363"><a href="#L-363"><span class="linenos">363</span></a>        <span class="p">)</span>
</span><span id="L-364"><a href="#L-364"><span class="linenos">364</span></a>
</span><span id="L-365"><a href="#L-365"><span class="linenos">365</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos">366</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos">367</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconvbnrelu2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos">368</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-369"><a href="#L-369"><span class="linenos">369</span></a>        <span class="k">return</span> <span class="n">x</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos">370</span></a>
</span><span id="L-371"><a href="#L-371"><span class="linenos">371</span></a>
</span><span id="L-372"><a href="#L-372"><span class="linenos">372</span></a><span class="k">class</span> <span class="nc">FRRU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos">373</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos">374</span></a><span class="sd">    Full Resolution Residual Unit for FRRN</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos">375</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-376"><a href="#L-376"><span class="linenos">376</span></a>
</span><span id="L-377"><a href="#L-377"><span class="linenos">377</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
</span><span id="L-378"><a href="#L-378"><span class="linenos">378</span></a>                 <span class="n">prev_channels</span><span class="p">,</span> 
</span><span id="L-379"><a href="#L-379"><span class="linenos">379</span></a>                 <span class="n">out_channels</span><span class="p">,</span> 
</span><span id="L-380"><a href="#L-380"><span class="linenos">380</span></a>                 <span class="n">scale</span><span class="p">,</span> 
</span><span id="L-381"><a href="#L-381"><span class="linenos">381</span></a>                 <span class="n">group_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos">382</span></a>                 <span class="n">n_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-383"><a href="#L-383"><span class="linenos">383</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">FRRU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos">384</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos">385</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prev_channels</span> <span class="o">=</span> <span class="n">prev_channels</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos">386</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
</span><span id="L-387"><a href="#L-387"><span class="linenos">387</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span> <span class="o">=</span> <span class="n">group_norm</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos">388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">=</span> <span class="n">n_groups</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos">389</span></a>
</span><span id="L-390"><a href="#L-390"><span class="linenos">390</span></a>
</span><span id="L-391"><a href="#L-391"><span class="linenos">391</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span>
</span><span id="L-392"><a href="#L-392"><span class="linenos">392</span></a>            <span class="n">conv_unit</span> <span class="o">=</span> <span class="n">conv2DGroupNormRelu</span>
</span><span id="L-393"><a href="#L-393"><span class="linenos">393</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span>
</span><span id="L-394"><a href="#L-394"><span class="linenos">394</span></a>                <span class="n">prev_channels</span> <span class="o">+</span> <span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="L-395"><a href="#L-395"><span class="linenos">395</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos">396</span></a>            <span class="p">)</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos">397</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span>
</span><span id="L-398"><a href="#L-398"><span class="linenos">398</span></a>                <span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="L-399"><a href="#L-399"><span class="linenos">399</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span>
</span><span id="L-400"><a href="#L-400"><span class="linenos">400</span></a>            <span class="p">)</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos">401</span></a>
</span><span id="L-402"><a href="#L-402"><span class="linenos">402</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-403"><a href="#L-403"><span class="linenos">403</span></a>            <span class="n">conv_unit</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos">404</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span><span class="n">prev_channels</span> <span class="o">+</span> <span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="L-405"><a href="#L-405"><span class="linenos">405</span></a>                                   <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos">406</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="L-407"><a href="#L-407"><span class="linenos">407</span></a>                                   <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos">408</span></a>
</span><span id="L-409"><a href="#L-409"><span class="linenos">409</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv_res</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos">410</span></a>
</span><span id="L-411"><a href="#L-411"><span class="linenos">411</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos">412</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)(</span><span class="n">z</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos">413</span></a>        <span class="n">y_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos">414</span></a>        <span class="n">y_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">y_prime</span><span class="p">)</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos">415</span></a>
</span><span id="L-416"><a href="#L-416"><span class="linenos">416</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_res</span><span class="p">(</span><span class="n">y_prime</span><span class="p">)</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos">417</span></a>        <span class="n">upsample_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">_s</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="k">for</span> <span class="n">_s</span> <span class="ow">in</span> <span class="n">y_prime</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos">418</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">upsample_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">)</span>
</span><span id="L-419"><a href="#L-419"><span class="linenos">419</span></a>        <span class="n">z_prime</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="n">x</span>
</span><span id="L-420"><a href="#L-420"><span class="linenos">420</span></a>
</span><span id="L-421"><a href="#L-421"><span class="linenos">421</span></a>        <span class="k">return</span> <span class="n">y_prime</span><span class="p">,</span> <span class="n">z_prime</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos">422</span></a>
</span><span id="L-423"><a href="#L-423"><span class="linenos">423</span></a>
</span><span id="L-424"><a href="#L-424"><span class="linenos">424</span></a><span class="k">class</span> <span class="nc">RU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-425"><a href="#L-425"><span class="linenos">425</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos">426</span></a><span class="sd">    Residual Unit for FRRN</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos">427</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos">428</span></a>
</span><span id="L-429"><a href="#L-429"><span class="linenos">429</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
</span><span id="L-430"><a href="#L-430"><span class="linenos">430</span></a>                 <span class="n">channels</span><span class="p">,</span> 
</span><span id="L-431"><a href="#L-431"><span class="linenos">431</span></a>                 <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="L-432"><a href="#L-432"><span class="linenos">432</span></a>                 <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
</span><span id="L-433"><a href="#L-433"><span class="linenos">433</span></a>                 <span class="n">group_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-434"><a href="#L-434"><span class="linenos">434</span></a>                 <span class="n">n_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-435"><a href="#L-435"><span class="linenos">435</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">RU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos">436</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span> <span class="o">=</span> <span class="n">group_norm</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos">437</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">=</span> <span class="n">n_groups</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos">438</span></a>
</span><span id="L-439"><a href="#L-439"><span class="linenos">439</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos">440</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DGroupNormRelu</span><span class="p">(</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos">441</span></a>               <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
</span><span id="L-442"><a href="#L-442"><span class="linenos">442</span></a>               <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">)</span>
</span><span id="L-443"><a href="#L-443"><span class="linenos">443</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DGroupNorm</span><span class="p">(</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos">444</span></a>                <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
</span><span id="L-445"><a href="#L-445"><span class="linenos">445</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">)</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos">446</span></a>
</span><span id="L-447"><a href="#L-447"><span class="linenos">447</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos">448</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos">449</span></a>               <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="L-450"><a href="#L-450"><span class="linenos">450</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos">451</span></a>                <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos">452</span></a>
</span><span id="L-453"><a href="#L-453"><span class="linenos">453</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos">454</span></a>        <span class="n">incoming</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos">455</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos">456</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-457"><a href="#L-457"><span class="linenos">457</span></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">incoming</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos">458</span></a>
</span><span id="L-459"><a href="#L-459"><span class="linenos">459</span></a>
</span><span id="L-460"><a href="#L-460"><span class="linenos">460</span></a><span class="k">class</span> <span class="nc">residualConvUnit</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-461"><a href="#L-461"><span class="linenos">461</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos">462</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualConvUnit</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-463"><a href="#L-463"><span class="linenos">463</span></a>
</span><span id="L-464"><a href="#L-464"><span class="linenos">464</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">residual_conv_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="L-465"><a href="#L-465"><span class="linenos">465</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos">466</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos">467</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos">468</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="L-469"><a href="#L-469"><span class="linenos">469</span></a>        <span class="p">)</span>
</span><span id="L-470"><a href="#L-470"><span class="linenos">470</span></a>
</span><span id="L-471"><a href="#L-471"><span class="linenos">471</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos">472</span></a>        <span class="nb">input</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="L-473"><a href="#L-473"><span class="linenos">473</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_conv_unit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-474"><a href="#L-474"><span class="linenos">474</span></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="nb">input</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos">475</span></a>
</span><span id="L-476"><a href="#L-476"><span class="linenos">476</span></a>
</span><span id="L-477"><a href="#L-477"><span class="linenos">477</span></a><span class="k">class</span> <span class="nc">multiResolutionFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-478"><a href="#L-478"><span class="linenos">478</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">up_scale_high</span><span class="p">,</span> <span class="n">up_scale_low</span><span class="p">,</span> <span class="n">high_shape</span><span class="p">,</span> <span class="n">low_shape</span><span class="p">):</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos">479</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">multiResolutionFusion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-480"><a href="#L-480"><span class="linenos">480</span></a>
</span><span id="L-481"><a href="#L-481"><span class="linenos">481</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">up_scale_high</span> <span class="o">=</span> <span class="n">up_scale_high</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos">482</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">up_scale_low</span> <span class="o">=</span> <span class="n">up_scale_low</span>
</span><span id="L-483"><a href="#L-483"><span class="linenos">483</span></a>
</span><span id="L-484"><a href="#L-484"><span class="linenos">484</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv_high</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">high_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span id="L-485"><a href="#L-485"><span class="linenos">485</span></a>
</span><span id="L-486"><a href="#L-486"><span class="linenos">486</span></a>        <span class="k">if</span> <span class="n">low_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos">487</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv_low</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">low_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span id="L-488"><a href="#L-488"><span class="linenos">488</span></a>
</span><span id="L-489"><a href="#L-489"><span class="linenos">489</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_high</span><span class="p">,</span> <span class="n">x_low</span><span class="p">):</span>
</span><span id="L-490"><a href="#L-490"><span class="linenos">490</span></a>        <span class="n">high_upsampled</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span>
</span><span id="L-491"><a href="#L-491"><span class="linenos">491</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv_high</span><span class="p">(</span><span class="n">x_high</span><span class="p">),</span> <span class="n">scale_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">up_scale_high</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span>
</span><span id="L-492"><a href="#L-492"><span class="linenos">492</span></a>        <span class="p">)</span>
</span><span id="L-493"><a href="#L-493"><span class="linenos">493</span></a>
</span><span id="L-494"><a href="#L-494"><span class="linenos">494</span></a>        <span class="k">if</span> <span class="n">x_low</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-495"><a href="#L-495"><span class="linenos">495</span></a>            <span class="k">return</span> <span class="n">high_upsampled</span>
</span><span id="L-496"><a href="#L-496"><span class="linenos">496</span></a>
</span><span id="L-497"><a href="#L-497"><span class="linenos">497</span></a>        <span class="n">low_upsampled</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos">498</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv_low</span><span class="p">(</span><span class="n">x_low</span><span class="p">),</span> <span class="n">scale_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">up_scale_low</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span>
</span><span id="L-499"><a href="#L-499"><span class="linenos">499</span></a>        <span class="p">)</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos">500</span></a>
</span><span id="L-501"><a href="#L-501"><span class="linenos">501</span></a>        <span class="k">return</span> <span class="n">low_upsampled</span> <span class="o">+</span> <span class="n">high_upsampled</span>
</span><span id="L-502"><a href="#L-502"><span class="linenos">502</span></a>
</span><span id="L-503"><a href="#L-503"><span class="linenos">503</span></a>
</span><span id="L-504"><a href="#L-504"><span class="linenos">504</span></a><span class="k">class</span> <span class="nc">chainedResidualPooling</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-505"><a href="#L-505"><span class="linenos">505</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos">506</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">chainedResidualPooling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-507"><a href="#L-507"><span class="linenos">507</span></a>
</span><span id="L-508"><a href="#L-508"><span class="linenos">508</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">chained_residual_pooling</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="L-509"><a href="#L-509"><span class="linenos">509</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos">510</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos">511</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos">512</span></a>        <span class="p">)</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos">513</span></a>
</span><span id="L-514"><a href="#L-514"><span class="linenos">514</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos">515</span></a>        <span class="nb">input</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="L-516"><a href="#L-516"><span class="linenos">516</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chained_residual_pooling</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-517"><a href="#L-517"><span class="linenos">517</span></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="nb">input</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos">518</span></a>
</span><span id="L-519"><a href="#L-519"><span class="linenos">519</span></a>
</span><span id="L-520"><a href="#L-520"><span class="linenos">520</span></a><span class="k">class</span> <span class="nc">pyramidPooling</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos">521</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos">522</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos">523</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos">524</span></a>        <span class="n">pool_sizes</span><span class="p">,</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos">525</span></a>        <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;pspnet&quot;</span><span class="p">,</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos">526</span></a>        <span class="n">fusion_mode</span><span class="o">=</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos">527</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos">528</span></a>    <span class="p">):</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos">529</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">pyramidPooling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos">530</span></a>
</span><span id="L-531"><a href="#L-531"><span class="linenos">531</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos">532</span></a>
</span><span id="L-533"><a href="#L-533"><span class="linenos">533</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">paths</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-534"><a href="#L-534"><span class="linenos">534</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pool_sizes</span><span class="p">)):</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos">535</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="L-536"><a href="#L-536"><span class="linenos">536</span></a>                <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos">537</span></a>                    <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos">538</span></a>                    <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">pool_sizes</span><span class="p">)),</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos">539</span></a>                    <span class="mi">1</span><span class="p">,</span>
</span><span id="L-540"><a href="#L-540"><span class="linenos">540</span></a>                    <span class="mi">1</span><span class="p">,</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos">541</span></a>                    <span class="mi">0</span><span class="p">,</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos">542</span></a>                    <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-543"><a href="#L-543"><span class="linenos">543</span></a>                    <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos">544</span></a>                <span class="p">)</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos">545</span></a>            <span class="p">)</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos">546</span></a>
</span><span id="L-547"><a href="#L-547"><span class="linenos">547</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">path_module_list</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">paths</span><span class="p">)</span>
</span><span id="L-548"><a href="#L-548"><span class="linenos">548</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span> <span class="o">=</span> <span class="n">pool_sizes</span>
</span><span id="L-549"><a href="#L-549"><span class="linenos">549</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos">550</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_mode</span> <span class="o">=</span> <span class="n">fusion_mode</span>
</span><span id="L-551"><a href="#L-551"><span class="linenos">551</span></a>
</span><span id="L-552"><a href="#L-552"><span class="linenos">552</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-553"><a href="#L-553"><span class="linenos">553</span></a>        <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos">554</span></a>
</span><span id="L-555"><a href="#L-555"><span class="linenos">555</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">!=</span> <span class="s2">&quot;icnet&quot;</span><span class="p">:</span>  <span class="c1"># general settings or pspnet</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos">556</span></a>            <span class="n">k_sizes</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos">557</span></a>            <span class="n">strides</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos">558</span></a>            <span class="k">for</span> <span class="n">pool_size</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span><span class="p">:</span>
</span><span id="L-559"><a href="#L-559"><span class="linenos">559</span></a>                <span class="n">k_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">h</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">)))</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos">560</span></a>                <span class="n">strides</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">h</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">)))</span>
</span><span id="L-561"><a href="#L-561"><span class="linenos">561</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># eval mode and icnet: pre-trained for 1025 x 2049</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos">562</span></a>            <span class="n">k_sizes</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">33</span><span class="p">),</span> <span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">65</span><span class="p">)]</span>
</span><span id="L-563"><a href="#L-563"><span class="linenos">563</span></a>            <span class="n">strides</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">65</span><span class="p">)]</span>
</span><span id="L-564"><a href="#L-564"><span class="linenos">564</span></a>
</span><span id="L-565"><a href="#L-565"><span class="linenos">565</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_mode</span> <span class="o">==</span> <span class="s2">&quot;cat&quot;</span><span class="p">:</span>  <span class="c1"># pspnet: concat (including x)</span>
</span><span id="L-566"><a href="#L-566"><span class="linenos">566</span></a>            <span class="n">output_slices</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos">567</span></a>
</span><span id="L-568"><a href="#L-568"><span class="linenos">568</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos">569</span></a>                <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path_module_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span><span class="p">)</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos">570</span></a>            <span class="p">):</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos">571</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="L-572"><a href="#L-572"><span class="linenos">572</span></a>                <span class="c1"># out = F.adaptive_avg_pool2d(x, output_size=(pool_size, pool_size))</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos">573</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">!=</span> <span class="s2">&quot;icnet&quot;</span><span class="p">:</span>
</span><span id="L-574"><a href="#L-574"><span class="linenos">574</span></a>                    <span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="L-575"><a href="#L-575"><span class="linenos">575</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-576"><a href="#L-576"><span class="linenos">576</span></a>                <span class="n">output_slices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="L-577"><a href="#L-577"><span class="linenos">577</span></a>
</span><span id="L-578"><a href="#L-578"><span class="linenos">578</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">output_slices</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos">579</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># icnet: element-wise sum (including x)</span>
</span><span id="L-580"><a href="#L-580"><span class="linenos">580</span></a>            <span class="n">pp_sum</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos">581</span></a>
</span><span id="L-582"><a href="#L-582"><span class="linenos">582</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
</span><span id="L-583"><a href="#L-583"><span class="linenos">583</span></a>                <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path_module_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span><span class="p">)</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos">584</span></a>            <span class="p">):</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos">585</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="L-586"><a href="#L-586"><span class="linenos">586</span></a>                <span class="c1"># out = F.adaptive_avg_pool2d(x, output_size=(pool_size, pool_size))</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos">587</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">!=</span> <span class="s2">&quot;icnet&quot;</span><span class="p">:</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos">588</span></a>                    <span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="L-589"><a href="#L-589"><span class="linenos">589</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-590"><a href="#L-590"><span class="linenos">590</span></a>                <span class="n">pp_sum</span> <span class="o">=</span> <span class="n">pp_sum</span> <span class="o">+</span> <span class="n">out</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos">591</span></a>
</span><span id="L-592"><a href="#L-592"><span class="linenos">592</span></a>            <span class="k">return</span> <span class="n">pp_sum</span>
</span><span id="L-593"><a href="#L-593"><span class="linenos">593</span></a>
</span><span id="L-594"><a href="#L-594"><span class="linenos">594</span></a>
</span><span id="L-595"><a href="#L-595"><span class="linenos">595</span></a><span class="k">class</span> <span class="nc">bottleNeckPSP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos">596</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-597"><a href="#L-597"><span class="linenos">597</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span>
</span><span id="L-598"><a href="#L-598"><span class="linenos">598</span></a>    <span class="p">):</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos">599</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">bottleNeckPSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-600"><a href="#L-600"><span class="linenos">600</span></a>
</span><span id="L-601"><a href="#L-601"><span class="linenos">601</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos">602</span></a>
</span><span id="L-603"><a href="#L-603"><span class="linenos">603</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-604"><a href="#L-604"><span class="linenos">604</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-605"><a href="#L-605"><span class="linenos">605</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos">606</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="L-607"><a href="#L-607"><span class="linenos">607</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos">608</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos">609</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-610"><a href="#L-610"><span class="linenos">610</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-611"><a href="#L-611"><span class="linenos">611</span></a>        <span class="p">)</span>
</span><span id="L-612"><a href="#L-612"><span class="linenos">612</span></a>        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos">613</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos">614</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos">615</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-616"><a href="#L-616"><span class="linenos">616</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos">617</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="L-618"><a href="#L-618"><span class="linenos">618</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="L-619"><a href="#L-619"><span class="linenos">619</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos">620</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos">621</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-622"><a href="#L-622"><span class="linenos">622</span></a>            <span class="p">)</span>
</span><span id="L-623"><a href="#L-623"><span class="linenos">623</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-624"><a href="#L-624"><span class="linenos">624</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-625"><a href="#L-625"><span class="linenos">625</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos">626</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos">627</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="L-628"><a href="#L-628"><span class="linenos">628</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos">629</span></a>                <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-630"><a href="#L-630"><span class="linenos">630</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-631"><a href="#L-631"><span class="linenos">631</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos">632</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-633"><a href="#L-633"><span class="linenos">633</span></a>            <span class="p">)</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos">634</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos">635</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-636"><a href="#L-636"><span class="linenos">636</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="L-637"><a href="#L-637"><span class="linenos">637</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos">638</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-639"><a href="#L-639"><span class="linenos">639</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-640"><a href="#L-640"><span class="linenos">640</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-641"><a href="#L-641"><span class="linenos">641</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos">642</span></a>        <span class="p">)</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos">643</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cb4</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="L-644"><a href="#L-644"><span class="linenos">644</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos">645</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos">646</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="L-647"><a href="#L-647"><span class="linenos">647</span></a>            <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos">648</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-649"><a href="#L-649"><span class="linenos">649</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-650"><a href="#L-650"><span class="linenos">650</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-651"><a href="#L-651"><span class="linenos">651</span></a>        <span class="p">)</span>
</span><span id="L-652"><a href="#L-652"><span class="linenos">652</span></a>
</span><span id="L-653"><a href="#L-653"><span class="linenos">653</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-654"><a href="#L-654"><span class="linenos">654</span></a>        <span class="n">conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="L-655"><a href="#L-655"><span class="linenos">655</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-656"><a href="#L-656"><span class="linenos">656</span></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv</span> <span class="o">+</span> <span class="n">residual</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-657"><a href="#L-657"><span class="linenos">657</span></a>
</span><span id="L-658"><a href="#L-658"><span class="linenos">658</span></a>
</span><span id="L-659"><a href="#L-659"><span class="linenos">659</span></a><span class="k">class</span> <span class="nc">bottleNeckIdentifyPSP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-660"><a href="#L-660"><span class="linenos">660</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="L-661"><a href="#L-661"><span class="linenos">661</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">bottleNeckIdentifyPSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-662"><a href="#L-662"><span class="linenos">662</span></a>
</span><span id="L-663"><a href="#L-663"><span class="linenos">663</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="L-664"><a href="#L-664"><span class="linenos">664</span></a>
</span><span id="L-665"><a href="#L-665"><span class="linenos">665</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-666"><a href="#L-666"><span class="linenos">666</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-667"><a href="#L-667"><span class="linenos">667</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-668"><a href="#L-668"><span class="linenos">668</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="L-669"><a href="#L-669"><span class="linenos">669</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-670"><a href="#L-670"><span class="linenos">670</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-671"><a href="#L-671"><span class="linenos">671</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-672"><a href="#L-672"><span class="linenos">672</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-673"><a href="#L-673"><span class="linenos">673</span></a>        <span class="p">)</span>
</span><span id="L-674"><a href="#L-674"><span class="linenos">674</span></a>        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-675"><a href="#L-675"><span class="linenos">675</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-676"><a href="#L-676"><span class="linenos">676</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-677"><a href="#L-677"><span class="linenos">677</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-678"><a href="#L-678"><span class="linenos">678</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="L-679"><a href="#L-679"><span class="linenos">679</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-680"><a href="#L-680"><span class="linenos">680</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="L-681"><a href="#L-681"><span class="linenos">681</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-682"><a href="#L-682"><span class="linenos">682</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="L-683"><a href="#L-683"><span class="linenos">683</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-684"><a href="#L-684"><span class="linenos">684</span></a>            <span class="p">)</span>
</span><span id="L-685"><a href="#L-685"><span class="linenos">685</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-686"><a href="#L-686"><span class="linenos">686</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="L-687"><a href="#L-687"><span class="linenos">687</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-688"><a href="#L-688"><span class="linenos">688</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-689"><a href="#L-689"><span class="linenos">689</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="L-690"><a href="#L-690"><span class="linenos">690</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-691"><a href="#L-691"><span class="linenos">691</span></a>                <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-692"><a href="#L-692"><span class="linenos">692</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-693"><a href="#L-693"><span class="linenos">693</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-694"><a href="#L-694"><span class="linenos">694</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-695"><a href="#L-695"><span class="linenos">695</span></a>            <span class="p">)</span>
</span><span id="L-696"><a href="#L-696"><span class="linenos">696</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="L-697"><a href="#L-697"><span class="linenos">697</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-698"><a href="#L-698"><span class="linenos">698</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-699"><a href="#L-699"><span class="linenos">699</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="L-700"><a href="#L-700"><span class="linenos">700</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-701"><a href="#L-701"><span class="linenos">701</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-702"><a href="#L-702"><span class="linenos">702</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-703"><a href="#L-703"><span class="linenos">703</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-704"><a href="#L-704"><span class="linenos">704</span></a>        <span class="p">)</span>
</span><span id="L-705"><a href="#L-705"><span class="linenos">705</span></a>
</span><span id="L-706"><a href="#L-706"><span class="linenos">706</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-707"><a href="#L-707"><span class="linenos">707</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="L-708"><a href="#L-708"><span class="linenos">708</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="L-709"><a href="#L-709"><span class="linenos">709</span></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">residual</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-710"><a href="#L-710"><span class="linenos">710</span></a>
</span><span id="L-711"><a href="#L-711"><span class="linenos">711</span></a>
</span><span id="L-712"><a href="#L-712"><span class="linenos">712</span></a><span class="k">class</span> <span class="nc">residualBlockPSP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-713"><a href="#L-713"><span class="linenos">713</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-714"><a href="#L-714"><span class="linenos">714</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-715"><a href="#L-715"><span class="linenos">715</span></a>        <span class="n">n_blocks</span><span class="p">,</span>
</span><span id="L-716"><a href="#L-716"><span class="linenos">716</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-717"><a href="#L-717"><span class="linenos">717</span></a>        <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-718"><a href="#L-718"><span class="linenos">718</span></a>        <span class="n">out_channels</span><span class="p">,</span>
</span><span id="L-719"><a href="#L-719"><span class="linenos">719</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="L-720"><a href="#L-720"><span class="linenos">720</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-721"><a href="#L-721"><span class="linenos">721</span></a>        <span class="n">include_range</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
</span><span id="L-722"><a href="#L-722"><span class="linenos">722</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-723"><a href="#L-723"><span class="linenos">723</span></a>    <span class="p">):</span>
</span><span id="L-724"><a href="#L-724"><span class="linenos">724</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualBlockPSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-725"><a href="#L-725"><span class="linenos">725</span></a>
</span><span id="L-726"><a href="#L-726"><span class="linenos">726</span></a>        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-727"><a href="#L-727"><span class="linenos">727</span></a>            <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-728"><a href="#L-728"><span class="linenos">728</span></a>
</span><span id="L-729"><a href="#L-729"><span class="linenos">729</span></a>        <span class="c1"># residualBlockPSP = convBlockPSP + identityBlockPSPs</span>
</span><span id="L-730"><a href="#L-730"><span class="linenos">730</span></a>        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-731"><a href="#L-731"><span class="linenos">731</span></a>        <span class="k">if</span> <span class="n">include_range</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="s2">&quot;conv&quot;</span><span class="p">]:</span>
</span><span id="L-732"><a href="#L-732"><span class="linenos">732</span></a>            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="L-733"><a href="#L-733"><span class="linenos">733</span></a>                <span class="n">bottleNeckPSP</span><span class="p">(</span>
</span><span id="L-734"><a href="#L-734"><span class="linenos">734</span></a>                    <span class="n">in_channels</span><span class="p">,</span>
</span><span id="L-735"><a href="#L-735"><span class="linenos">735</span></a>                    <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="L-736"><a href="#L-736"><span class="linenos">736</span></a>                    <span class="n">out_channels</span><span class="p">,</span>
</span><span id="L-737"><a href="#L-737"><span class="linenos">737</span></a>                    <span class="n">stride</span><span class="p">,</span>
</span><span id="L-738"><a href="#L-738"><span class="linenos">738</span></a>                    <span class="n">dilation</span><span class="p">,</span>
</span><span id="L-739"><a href="#L-739"><span class="linenos">739</span></a>                    <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-740"><a href="#L-740"><span class="linenos">740</span></a>                <span class="p">)</span>
</span><span id="L-741"><a href="#L-741"><span class="linenos">741</span></a>            <span class="p">)</span>
</span><span id="L-742"><a href="#L-742"><span class="linenos">742</span></a>        <span class="k">if</span> <span class="n">include_range</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="s2">&quot;identity&quot;</span><span class="p">]:</span>
</span><span id="L-743"><a href="#L-743"><span class="linenos">743</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="L-744"><a href="#L-744"><span class="linenos">744</span></a>                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="L-745"><a href="#L-745"><span class="linenos">745</span></a>                    <span class="n">bottleNeckIdentifyPSP</span><span class="p">(</span>
</span><span id="L-746"><a href="#L-746"><span class="linenos">746</span></a>                        <span class="n">out_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span>
</span><span id="L-747"><a href="#L-747"><span class="linenos">747</span></a>                    <span class="p">)</span>
</span><span id="L-748"><a href="#L-748"><span class="linenos">748</span></a>                <span class="p">)</span>
</span><span id="L-749"><a href="#L-749"><span class="linenos">749</span></a>
</span><span id="L-750"><a href="#L-750"><span class="linenos">750</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</span><span id="L-751"><a href="#L-751"><span class="linenos">751</span></a>
</span><span id="L-752"><a href="#L-752"><span class="linenos">752</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-753"><a href="#L-753"><span class="linenos">753</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-754"><a href="#L-754"><span class="linenos">754</span></a>
</span><span id="L-755"><a href="#L-755"><span class="linenos">755</span></a>
</span><span id="L-756"><a href="#L-756"><span class="linenos">756</span></a><span class="k">class</span> <span class="nc">cascadeFeatureFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-757"><a href="#L-757"><span class="linenos">757</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-758"><a href="#L-758"><span class="linenos">758</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">low_in_channels</span><span class="p">,</span> <span class="n">high_in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span>
</span><span id="L-759"><a href="#L-759"><span class="linenos">759</span></a>    <span class="p">):</span>
</span><span id="L-760"><a href="#L-760"><span class="linenos">760</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">cascadeFeatureFusion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-761"><a href="#L-761"><span class="linenos">761</span></a>
</span><span id="L-762"><a href="#L-762"><span class="linenos">762</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="L-763"><a href="#L-763"><span class="linenos">763</span></a>
</span><span id="L-764"><a href="#L-764"><span class="linenos">764</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">low_dilated_conv_bn</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="L-765"><a href="#L-765"><span class="linenos">765</span></a>            <span class="n">low_in_channels</span><span class="p">,</span>
</span><span id="L-766"><a href="#L-766"><span class="linenos">766</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="L-767"><a href="#L-767"><span class="linenos">767</span></a>            <span class="mi">3</span><span class="p">,</span>
</span><span id="L-768"><a href="#L-768"><span class="linenos">768</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-769"><a href="#L-769"><span class="linenos">769</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="L-770"><a href="#L-770"><span class="linenos">770</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-771"><a href="#L-771"><span class="linenos">771</span></a>            <span class="n">dilation</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="L-772"><a href="#L-772"><span class="linenos">772</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-773"><a href="#L-773"><span class="linenos">773</span></a>        <span class="p">)</span>
</span><span id="L-774"><a href="#L-774"><span class="linenos">774</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">low_classifier_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
</span><span id="L-775"><a href="#L-775"><span class="linenos">775</span></a>            <span class="nb">int</span><span class="p">(</span><span class="n">low_in_channels</span><span class="p">),</span>
</span><span id="L-776"><a href="#L-776"><span class="linenos">776</span></a>            <span class="nb">int</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span>
</span><span id="L-777"><a href="#L-777"><span class="linenos">777</span></a>            <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-778"><a href="#L-778"><span class="linenos">778</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-779"><a href="#L-779"><span class="linenos">779</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-780"><a href="#L-780"><span class="linenos">780</span></a>            <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-781"><a href="#L-781"><span class="linenos">781</span></a>            <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-782"><a href="#L-782"><span class="linenos">782</span></a>        <span class="p">)</span>  <span class="c1"># Train only</span>
</span><span id="L-783"><a href="#L-783"><span class="linenos">783</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">high_proj_conv_bn</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="L-784"><a href="#L-784"><span class="linenos">784</span></a>            <span class="n">high_in_channels</span><span class="p">,</span>
</span><span id="L-785"><a href="#L-785"><span class="linenos">785</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="L-786"><a href="#L-786"><span class="linenos">786</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="L-787"><a href="#L-787"><span class="linenos">787</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-788"><a href="#L-788"><span class="linenos">788</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-789"><a href="#L-789"><span class="linenos">789</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="L-790"><a href="#L-790"><span class="linenos">790</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="L-791"><a href="#L-791"><span class="linenos">791</span></a>        <span class="p">)</span>
</span><span id="L-792"><a href="#L-792"><span class="linenos">792</span></a>
</span><span id="L-793"><a href="#L-793"><span class="linenos">793</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_low</span><span class="p">,</span> <span class="n">x_high</span><span class="p">):</span>
</span><span id="L-794"><a href="#L-794"><span class="linenos">794</span></a>        <span class="n">x_low_upsampled</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span>
</span><span id="L-795"><a href="#L-795"><span class="linenos">795</span></a>            <span class="n">x_low</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">get_interp_size</span><span class="p">(</span><span class="n">x_low</span><span class="p">,</span> <span class="n">z_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span>
</span><span id="L-796"><a href="#L-796"><span class="linenos">796</span></a>        <span class="p">)</span>
</span><span id="L-797"><a href="#L-797"><span class="linenos">797</span></a>
</span><span id="L-798"><a href="#L-798"><span class="linenos">798</span></a>        <span class="n">low_cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_classifier_conv</span><span class="p">(</span><span class="n">x_low_upsampled</span><span class="p">)</span>
</span><span id="L-799"><a href="#L-799"><span class="linenos">799</span></a>
</span><span id="L-800"><a href="#L-800"><span class="linenos">800</span></a>        <span class="n">low_fm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_dilated_conv_bn</span><span class="p">(</span><span class="n">x_low_upsampled</span><span class="p">)</span>
</span><span id="L-801"><a href="#L-801"><span class="linenos">801</span></a>        <span class="n">high_fm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_proj_conv_bn</span><span class="p">(</span><span class="n">x_high</span><span class="p">)</span>
</span><span id="L-802"><a href="#L-802"><span class="linenos">802</span></a>        <span class="n">high_fused_fm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">low_fm</span> <span class="o">+</span> <span class="n">high_fm</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-803"><a href="#L-803"><span class="linenos">803</span></a>
</span><span id="L-804"><a href="#L-804"><span class="linenos">804</span></a>        <span class="k">return</span> <span class="n">high_fused_fm</span><span class="p">,</span> <span class="n">low_cls</span>
</span><span id="L-805"><a href="#L-805"><span class="linenos">805</span></a>
</span><span id="L-806"><a href="#L-806"><span class="linenos">806</span></a>
</span><span id="L-807"><a href="#L-807"><span class="linenos">807</span></a><span class="k">def</span> <span class="nf">get_interp_size</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">s_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">z_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># for caffe</span>
</span><span id="L-808"><a href="#L-808"><span class="linenos">808</span></a>    <span class="n">ori_h</span><span class="p">,</span> <span class="n">ori_w</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
</span><span id="L-809"><a href="#L-809"><span class="linenos">809</span></a>
</span><span id="L-810"><a href="#L-810"><span class="linenos">810</span></a>    <span class="c1"># shrink (s_factor &gt;= 1)</span>
</span><span id="L-811"><a href="#L-811"><span class="linenos">811</span></a>    <span class="n">ori_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">ori_h</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">s_factor</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="L-812"><a href="#L-812"><span class="linenos">812</span></a>    <span class="n">ori_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">ori_w</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">s_factor</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="L-813"><a href="#L-813"><span class="linenos">813</span></a>
</span><span id="L-814"><a href="#L-814"><span class="linenos">814</span></a>    <span class="c1"># zoom (z_factor &gt;= 1)</span>
</span><span id="L-815"><a href="#L-815"><span class="linenos">815</span></a>    <span class="n">ori_h</span> <span class="o">=</span> <span class="n">ori_h</span> <span class="o">+</span> <span class="p">(</span><span class="n">ori_h</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">z_factor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-816"><a href="#L-816"><span class="linenos">816</span></a>    <span class="n">ori_w</span> <span class="o">=</span> <span class="n">ori_w</span> <span class="o">+</span> <span class="p">(</span><span class="n">ori_w</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">z_factor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-817"><a href="#L-817"><span class="linenos">817</span></a>
</span><span id="L-818"><a href="#L-818"><span class="linenos">818</span></a>    <span class="n">resize_shape</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ori_h</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">ori_w</span><span class="p">))</span>
</span><span id="L-819"><a href="#L-819"><span class="linenos">819</span></a>    <span class="k">return</span> <span class="n">resize_shape</span>
</span><span id="L-820"><a href="#L-820"><span class="linenos">820</span></a>
</span><span id="L-821"><a href="#L-821"><span class="linenos">821</span></a>
</span><span id="L-822"><a href="#L-822"><span class="linenos">822</span></a><span class="k">def</span> <span class="nf">interp</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">):</span>
</span><span id="L-823"><a href="#L-823"><span class="linenos">823</span></a>    <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">ih</span><span class="p">,</span> <span class="n">iw</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
</span><span id="L-824"><a href="#L-824"><span class="linenos">824</span></a>    <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span> <span class="o">=</span> <span class="n">output_size</span>
</span><span id="L-825"><a href="#L-825"><span class="linenos">825</span></a>
</span><span id="L-826"><a href="#L-826"><span class="linenos">826</span></a>    <span class="c1"># normalize to [-1, 1]</span>
</span><span id="L-827"><a href="#L-827"><span class="linenos">827</span></a>    <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="nb">input</span><span class="o">.</span><span class="n">is_cuda</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">oh</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="L-828"><a href="#L-828"><span class="linenos">828</span></a>    <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ow</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="nb">input</span><span class="o">.</span><span class="n">is_cuda</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">ow</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="L-829"><a href="#L-829"><span class="linenos">829</span></a>
</span><span id="L-830"><a href="#L-830"><span class="linenos">830</span></a>    <span class="n">grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="nb">input</span><span class="o">.</span><span class="n">is_cuda</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</span><span id="L-831"><a href="#L-831"><span class="linenos">831</span></a>    <span class="n">grid</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">oh</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-832"><a href="#L-832"><span class="linenos">832</span></a>    <span class="n">grid</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">ow</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-833"><a href="#L-833"><span class="linenos">833</span></a>    <span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># grid.shape: [n, oh, ow, 2]</span>
</span><span id="L-834"><a href="#L-834"><span class="linenos">834</span></a>
</span><span id="L-835"><a href="#L-835"><span class="linenos">835</span></a>    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">grid_sample</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
</span><span id="L-836"><a href="#L-836"><span class="linenos">836</span></a>
</span><span id="L-837"><a href="#L-837"><span class="linenos">837</span></a>
</span><span id="L-838"><a href="#L-838"><span class="linenos">838</span></a><span class="k">def</span> <span class="nf">get_upsampling_weight</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">):</span>
</span><span id="L-839"><a href="#L-839"><span class="linenos">839</span></a>    <span class="sd">&quot;&quot;&quot;Make a 2D bilinear kernel suitable for upsampling&quot;&quot;&quot;</span>
</span><span id="L-840"><a href="#L-840"><span class="linenos">840</span></a>    <span class="n">factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
</span><span id="L-841"><a href="#L-841"><span class="linenos">841</span></a>    <span class="k">if</span> <span class="n">kernel_size</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-842"><a href="#L-842"><span class="linenos">842</span></a>        <span class="n">center</span> <span class="o">=</span> <span class="n">factor</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="L-843"><a href="#L-843"><span class="linenos">843</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="L-844"><a href="#L-844"><span class="linenos">844</span></a>        <span class="n">center</span> <span class="o">=</span> <span class="n">factor</span> <span class="o">-</span> <span class="mf">0.5</span>
</span><span id="L-845"><a href="#L-845"><span class="linenos">845</span></a>    <span class="n">og</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ogrid</span><span class="p">[:</span><span class="n">kernel_size</span><span class="p">,</span> <span class="p">:</span><span class="n">kernel_size</span><span class="p">]</span>
</span><span id="L-846"><a href="#L-846"><span class="linenos">846</span></a>    <span class="n">filt</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="nb">abs</span><span class="p">(</span><span class="n">og</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span> <span class="o">/</span> <span class="n">factor</span><span class="p">)</span> <span class="o">*</span> \
</span><span id="L-847"><a href="#L-847"><span class="linenos">847</span></a>           <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="nb">abs</span><span class="p">(</span><span class="n">og</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span> <span class="o">/</span> <span class="n">factor</span><span class="p">)</span>
</span><span id="L-848"><a href="#L-848"><span class="linenos">848</span></a>    <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">),</span>
</span><span id="L-849"><a href="#L-849"><span class="linenos">849</span></a>                      <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="L-850"><a href="#L-850"><span class="linenos">850</span></a>    <span class="n">weight</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_channels</span><span class="p">),</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">filt</span>
</span><span id="L-851"><a href="#L-851"><span class="linenos">851</span></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span></pre></div>


            </section>
                <section id="conv2DBatchNorm">
                            <input id="conv2DBatchNorm-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">conv2DBatchNorm</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="conv2DBatchNorm-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DBatchNorm"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DBatchNorm-7"><a href="#conv2DBatchNorm-7"><span class="linenos"> 7</span></a><span class="k">class</span> <span class="nc">conv2DBatchNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="conv2DBatchNorm-8"><a href="#conv2DBatchNorm-8"><span class="linenos"> 8</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="conv2DBatchNorm-9"><a href="#conv2DBatchNorm-9"><span class="linenos"> 9</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-10"><a href="#conv2DBatchNorm-10"><span class="linenos">10</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-11"><a href="#conv2DBatchNorm-11"><span class="linenos">11</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-12"><a href="#conv2DBatchNorm-12"><span class="linenos">12</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-13"><a href="#conv2DBatchNorm-13"><span class="linenos">13</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-14"><a href="#conv2DBatchNorm-14"><span class="linenos">14</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-15"><a href="#conv2DBatchNorm-15"><span class="linenos">15</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-16"><a href="#conv2DBatchNorm-16"><span class="linenos">16</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-17"><a href="#conv2DBatchNorm-17"><span class="linenos">17</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-18"><a href="#conv2DBatchNorm-18"><span class="linenos">18</span></a>    <span class="p">):</span>
</span><span id="conv2DBatchNorm-19"><a href="#conv2DBatchNorm-19"><span class="linenos">19</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DBatchNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="conv2DBatchNorm-20"><a href="#conv2DBatchNorm-20"><span class="linenos">20</span></a>
</span><span id="conv2DBatchNorm-21"><a href="#conv2DBatchNorm-21"><span class="linenos">21</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="conv2DBatchNorm-22"><a href="#conv2DBatchNorm-22"><span class="linenos">22</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="conv2DBatchNorm-23"><a href="#conv2DBatchNorm-23"><span class="linenos">23</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-24"><a href="#conv2DBatchNorm-24"><span class="linenos">24</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-25"><a href="#conv2DBatchNorm-25"><span class="linenos">25</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-26"><a href="#conv2DBatchNorm-26"><span class="linenos">26</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="conv2DBatchNorm-27"><a href="#conv2DBatchNorm-27"><span class="linenos">27</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="conv2DBatchNorm-28"><a href="#conv2DBatchNorm-28"><span class="linenos">28</span></a>
</span><span id="conv2DBatchNorm-29"><a href="#conv2DBatchNorm-29"><span class="linenos">29</span></a>        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
</span><span id="conv2DBatchNorm-30"><a href="#conv2DBatchNorm-30"><span class="linenos">30</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cb_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)))</span>
</span><span id="conv2DBatchNorm-31"><a href="#conv2DBatchNorm-31"><span class="linenos">31</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="conv2DBatchNorm-32"><a href="#conv2DBatchNorm-32"><span class="linenos">32</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cb_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">)</span>
</span><span id="conv2DBatchNorm-33"><a href="#conv2DBatchNorm-33"><span class="linenos">33</span></a>
</span><span id="conv2DBatchNorm-34"><a href="#conv2DBatchNorm-34"><span class="linenos">34</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="conv2DBatchNorm-35"><a href="#conv2DBatchNorm-35"><span class="linenos">35</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="conv2DBatchNorm-36"><a href="#conv2DBatchNorm-36"><span class="linenos">36</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#conv2DBatchNorm.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#conv2DBatchNorm.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="conv2DBatchNorm.__init__" class="classattr">
                                        <input id="conv2DBatchNorm.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">conv2DBatchNorm</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">in_channels</span>,</span><span class="param">	<span class="n">n_filters</span>,</span><span class="param">	<span class="n">k_size</span>,</span><span class="param">	<span class="n">stride</span>,</span><span class="param">	<span class="n">padding</span>,</span><span class="param">	<span class="n">bias</span><span class="o">=</span><span class="kc">True</span>,</span><span class="param">	<span class="n">dilation</span><span class="o">=</span><span class="mi">1</span>,</span><span class="param">	<span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="conv2DBatchNorm.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DBatchNorm.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DBatchNorm.__init__-8"><a href="#conv2DBatchNorm.__init__-8"><span class="linenos"> 8</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="conv2DBatchNorm.__init__-9"><a href="#conv2DBatchNorm.__init__-9"><span class="linenos"> 9</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-10"><a href="#conv2DBatchNorm.__init__-10"><span class="linenos">10</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-11"><a href="#conv2DBatchNorm.__init__-11"><span class="linenos">11</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-12"><a href="#conv2DBatchNorm.__init__-12"><span class="linenos">12</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-13"><a href="#conv2DBatchNorm.__init__-13"><span class="linenos">13</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-14"><a href="#conv2DBatchNorm.__init__-14"><span class="linenos">14</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-15"><a href="#conv2DBatchNorm.__init__-15"><span class="linenos">15</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-16"><a href="#conv2DBatchNorm.__init__-16"><span class="linenos">16</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-17"><a href="#conv2DBatchNorm.__init__-17"><span class="linenos">17</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-18"><a href="#conv2DBatchNorm.__init__-18"><span class="linenos">18</span></a>    <span class="p">):</span>
</span><span id="conv2DBatchNorm.__init__-19"><a href="#conv2DBatchNorm.__init__-19"><span class="linenos">19</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DBatchNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="conv2DBatchNorm.__init__-20"><a href="#conv2DBatchNorm.__init__-20"><span class="linenos">20</span></a>
</span><span id="conv2DBatchNorm.__init__-21"><a href="#conv2DBatchNorm.__init__-21"><span class="linenos">21</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="conv2DBatchNorm.__init__-22"><a href="#conv2DBatchNorm.__init__-22"><span class="linenos">22</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="conv2DBatchNorm.__init__-23"><a href="#conv2DBatchNorm.__init__-23"><span class="linenos">23</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-24"><a href="#conv2DBatchNorm.__init__-24"><span class="linenos">24</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-25"><a href="#conv2DBatchNorm.__init__-25"><span class="linenos">25</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-26"><a href="#conv2DBatchNorm.__init__-26"><span class="linenos">26</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="conv2DBatchNorm.__init__-27"><a href="#conv2DBatchNorm.__init__-27"><span class="linenos">27</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="conv2DBatchNorm.__init__-28"><a href="#conv2DBatchNorm.__init__-28"><span class="linenos">28</span></a>
</span><span id="conv2DBatchNorm.__init__-29"><a href="#conv2DBatchNorm.__init__-29"><span class="linenos">29</span></a>        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
</span><span id="conv2DBatchNorm.__init__-30"><a href="#conv2DBatchNorm.__init__-30"><span class="linenos">30</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cb_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)))</span>
</span><span id="conv2DBatchNorm.__init__-31"><a href="#conv2DBatchNorm.__init__-31"><span class="linenos">31</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="conv2DBatchNorm.__init__-32"><a href="#conv2DBatchNorm.__init__-32"><span class="linenos">32</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cb_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="conv2DBatchNorm.forward" class="classattr">
                                        <input id="conv2DBatchNorm.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="conv2DBatchNorm.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DBatchNorm.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DBatchNorm.forward-34"><a href="#conv2DBatchNorm.forward-34"><span class="linenos">34</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="conv2DBatchNorm.forward-35"><a href="#conv2DBatchNorm.forward-35"><span class="linenos">35</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="conv2DBatchNorm.forward-36"><a href="#conv2DBatchNorm.forward-36"><span class="linenos">36</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="conv2DBatchNorm.dump_patches" class="variable">dump_patches</dd>
                <dd id="conv2DBatchNorm.register_buffer" class="function">register_buffer</dd>
                <dd id="conv2DBatchNorm.register_parameter" class="function">register_parameter</dd>
                <dd id="conv2DBatchNorm.add_module" class="function">add_module</dd>
                <dd id="conv2DBatchNorm.register_module" class="function">register_module</dd>
                <dd id="conv2DBatchNorm.get_submodule" class="function">get_submodule</dd>
                <dd id="conv2DBatchNorm.get_parameter" class="function">get_parameter</dd>
                <dd id="conv2DBatchNorm.get_buffer" class="function">get_buffer</dd>
                <dd id="conv2DBatchNorm.get_extra_state" class="function">get_extra_state</dd>
                <dd id="conv2DBatchNorm.set_extra_state" class="function">set_extra_state</dd>
                <dd id="conv2DBatchNorm.apply" class="function">apply</dd>
                <dd id="conv2DBatchNorm.cuda" class="function">cuda</dd>
                <dd id="conv2DBatchNorm.ipu" class="function">ipu</dd>
                <dd id="conv2DBatchNorm.xpu" class="function">xpu</dd>
                <dd id="conv2DBatchNorm.cpu" class="function">cpu</dd>
                <dd id="conv2DBatchNorm.type" class="function">type</dd>
                <dd id="conv2DBatchNorm.float" class="function">float</dd>
                <dd id="conv2DBatchNorm.double" class="function">double</dd>
                <dd id="conv2DBatchNorm.half" class="function">half</dd>
                <dd id="conv2DBatchNorm.bfloat16" class="function">bfloat16</dd>
                <dd id="conv2DBatchNorm.to_empty" class="function">to_empty</dd>
                <dd id="conv2DBatchNorm.to" class="function">to</dd>
                <dd id="conv2DBatchNorm.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="conv2DBatchNorm.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="conv2DBatchNorm.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="conv2DBatchNorm.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="conv2DBatchNorm.T_destination" class="variable">T_destination</dd>
                <dd id="conv2DBatchNorm.state_dict" class="function">state_dict</dd>
                <dd id="conv2DBatchNorm.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="conv2DBatchNorm.load_state_dict" class="function">load_state_dict</dd>
                <dd id="conv2DBatchNorm.parameters" class="function">parameters</dd>
                <dd id="conv2DBatchNorm.named_parameters" class="function">named_parameters</dd>
                <dd id="conv2DBatchNorm.buffers" class="function">buffers</dd>
                <dd id="conv2DBatchNorm.named_buffers" class="function">named_buffers</dd>
                <dd id="conv2DBatchNorm.children" class="function">children</dd>
                <dd id="conv2DBatchNorm.named_children" class="function">named_children</dd>
                <dd id="conv2DBatchNorm.modules" class="function">modules</dd>
                <dd id="conv2DBatchNorm.named_modules" class="function">named_modules</dd>
                <dd id="conv2DBatchNorm.train" class="function">train</dd>
                <dd id="conv2DBatchNorm.eval" class="function">eval</dd>
                <dd id="conv2DBatchNorm.requires_grad_" class="function">requires_grad_</dd>
                <dd id="conv2DBatchNorm.zero_grad" class="function">zero_grad</dd>
                <dd id="conv2DBatchNorm.share_memory" class="function">share_memory</dd>
                <dd id="conv2DBatchNorm.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="conv2DGroupNorm">
                            <input id="conv2DGroupNorm-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">conv2DGroupNorm</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="conv2DGroupNorm-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DGroupNorm"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DGroupNorm-39"><a href="#conv2DGroupNorm-39"><span class="linenos">39</span></a><span class="k">class</span> <span class="nc">conv2DGroupNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="conv2DGroupNorm-40"><a href="#conv2DGroupNorm-40"><span class="linenos">40</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="conv2DGroupNorm-41"><a href="#conv2DGroupNorm-41"><span class="linenos">41</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-42"><a href="#conv2DGroupNorm-42"><span class="linenos">42</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-43"><a href="#conv2DGroupNorm-43"><span class="linenos">43</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-44"><a href="#conv2DGroupNorm-44"><span class="linenos">44</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-45"><a href="#conv2DGroupNorm-45"><span class="linenos">45</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-46"><a href="#conv2DGroupNorm-46"><span class="linenos">46</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-47"><a href="#conv2DGroupNorm-47"><span class="linenos">47</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-48"><a href="#conv2DGroupNorm-48"><span class="linenos">48</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-49"><a href="#conv2DGroupNorm-49"><span class="linenos">49</span></a>        <span class="n">n_groups</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-50"><a href="#conv2DGroupNorm-50"><span class="linenos">50</span></a>    <span class="p">):</span>
</span><span id="conv2DGroupNorm-51"><a href="#conv2DGroupNorm-51"><span class="linenos">51</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DGroupNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="conv2DGroupNorm-52"><a href="#conv2DGroupNorm-52"><span class="linenos">52</span></a>
</span><span id="conv2DGroupNorm-53"><a href="#conv2DGroupNorm-53"><span class="linenos">53</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="conv2DGroupNorm-54"><a href="#conv2DGroupNorm-54"><span class="linenos">54</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="conv2DGroupNorm-55"><a href="#conv2DGroupNorm-55"><span class="linenos">55</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-56"><a href="#conv2DGroupNorm-56"><span class="linenos">56</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-57"><a href="#conv2DGroupNorm-57"><span class="linenos">57</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-58"><a href="#conv2DGroupNorm-58"><span class="linenos">58</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="conv2DGroupNorm-59"><a href="#conv2DGroupNorm-59"><span class="linenos">59</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="conv2DGroupNorm-60"><a href="#conv2DGroupNorm-60"><span class="linenos">60</span></a>
</span><span id="conv2DGroupNorm-61"><a href="#conv2DGroupNorm-61"><span class="linenos">61</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cg_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> 
</span><span id="conv2DGroupNorm-62"><a href="#conv2DGroupNorm-62"><span class="linenos">62</span></a>                                     <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">n_groups</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)))</span>
</span><span id="conv2DGroupNorm-63"><a href="#conv2DGroupNorm-63"><span class="linenos">63</span></a>
</span><span id="conv2DGroupNorm-64"><a href="#conv2DGroupNorm-64"><span class="linenos">64</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="conv2DGroupNorm-65"><a href="#conv2DGroupNorm-65"><span class="linenos">65</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cg_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="conv2DGroupNorm-66"><a href="#conv2DGroupNorm-66"><span class="linenos">66</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#conv2DGroupNorm.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#conv2DGroupNorm.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="conv2DGroupNorm.__init__" class="classattr">
                                        <input id="conv2DGroupNorm.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">conv2DGroupNorm</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">in_channels</span>,</span><span class="param">	<span class="n">n_filters</span>,</span><span class="param">	<span class="n">k_size</span>,</span><span class="param">	<span class="n">stride</span>,</span><span class="param">	<span class="n">padding</span>,</span><span class="param">	<span class="n">bias</span><span class="o">=</span><span class="kc">True</span>,</span><span class="param">	<span class="n">dilation</span><span class="o">=</span><span class="mi">1</span>,</span><span class="param">	<span class="n">n_groups</span><span class="o">=</span><span class="mi">16</span></span>)</span>

                <label class="view-source-button" for="conv2DGroupNorm.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DGroupNorm.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DGroupNorm.__init__-40"><a href="#conv2DGroupNorm.__init__-40"><span class="linenos">40</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="conv2DGroupNorm.__init__-41"><a href="#conv2DGroupNorm.__init__-41"><span class="linenos">41</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-42"><a href="#conv2DGroupNorm.__init__-42"><span class="linenos">42</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-43"><a href="#conv2DGroupNorm.__init__-43"><span class="linenos">43</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-44"><a href="#conv2DGroupNorm.__init__-44"><span class="linenos">44</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-45"><a href="#conv2DGroupNorm.__init__-45"><span class="linenos">45</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-46"><a href="#conv2DGroupNorm.__init__-46"><span class="linenos">46</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-47"><a href="#conv2DGroupNorm.__init__-47"><span class="linenos">47</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-48"><a href="#conv2DGroupNorm.__init__-48"><span class="linenos">48</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-49"><a href="#conv2DGroupNorm.__init__-49"><span class="linenos">49</span></a>        <span class="n">n_groups</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-50"><a href="#conv2DGroupNorm.__init__-50"><span class="linenos">50</span></a>    <span class="p">):</span>
</span><span id="conv2DGroupNorm.__init__-51"><a href="#conv2DGroupNorm.__init__-51"><span class="linenos">51</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DGroupNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="conv2DGroupNorm.__init__-52"><a href="#conv2DGroupNorm.__init__-52"><span class="linenos">52</span></a>
</span><span id="conv2DGroupNorm.__init__-53"><a href="#conv2DGroupNorm.__init__-53"><span class="linenos">53</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="conv2DGroupNorm.__init__-54"><a href="#conv2DGroupNorm.__init__-54"><span class="linenos">54</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="conv2DGroupNorm.__init__-55"><a href="#conv2DGroupNorm.__init__-55"><span class="linenos">55</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-56"><a href="#conv2DGroupNorm.__init__-56"><span class="linenos">56</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-57"><a href="#conv2DGroupNorm.__init__-57"><span class="linenos">57</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-58"><a href="#conv2DGroupNorm.__init__-58"><span class="linenos">58</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="conv2DGroupNorm.__init__-59"><a href="#conv2DGroupNorm.__init__-59"><span class="linenos">59</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="conv2DGroupNorm.__init__-60"><a href="#conv2DGroupNorm.__init__-60"><span class="linenos">60</span></a>
</span><span id="conv2DGroupNorm.__init__-61"><a href="#conv2DGroupNorm.__init__-61"><span class="linenos">61</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cg_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> 
</span><span id="conv2DGroupNorm.__init__-62"><a href="#conv2DGroupNorm.__init__-62"><span class="linenos">62</span></a>                                     <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">n_groups</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)))</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="conv2DGroupNorm.forward" class="classattr">
                                        <input id="conv2DGroupNorm.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="conv2DGroupNorm.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DGroupNorm.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DGroupNorm.forward-64"><a href="#conv2DGroupNorm.forward-64"><span class="linenos">64</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="conv2DGroupNorm.forward-65"><a href="#conv2DGroupNorm.forward-65"><span class="linenos">65</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cg_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="conv2DGroupNorm.forward-66"><a href="#conv2DGroupNorm.forward-66"><span class="linenos">66</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="conv2DGroupNorm.dump_patches" class="variable">dump_patches</dd>
                <dd id="conv2DGroupNorm.register_buffer" class="function">register_buffer</dd>
                <dd id="conv2DGroupNorm.register_parameter" class="function">register_parameter</dd>
                <dd id="conv2DGroupNorm.add_module" class="function">add_module</dd>
                <dd id="conv2DGroupNorm.register_module" class="function">register_module</dd>
                <dd id="conv2DGroupNorm.get_submodule" class="function">get_submodule</dd>
                <dd id="conv2DGroupNorm.get_parameter" class="function">get_parameter</dd>
                <dd id="conv2DGroupNorm.get_buffer" class="function">get_buffer</dd>
                <dd id="conv2DGroupNorm.get_extra_state" class="function">get_extra_state</dd>
                <dd id="conv2DGroupNorm.set_extra_state" class="function">set_extra_state</dd>
                <dd id="conv2DGroupNorm.apply" class="function">apply</dd>
                <dd id="conv2DGroupNorm.cuda" class="function">cuda</dd>
                <dd id="conv2DGroupNorm.ipu" class="function">ipu</dd>
                <dd id="conv2DGroupNorm.xpu" class="function">xpu</dd>
                <dd id="conv2DGroupNorm.cpu" class="function">cpu</dd>
                <dd id="conv2DGroupNorm.type" class="function">type</dd>
                <dd id="conv2DGroupNorm.float" class="function">float</dd>
                <dd id="conv2DGroupNorm.double" class="function">double</dd>
                <dd id="conv2DGroupNorm.half" class="function">half</dd>
                <dd id="conv2DGroupNorm.bfloat16" class="function">bfloat16</dd>
                <dd id="conv2DGroupNorm.to_empty" class="function">to_empty</dd>
                <dd id="conv2DGroupNorm.to" class="function">to</dd>
                <dd id="conv2DGroupNorm.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="conv2DGroupNorm.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="conv2DGroupNorm.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="conv2DGroupNorm.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="conv2DGroupNorm.T_destination" class="variable">T_destination</dd>
                <dd id="conv2DGroupNorm.state_dict" class="function">state_dict</dd>
                <dd id="conv2DGroupNorm.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="conv2DGroupNorm.load_state_dict" class="function">load_state_dict</dd>
                <dd id="conv2DGroupNorm.parameters" class="function">parameters</dd>
                <dd id="conv2DGroupNorm.named_parameters" class="function">named_parameters</dd>
                <dd id="conv2DGroupNorm.buffers" class="function">buffers</dd>
                <dd id="conv2DGroupNorm.named_buffers" class="function">named_buffers</dd>
                <dd id="conv2DGroupNorm.children" class="function">children</dd>
                <dd id="conv2DGroupNorm.named_children" class="function">named_children</dd>
                <dd id="conv2DGroupNorm.modules" class="function">modules</dd>
                <dd id="conv2DGroupNorm.named_modules" class="function">named_modules</dd>
                <dd id="conv2DGroupNorm.train" class="function">train</dd>
                <dd id="conv2DGroupNorm.eval" class="function">eval</dd>
                <dd id="conv2DGroupNorm.requires_grad_" class="function">requires_grad_</dd>
                <dd id="conv2DGroupNorm.zero_grad" class="function">zero_grad</dd>
                <dd id="conv2DGroupNorm.share_memory" class="function">share_memory</dd>
                <dd id="conv2DGroupNorm.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="deconv2DBatchNorm">
                            <input id="deconv2DBatchNorm-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">deconv2DBatchNorm</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="deconv2DBatchNorm-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#deconv2DBatchNorm"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="deconv2DBatchNorm-69"><a href="#deconv2DBatchNorm-69"><span class="linenos">69</span></a><span class="k">class</span> <span class="nc">deconv2DBatchNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="deconv2DBatchNorm-70"><a href="#deconv2DBatchNorm-70"><span class="linenos">70</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="deconv2DBatchNorm-71"><a href="#deconv2DBatchNorm-71"><span class="linenos">71</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">deconv2DBatchNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="deconv2DBatchNorm-72"><a href="#deconv2DBatchNorm-72"><span class="linenos">72</span></a>
</span><span id="deconv2DBatchNorm-73"><a href="#deconv2DBatchNorm-73"><span class="linenos">73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dcb_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="deconv2DBatchNorm-74"><a href="#deconv2DBatchNorm-74"><span class="linenos">74</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span>
</span><span id="deconv2DBatchNorm-75"><a href="#deconv2DBatchNorm-75"><span class="linenos">75</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="deconv2DBatchNorm-76"><a href="#deconv2DBatchNorm-76"><span class="linenos">76</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="deconv2DBatchNorm-77"><a href="#deconv2DBatchNorm-77"><span class="linenos">77</span></a>                <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="deconv2DBatchNorm-78"><a href="#deconv2DBatchNorm-78"><span class="linenos">78</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="deconv2DBatchNorm-79"><a href="#deconv2DBatchNorm-79"><span class="linenos">79</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="deconv2DBatchNorm-80"><a href="#deconv2DBatchNorm-80"><span class="linenos">80</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="deconv2DBatchNorm-81"><a href="#deconv2DBatchNorm-81"><span class="linenos">81</span></a>            <span class="p">),</span>
</span><span id="deconv2DBatchNorm-82"><a href="#deconv2DBatchNorm-82"><span class="linenos">82</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span>
</span><span id="deconv2DBatchNorm-83"><a href="#deconv2DBatchNorm-83"><span class="linenos">83</span></a>        <span class="p">)</span>
</span><span id="deconv2DBatchNorm-84"><a href="#deconv2DBatchNorm-84"><span class="linenos">84</span></a>
</span><span id="deconv2DBatchNorm-85"><a href="#deconv2DBatchNorm-85"><span class="linenos">85</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="deconv2DBatchNorm-86"><a href="#deconv2DBatchNorm-86"><span class="linenos">86</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dcb_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="deconv2DBatchNorm-87"><a href="#deconv2DBatchNorm-87"><span class="linenos">87</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#deconv2DBatchNorm.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#deconv2DBatchNorm.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="deconv2DBatchNorm.__init__" class="classattr">
                                        <input id="deconv2DBatchNorm.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">deconv2DBatchNorm</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_channels</span>, </span><span class="param"><span class="n">n_filters</span>, </span><span class="param"><span class="n">k_size</span>, </span><span class="param"><span class="n">stride</span>, </span><span class="param"><span class="n">padding</span>, </span><span class="param"><span class="n">bias</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="deconv2DBatchNorm.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#deconv2DBatchNorm.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="deconv2DBatchNorm.__init__-70"><a href="#deconv2DBatchNorm.__init__-70"><span class="linenos">70</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="deconv2DBatchNorm.__init__-71"><a href="#deconv2DBatchNorm.__init__-71"><span class="linenos">71</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">deconv2DBatchNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="deconv2DBatchNorm.__init__-72"><a href="#deconv2DBatchNorm.__init__-72"><span class="linenos">72</span></a>
</span><span id="deconv2DBatchNorm.__init__-73"><a href="#deconv2DBatchNorm.__init__-73"><span class="linenos">73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dcb_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="deconv2DBatchNorm.__init__-74"><a href="#deconv2DBatchNorm.__init__-74"><span class="linenos">74</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span>
</span><span id="deconv2DBatchNorm.__init__-75"><a href="#deconv2DBatchNorm.__init__-75"><span class="linenos">75</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="deconv2DBatchNorm.__init__-76"><a href="#deconv2DBatchNorm.__init__-76"><span class="linenos">76</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="deconv2DBatchNorm.__init__-77"><a href="#deconv2DBatchNorm.__init__-77"><span class="linenos">77</span></a>                <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="deconv2DBatchNorm.__init__-78"><a href="#deconv2DBatchNorm.__init__-78"><span class="linenos">78</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="deconv2DBatchNorm.__init__-79"><a href="#deconv2DBatchNorm.__init__-79"><span class="linenos">79</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="deconv2DBatchNorm.__init__-80"><a href="#deconv2DBatchNorm.__init__-80"><span class="linenos">80</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="deconv2DBatchNorm.__init__-81"><a href="#deconv2DBatchNorm.__init__-81"><span class="linenos">81</span></a>            <span class="p">),</span>
</span><span id="deconv2DBatchNorm.__init__-82"><a href="#deconv2DBatchNorm.__init__-82"><span class="linenos">82</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span>
</span><span id="deconv2DBatchNorm.__init__-83"><a href="#deconv2DBatchNorm.__init__-83"><span class="linenos">83</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="deconv2DBatchNorm.forward" class="classattr">
                                        <input id="deconv2DBatchNorm.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="deconv2DBatchNorm.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#deconv2DBatchNorm.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="deconv2DBatchNorm.forward-85"><a href="#deconv2DBatchNorm.forward-85"><span class="linenos">85</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="deconv2DBatchNorm.forward-86"><a href="#deconv2DBatchNorm.forward-86"><span class="linenos">86</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dcb_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="deconv2DBatchNorm.forward-87"><a href="#deconv2DBatchNorm.forward-87"><span class="linenos">87</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="deconv2DBatchNorm.dump_patches" class="variable">dump_patches</dd>
                <dd id="deconv2DBatchNorm.register_buffer" class="function">register_buffer</dd>
                <dd id="deconv2DBatchNorm.register_parameter" class="function">register_parameter</dd>
                <dd id="deconv2DBatchNorm.add_module" class="function">add_module</dd>
                <dd id="deconv2DBatchNorm.register_module" class="function">register_module</dd>
                <dd id="deconv2DBatchNorm.get_submodule" class="function">get_submodule</dd>
                <dd id="deconv2DBatchNorm.get_parameter" class="function">get_parameter</dd>
                <dd id="deconv2DBatchNorm.get_buffer" class="function">get_buffer</dd>
                <dd id="deconv2DBatchNorm.get_extra_state" class="function">get_extra_state</dd>
                <dd id="deconv2DBatchNorm.set_extra_state" class="function">set_extra_state</dd>
                <dd id="deconv2DBatchNorm.apply" class="function">apply</dd>
                <dd id="deconv2DBatchNorm.cuda" class="function">cuda</dd>
                <dd id="deconv2DBatchNorm.ipu" class="function">ipu</dd>
                <dd id="deconv2DBatchNorm.xpu" class="function">xpu</dd>
                <dd id="deconv2DBatchNorm.cpu" class="function">cpu</dd>
                <dd id="deconv2DBatchNorm.type" class="function">type</dd>
                <dd id="deconv2DBatchNorm.float" class="function">float</dd>
                <dd id="deconv2DBatchNorm.double" class="function">double</dd>
                <dd id="deconv2DBatchNorm.half" class="function">half</dd>
                <dd id="deconv2DBatchNorm.bfloat16" class="function">bfloat16</dd>
                <dd id="deconv2DBatchNorm.to_empty" class="function">to_empty</dd>
                <dd id="deconv2DBatchNorm.to" class="function">to</dd>
                <dd id="deconv2DBatchNorm.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="deconv2DBatchNorm.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="deconv2DBatchNorm.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="deconv2DBatchNorm.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="deconv2DBatchNorm.T_destination" class="variable">T_destination</dd>
                <dd id="deconv2DBatchNorm.state_dict" class="function">state_dict</dd>
                <dd id="deconv2DBatchNorm.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="deconv2DBatchNorm.load_state_dict" class="function">load_state_dict</dd>
                <dd id="deconv2DBatchNorm.parameters" class="function">parameters</dd>
                <dd id="deconv2DBatchNorm.named_parameters" class="function">named_parameters</dd>
                <dd id="deconv2DBatchNorm.buffers" class="function">buffers</dd>
                <dd id="deconv2DBatchNorm.named_buffers" class="function">named_buffers</dd>
                <dd id="deconv2DBatchNorm.children" class="function">children</dd>
                <dd id="deconv2DBatchNorm.named_children" class="function">named_children</dd>
                <dd id="deconv2DBatchNorm.modules" class="function">modules</dd>
                <dd id="deconv2DBatchNorm.named_modules" class="function">named_modules</dd>
                <dd id="deconv2DBatchNorm.train" class="function">train</dd>
                <dd id="deconv2DBatchNorm.eval" class="function">eval</dd>
                <dd id="deconv2DBatchNorm.requires_grad_" class="function">requires_grad_</dd>
                <dd id="deconv2DBatchNorm.zero_grad" class="function">zero_grad</dd>
                <dd id="deconv2DBatchNorm.share_memory" class="function">share_memory</dd>
                <dd id="deconv2DBatchNorm.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="conv2DBatchNormRelu">
                            <input id="conv2DBatchNormRelu-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">conv2DBatchNormRelu</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="conv2DBatchNormRelu-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DBatchNormRelu"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DBatchNormRelu-90"><a href="#conv2DBatchNormRelu-90"><span class="linenos"> 90</span></a><span class="k">class</span> <span class="nc">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="conv2DBatchNormRelu-91"><a href="#conv2DBatchNormRelu-91"><span class="linenos"> 91</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="conv2DBatchNormRelu-92"><a href="#conv2DBatchNormRelu-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-93"><a href="#conv2DBatchNormRelu-93"><span class="linenos"> 93</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-94"><a href="#conv2DBatchNormRelu-94"><span class="linenos"> 94</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-95"><a href="#conv2DBatchNormRelu-95"><span class="linenos"> 95</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-96"><a href="#conv2DBatchNormRelu-96"><span class="linenos"> 96</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-97"><a href="#conv2DBatchNormRelu-97"><span class="linenos"> 97</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-98"><a href="#conv2DBatchNormRelu-98"><span class="linenos"> 98</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-99"><a href="#conv2DBatchNormRelu-99"><span class="linenos"> 99</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-100"><a href="#conv2DBatchNormRelu-100"><span class="linenos">100</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-101"><a href="#conv2DBatchNormRelu-101"><span class="linenos">101</span></a>    <span class="p">):</span>
</span><span id="conv2DBatchNormRelu-102"><a href="#conv2DBatchNormRelu-102"><span class="linenos">102</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DBatchNormRelu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="conv2DBatchNormRelu-103"><a href="#conv2DBatchNormRelu-103"><span class="linenos">103</span></a>
</span><span id="conv2DBatchNormRelu-104"><a href="#conv2DBatchNormRelu-104"><span class="linenos">104</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="conv2DBatchNormRelu-105"><a href="#conv2DBatchNormRelu-105"><span class="linenos">105</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="conv2DBatchNormRelu-106"><a href="#conv2DBatchNormRelu-106"><span class="linenos">106</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-107"><a href="#conv2DBatchNormRelu-107"><span class="linenos">107</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-108"><a href="#conv2DBatchNormRelu-108"><span class="linenos">108</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-109"><a href="#conv2DBatchNormRelu-109"><span class="linenos">109</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu-110"><a href="#conv2DBatchNormRelu-110"><span class="linenos">110</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="conv2DBatchNormRelu-111"><a href="#conv2DBatchNormRelu-111"><span class="linenos">111</span></a>
</span><span id="conv2DBatchNormRelu-112"><a href="#conv2DBatchNormRelu-112"><span class="linenos">112</span></a>        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
</span><span id="conv2DBatchNormRelu-113"><a href="#conv2DBatchNormRelu-113"><span class="linenos">113</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> 
</span><span id="conv2DBatchNormRelu-114"><a href="#conv2DBatchNormRelu-114"><span class="linenos">114</span></a>                                          <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span> 
</span><span id="conv2DBatchNormRelu-115"><a href="#conv2DBatchNormRelu-115"><span class="linenos">115</span></a>                                          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="conv2DBatchNormRelu-116"><a href="#conv2DBatchNormRelu-116"><span class="linenos">116</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="conv2DBatchNormRelu-117"><a href="#conv2DBatchNormRelu-117"><span class="linenos">117</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="conv2DBatchNormRelu-118"><a href="#conv2DBatchNormRelu-118"><span class="linenos">118</span></a>
</span><span id="conv2DBatchNormRelu-119"><a href="#conv2DBatchNormRelu-119"><span class="linenos">119</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="conv2DBatchNormRelu-120"><a href="#conv2DBatchNormRelu-120"><span class="linenos">120</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cbr_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="conv2DBatchNormRelu-121"><a href="#conv2DBatchNormRelu-121"><span class="linenos">121</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#conv2DBatchNormRelu.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#conv2DBatchNormRelu.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="conv2DBatchNormRelu.__init__" class="classattr">
                                        <input id="conv2DBatchNormRelu.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">conv2DBatchNormRelu</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">in_channels</span>,</span><span class="param">	<span class="n">n_filters</span>,</span><span class="param">	<span class="n">k_size</span>,</span><span class="param">	<span class="n">stride</span>,</span><span class="param">	<span class="n">padding</span>,</span><span class="param">	<span class="n">bias</span><span class="o">=</span><span class="kc">True</span>,</span><span class="param">	<span class="n">dilation</span><span class="o">=</span><span class="mi">1</span>,</span><span class="param">	<span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="conv2DBatchNormRelu.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DBatchNormRelu.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DBatchNormRelu.__init__-91"><a href="#conv2DBatchNormRelu.__init__-91"><span class="linenos"> 91</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="conv2DBatchNormRelu.__init__-92"><a href="#conv2DBatchNormRelu.__init__-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-93"><a href="#conv2DBatchNormRelu.__init__-93"><span class="linenos"> 93</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-94"><a href="#conv2DBatchNormRelu.__init__-94"><span class="linenos"> 94</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-95"><a href="#conv2DBatchNormRelu.__init__-95"><span class="linenos"> 95</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-96"><a href="#conv2DBatchNormRelu.__init__-96"><span class="linenos"> 96</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-97"><a href="#conv2DBatchNormRelu.__init__-97"><span class="linenos"> 97</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-98"><a href="#conv2DBatchNormRelu.__init__-98"><span class="linenos"> 98</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-99"><a href="#conv2DBatchNormRelu.__init__-99"><span class="linenos"> 99</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-100"><a href="#conv2DBatchNormRelu.__init__-100"><span class="linenos">100</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-101"><a href="#conv2DBatchNormRelu.__init__-101"><span class="linenos">101</span></a>    <span class="p">):</span>
</span><span id="conv2DBatchNormRelu.__init__-102"><a href="#conv2DBatchNormRelu.__init__-102"><span class="linenos">102</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DBatchNormRelu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="conv2DBatchNormRelu.__init__-103"><a href="#conv2DBatchNormRelu.__init__-103"><span class="linenos">103</span></a>
</span><span id="conv2DBatchNormRelu.__init__-104"><a href="#conv2DBatchNormRelu.__init__-104"><span class="linenos">104</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="conv2DBatchNormRelu.__init__-105"><a href="#conv2DBatchNormRelu.__init__-105"><span class="linenos">105</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="conv2DBatchNormRelu.__init__-106"><a href="#conv2DBatchNormRelu.__init__-106"><span class="linenos">106</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-107"><a href="#conv2DBatchNormRelu.__init__-107"><span class="linenos">107</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-108"><a href="#conv2DBatchNormRelu.__init__-108"><span class="linenos">108</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-109"><a href="#conv2DBatchNormRelu.__init__-109"><span class="linenos">109</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="conv2DBatchNormRelu.__init__-110"><a href="#conv2DBatchNormRelu.__init__-110"><span class="linenos">110</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="conv2DBatchNormRelu.__init__-111"><a href="#conv2DBatchNormRelu.__init__-111"><span class="linenos">111</span></a>
</span><span id="conv2DBatchNormRelu.__init__-112"><a href="#conv2DBatchNormRelu.__init__-112"><span class="linenos">112</span></a>        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
</span><span id="conv2DBatchNormRelu.__init__-113"><a href="#conv2DBatchNormRelu.__init__-113"><span class="linenos">113</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> 
</span><span id="conv2DBatchNormRelu.__init__-114"><a href="#conv2DBatchNormRelu.__init__-114"><span class="linenos">114</span></a>                                          <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span> 
</span><span id="conv2DBatchNormRelu.__init__-115"><a href="#conv2DBatchNormRelu.__init__-115"><span class="linenos">115</span></a>                                          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="conv2DBatchNormRelu.__init__-116"><a href="#conv2DBatchNormRelu.__init__-116"><span class="linenos">116</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="conv2DBatchNormRelu.__init__-117"><a href="#conv2DBatchNormRelu.__init__-117"><span class="linenos">117</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="conv2DBatchNormRelu.forward" class="classattr">
                                        <input id="conv2DBatchNormRelu.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="conv2DBatchNormRelu.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DBatchNormRelu.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DBatchNormRelu.forward-119"><a href="#conv2DBatchNormRelu.forward-119"><span class="linenos">119</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="conv2DBatchNormRelu.forward-120"><a href="#conv2DBatchNormRelu.forward-120"><span class="linenos">120</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cbr_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="conv2DBatchNormRelu.forward-121"><a href="#conv2DBatchNormRelu.forward-121"><span class="linenos">121</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="conv2DBatchNormRelu.dump_patches" class="variable">dump_patches</dd>
                <dd id="conv2DBatchNormRelu.register_buffer" class="function">register_buffer</dd>
                <dd id="conv2DBatchNormRelu.register_parameter" class="function">register_parameter</dd>
                <dd id="conv2DBatchNormRelu.add_module" class="function">add_module</dd>
                <dd id="conv2DBatchNormRelu.register_module" class="function">register_module</dd>
                <dd id="conv2DBatchNormRelu.get_submodule" class="function">get_submodule</dd>
                <dd id="conv2DBatchNormRelu.get_parameter" class="function">get_parameter</dd>
                <dd id="conv2DBatchNormRelu.get_buffer" class="function">get_buffer</dd>
                <dd id="conv2DBatchNormRelu.get_extra_state" class="function">get_extra_state</dd>
                <dd id="conv2DBatchNormRelu.set_extra_state" class="function">set_extra_state</dd>
                <dd id="conv2DBatchNormRelu.apply" class="function">apply</dd>
                <dd id="conv2DBatchNormRelu.cuda" class="function">cuda</dd>
                <dd id="conv2DBatchNormRelu.ipu" class="function">ipu</dd>
                <dd id="conv2DBatchNormRelu.xpu" class="function">xpu</dd>
                <dd id="conv2DBatchNormRelu.cpu" class="function">cpu</dd>
                <dd id="conv2DBatchNormRelu.type" class="function">type</dd>
                <dd id="conv2DBatchNormRelu.float" class="function">float</dd>
                <dd id="conv2DBatchNormRelu.double" class="function">double</dd>
                <dd id="conv2DBatchNormRelu.half" class="function">half</dd>
                <dd id="conv2DBatchNormRelu.bfloat16" class="function">bfloat16</dd>
                <dd id="conv2DBatchNormRelu.to_empty" class="function">to_empty</dd>
                <dd id="conv2DBatchNormRelu.to" class="function">to</dd>
                <dd id="conv2DBatchNormRelu.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="conv2DBatchNormRelu.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="conv2DBatchNormRelu.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="conv2DBatchNormRelu.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="conv2DBatchNormRelu.T_destination" class="variable">T_destination</dd>
                <dd id="conv2DBatchNormRelu.state_dict" class="function">state_dict</dd>
                <dd id="conv2DBatchNormRelu.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="conv2DBatchNormRelu.load_state_dict" class="function">load_state_dict</dd>
                <dd id="conv2DBatchNormRelu.parameters" class="function">parameters</dd>
                <dd id="conv2DBatchNormRelu.named_parameters" class="function">named_parameters</dd>
                <dd id="conv2DBatchNormRelu.buffers" class="function">buffers</dd>
                <dd id="conv2DBatchNormRelu.named_buffers" class="function">named_buffers</dd>
                <dd id="conv2DBatchNormRelu.children" class="function">children</dd>
                <dd id="conv2DBatchNormRelu.named_children" class="function">named_children</dd>
                <dd id="conv2DBatchNormRelu.modules" class="function">modules</dd>
                <dd id="conv2DBatchNormRelu.named_modules" class="function">named_modules</dd>
                <dd id="conv2DBatchNormRelu.train" class="function">train</dd>
                <dd id="conv2DBatchNormRelu.eval" class="function">eval</dd>
                <dd id="conv2DBatchNormRelu.requires_grad_" class="function">requires_grad_</dd>
                <dd id="conv2DBatchNormRelu.zero_grad" class="function">zero_grad</dd>
                <dd id="conv2DBatchNormRelu.share_memory" class="function">share_memory</dd>
                <dd id="conv2DBatchNormRelu.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="conv2DGroupNormRelu">
                            <input id="conv2DGroupNormRelu-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">conv2DGroupNormRelu</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="conv2DGroupNormRelu-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DGroupNormRelu"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DGroupNormRelu-124"><a href="#conv2DGroupNormRelu-124"><span class="linenos">124</span></a><span class="k">class</span> <span class="nc">conv2DGroupNormRelu</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="conv2DGroupNormRelu-125"><a href="#conv2DGroupNormRelu-125"><span class="linenos">125</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="conv2DGroupNormRelu-126"><a href="#conv2DGroupNormRelu-126"><span class="linenos">126</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-127"><a href="#conv2DGroupNormRelu-127"><span class="linenos">127</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-128"><a href="#conv2DGroupNormRelu-128"><span class="linenos">128</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-129"><a href="#conv2DGroupNormRelu-129"><span class="linenos">129</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-130"><a href="#conv2DGroupNormRelu-130"><span class="linenos">130</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-131"><a href="#conv2DGroupNormRelu-131"><span class="linenos">131</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-132"><a href="#conv2DGroupNormRelu-132"><span class="linenos">132</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-133"><a href="#conv2DGroupNormRelu-133"><span class="linenos">133</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-134"><a href="#conv2DGroupNormRelu-134"><span class="linenos">134</span></a>        <span class="n">n_groups</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-135"><a href="#conv2DGroupNormRelu-135"><span class="linenos">135</span></a>    <span class="p">):</span>
</span><span id="conv2DGroupNormRelu-136"><a href="#conv2DGroupNormRelu-136"><span class="linenos">136</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DGroupNormRelu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="conv2DGroupNormRelu-137"><a href="#conv2DGroupNormRelu-137"><span class="linenos">137</span></a>
</span><span id="conv2DGroupNormRelu-138"><a href="#conv2DGroupNormRelu-138"><span class="linenos">138</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="conv2DGroupNormRelu-139"><a href="#conv2DGroupNormRelu-139"><span class="linenos">139</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="conv2DGroupNormRelu-140"><a href="#conv2DGroupNormRelu-140"><span class="linenos">140</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-141"><a href="#conv2DGroupNormRelu-141"><span class="linenos">141</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-142"><a href="#conv2DGroupNormRelu-142"><span class="linenos">142</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-143"><a href="#conv2DGroupNormRelu-143"><span class="linenos">143</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu-144"><a href="#conv2DGroupNormRelu-144"><span class="linenos">144</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="conv2DGroupNormRelu-145"><a href="#conv2DGroupNormRelu-145"><span class="linenos">145</span></a>
</span><span id="conv2DGroupNormRelu-146"><a href="#conv2DGroupNormRelu-146"><span class="linenos">146</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cgr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> 
</span><span id="conv2DGroupNormRelu-147"><a href="#conv2DGroupNormRelu-147"><span class="linenos">147</span></a>                                      <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">n_groups</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span> 
</span><span id="conv2DGroupNormRelu-148"><a href="#conv2DGroupNormRelu-148"><span class="linenos">148</span></a>                                      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="conv2DGroupNormRelu-149"><a href="#conv2DGroupNormRelu-149"><span class="linenos">149</span></a>
</span><span id="conv2DGroupNormRelu-150"><a href="#conv2DGroupNormRelu-150"><span class="linenos">150</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="conv2DGroupNormRelu-151"><a href="#conv2DGroupNormRelu-151"><span class="linenos">151</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cgr_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="conv2DGroupNormRelu-152"><a href="#conv2DGroupNormRelu-152"><span class="linenos">152</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#conv2DGroupNormRelu.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#conv2DGroupNormRelu.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="conv2DGroupNormRelu.__init__" class="classattr">
                                        <input id="conv2DGroupNormRelu.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">conv2DGroupNormRelu</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">in_channels</span>,</span><span class="param">	<span class="n">n_filters</span>,</span><span class="param">	<span class="n">k_size</span>,</span><span class="param">	<span class="n">stride</span>,</span><span class="param">	<span class="n">padding</span>,</span><span class="param">	<span class="n">bias</span><span class="o">=</span><span class="kc">True</span>,</span><span class="param">	<span class="n">dilation</span><span class="o">=</span><span class="mi">1</span>,</span><span class="param">	<span class="n">n_groups</span><span class="o">=</span><span class="mi">16</span></span>)</span>

                <label class="view-source-button" for="conv2DGroupNormRelu.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DGroupNormRelu.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DGroupNormRelu.__init__-125"><a href="#conv2DGroupNormRelu.__init__-125"><span class="linenos">125</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="conv2DGroupNormRelu.__init__-126"><a href="#conv2DGroupNormRelu.__init__-126"><span class="linenos">126</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-127"><a href="#conv2DGroupNormRelu.__init__-127"><span class="linenos">127</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-128"><a href="#conv2DGroupNormRelu.__init__-128"><span class="linenos">128</span></a>        <span class="n">n_filters</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-129"><a href="#conv2DGroupNormRelu.__init__-129"><span class="linenos">129</span></a>        <span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-130"><a href="#conv2DGroupNormRelu.__init__-130"><span class="linenos">130</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-131"><a href="#conv2DGroupNormRelu.__init__-131"><span class="linenos">131</span></a>        <span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-132"><a href="#conv2DGroupNormRelu.__init__-132"><span class="linenos">132</span></a>        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-133"><a href="#conv2DGroupNormRelu.__init__-133"><span class="linenos">133</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-134"><a href="#conv2DGroupNormRelu.__init__-134"><span class="linenos">134</span></a>        <span class="n">n_groups</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-135"><a href="#conv2DGroupNormRelu.__init__-135"><span class="linenos">135</span></a>    <span class="p">):</span>
</span><span id="conv2DGroupNormRelu.__init__-136"><a href="#conv2DGroupNormRelu.__init__-136"><span class="linenos">136</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">conv2DGroupNormRelu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="conv2DGroupNormRelu.__init__-137"><a href="#conv2DGroupNormRelu.__init__-137"><span class="linenos">137</span></a>
</span><span id="conv2DGroupNormRelu.__init__-138"><a href="#conv2DGroupNormRelu.__init__-138"><span class="linenos">138</span></a>        <span class="n">conv_mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="conv2DGroupNormRelu.__init__-139"><a href="#conv2DGroupNormRelu.__init__-139"><span class="linenos">139</span></a>                             <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="conv2DGroupNormRelu.__init__-140"><a href="#conv2DGroupNormRelu.__init__-140"><span class="linenos">140</span></a>                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-141"><a href="#conv2DGroupNormRelu.__init__-141"><span class="linenos">141</span></a>                             <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-142"><a href="#conv2DGroupNormRelu.__init__-142"><span class="linenos">142</span></a>                             <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-143"><a href="#conv2DGroupNormRelu.__init__-143"><span class="linenos">143</span></a>                             <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="conv2DGroupNormRelu.__init__-144"><a href="#conv2DGroupNormRelu.__init__-144"><span class="linenos">144</span></a>                             <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,)</span>
</span><span id="conv2DGroupNormRelu.__init__-145"><a href="#conv2DGroupNormRelu.__init__-145"><span class="linenos">145</span></a>
</span><span id="conv2DGroupNormRelu.__init__-146"><a href="#conv2DGroupNormRelu.__init__-146"><span class="linenos">146</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cgr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv_mod</span><span class="p">,</span> 
</span><span id="conv2DGroupNormRelu.__init__-147"><a href="#conv2DGroupNormRelu.__init__-147"><span class="linenos">147</span></a>                                      <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">n_groups</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span> 
</span><span id="conv2DGroupNormRelu.__init__-148"><a href="#conv2DGroupNormRelu.__init__-148"><span class="linenos">148</span></a>                                      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="conv2DGroupNormRelu.forward" class="classattr">
                                        <input id="conv2DGroupNormRelu.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="conv2DGroupNormRelu.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#conv2DGroupNormRelu.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="conv2DGroupNormRelu.forward-150"><a href="#conv2DGroupNormRelu.forward-150"><span class="linenos">150</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="conv2DGroupNormRelu.forward-151"><a href="#conv2DGroupNormRelu.forward-151"><span class="linenos">151</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cgr_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="conv2DGroupNormRelu.forward-152"><a href="#conv2DGroupNormRelu.forward-152"><span class="linenos">152</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="conv2DGroupNormRelu.dump_patches" class="variable">dump_patches</dd>
                <dd id="conv2DGroupNormRelu.register_buffer" class="function">register_buffer</dd>
                <dd id="conv2DGroupNormRelu.register_parameter" class="function">register_parameter</dd>
                <dd id="conv2DGroupNormRelu.add_module" class="function">add_module</dd>
                <dd id="conv2DGroupNormRelu.register_module" class="function">register_module</dd>
                <dd id="conv2DGroupNormRelu.get_submodule" class="function">get_submodule</dd>
                <dd id="conv2DGroupNormRelu.get_parameter" class="function">get_parameter</dd>
                <dd id="conv2DGroupNormRelu.get_buffer" class="function">get_buffer</dd>
                <dd id="conv2DGroupNormRelu.get_extra_state" class="function">get_extra_state</dd>
                <dd id="conv2DGroupNormRelu.set_extra_state" class="function">set_extra_state</dd>
                <dd id="conv2DGroupNormRelu.apply" class="function">apply</dd>
                <dd id="conv2DGroupNormRelu.cuda" class="function">cuda</dd>
                <dd id="conv2DGroupNormRelu.ipu" class="function">ipu</dd>
                <dd id="conv2DGroupNormRelu.xpu" class="function">xpu</dd>
                <dd id="conv2DGroupNormRelu.cpu" class="function">cpu</dd>
                <dd id="conv2DGroupNormRelu.type" class="function">type</dd>
                <dd id="conv2DGroupNormRelu.float" class="function">float</dd>
                <dd id="conv2DGroupNormRelu.double" class="function">double</dd>
                <dd id="conv2DGroupNormRelu.half" class="function">half</dd>
                <dd id="conv2DGroupNormRelu.bfloat16" class="function">bfloat16</dd>
                <dd id="conv2DGroupNormRelu.to_empty" class="function">to_empty</dd>
                <dd id="conv2DGroupNormRelu.to" class="function">to</dd>
                <dd id="conv2DGroupNormRelu.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="conv2DGroupNormRelu.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="conv2DGroupNormRelu.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="conv2DGroupNormRelu.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="conv2DGroupNormRelu.T_destination" class="variable">T_destination</dd>
                <dd id="conv2DGroupNormRelu.state_dict" class="function">state_dict</dd>
                <dd id="conv2DGroupNormRelu.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="conv2DGroupNormRelu.load_state_dict" class="function">load_state_dict</dd>
                <dd id="conv2DGroupNormRelu.parameters" class="function">parameters</dd>
                <dd id="conv2DGroupNormRelu.named_parameters" class="function">named_parameters</dd>
                <dd id="conv2DGroupNormRelu.buffers" class="function">buffers</dd>
                <dd id="conv2DGroupNormRelu.named_buffers" class="function">named_buffers</dd>
                <dd id="conv2DGroupNormRelu.children" class="function">children</dd>
                <dd id="conv2DGroupNormRelu.named_children" class="function">named_children</dd>
                <dd id="conv2DGroupNormRelu.modules" class="function">modules</dd>
                <dd id="conv2DGroupNormRelu.named_modules" class="function">named_modules</dd>
                <dd id="conv2DGroupNormRelu.train" class="function">train</dd>
                <dd id="conv2DGroupNormRelu.eval" class="function">eval</dd>
                <dd id="conv2DGroupNormRelu.requires_grad_" class="function">requires_grad_</dd>
                <dd id="conv2DGroupNormRelu.zero_grad" class="function">zero_grad</dd>
                <dd id="conv2DGroupNormRelu.share_memory" class="function">share_memory</dd>
                <dd id="conv2DGroupNormRelu.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="deconv2DBatchNormRelu">
                            <input id="deconv2DBatchNormRelu-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">deconv2DBatchNormRelu</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="deconv2DBatchNormRelu-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#deconv2DBatchNormRelu"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="deconv2DBatchNormRelu-156"><a href="#deconv2DBatchNormRelu-156"><span class="linenos">156</span></a><span class="k">class</span> <span class="nc">deconv2DBatchNormRelu</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="deconv2DBatchNormRelu-157"><a href="#deconv2DBatchNormRelu-157"><span class="linenos">157</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="deconv2DBatchNormRelu-158"><a href="#deconv2DBatchNormRelu-158"><span class="linenos">158</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">deconv2DBatchNormRelu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="deconv2DBatchNormRelu-159"><a href="#deconv2DBatchNormRelu-159"><span class="linenos">159</span></a>
</span><span id="deconv2DBatchNormRelu-160"><a href="#deconv2DBatchNormRelu-160"><span class="linenos">160</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dcbr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="deconv2DBatchNormRelu-161"><a href="#deconv2DBatchNormRelu-161"><span class="linenos">161</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span>
</span><span id="deconv2DBatchNormRelu-162"><a href="#deconv2DBatchNormRelu-162"><span class="linenos">162</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="deconv2DBatchNormRelu-163"><a href="#deconv2DBatchNormRelu-163"><span class="linenos">163</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="deconv2DBatchNormRelu-164"><a href="#deconv2DBatchNormRelu-164"><span class="linenos">164</span></a>                <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="deconv2DBatchNormRelu-165"><a href="#deconv2DBatchNormRelu-165"><span class="linenos">165</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="deconv2DBatchNormRelu-166"><a href="#deconv2DBatchNormRelu-166"><span class="linenos">166</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="deconv2DBatchNormRelu-167"><a href="#deconv2DBatchNormRelu-167"><span class="linenos">167</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="deconv2DBatchNormRelu-168"><a href="#deconv2DBatchNormRelu-168"><span class="linenos">168</span></a>            <span class="p">),</span>
</span><span id="deconv2DBatchNormRelu-169"><a href="#deconv2DBatchNormRelu-169"><span class="linenos">169</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span>
</span><span id="deconv2DBatchNormRelu-170"><a href="#deconv2DBatchNormRelu-170"><span class="linenos">170</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="deconv2DBatchNormRelu-171"><a href="#deconv2DBatchNormRelu-171"><span class="linenos">171</span></a>        <span class="p">)</span>
</span><span id="deconv2DBatchNormRelu-172"><a href="#deconv2DBatchNormRelu-172"><span class="linenos">172</span></a>
</span><span id="deconv2DBatchNormRelu-173"><a href="#deconv2DBatchNormRelu-173"><span class="linenos">173</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="deconv2DBatchNormRelu-174"><a href="#deconv2DBatchNormRelu-174"><span class="linenos">174</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dcbr_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="deconv2DBatchNormRelu-175"><a href="#deconv2DBatchNormRelu-175"><span class="linenos">175</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#deconv2DBatchNormRelu.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#deconv2DBatchNormRelu.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="deconv2DBatchNormRelu.__init__" class="classattr">
                                        <input id="deconv2DBatchNormRelu.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">deconv2DBatchNormRelu</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_channels</span>, </span><span class="param"><span class="n">n_filters</span>, </span><span class="param"><span class="n">k_size</span>, </span><span class="param"><span class="n">stride</span>, </span><span class="param"><span class="n">padding</span>, </span><span class="param"><span class="n">bias</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="deconv2DBatchNormRelu.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#deconv2DBatchNormRelu.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="deconv2DBatchNormRelu.__init__-157"><a href="#deconv2DBatchNormRelu.__init__-157"><span class="linenos">157</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="deconv2DBatchNormRelu.__init__-158"><a href="#deconv2DBatchNormRelu.__init__-158"><span class="linenos">158</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">deconv2DBatchNormRelu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="deconv2DBatchNormRelu.__init__-159"><a href="#deconv2DBatchNormRelu.__init__-159"><span class="linenos">159</span></a>
</span><span id="deconv2DBatchNormRelu.__init__-160"><a href="#deconv2DBatchNormRelu.__init__-160"><span class="linenos">160</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dcbr_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="deconv2DBatchNormRelu.__init__-161"><a href="#deconv2DBatchNormRelu.__init__-161"><span class="linenos">161</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span>
</span><span id="deconv2DBatchNormRelu.__init__-162"><a href="#deconv2DBatchNormRelu.__init__-162"><span class="linenos">162</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span>
</span><span id="deconv2DBatchNormRelu.__init__-163"><a href="#deconv2DBatchNormRelu.__init__-163"><span class="linenos">163</span></a>                <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">),</span>
</span><span id="deconv2DBatchNormRelu.__init__-164"><a href="#deconv2DBatchNormRelu.__init__-164"><span class="linenos">164</span></a>                <span class="n">kernel_size</span><span class="o">=</span><span class="n">k_size</span><span class="p">,</span>
</span><span id="deconv2DBatchNormRelu.__init__-165"><a href="#deconv2DBatchNormRelu.__init__-165"><span class="linenos">165</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
</span><span id="deconv2DBatchNormRelu.__init__-166"><a href="#deconv2DBatchNormRelu.__init__-166"><span class="linenos">166</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="deconv2DBatchNormRelu.__init__-167"><a href="#deconv2DBatchNormRelu.__init__-167"><span class="linenos">167</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="deconv2DBatchNormRelu.__init__-168"><a href="#deconv2DBatchNormRelu.__init__-168"><span class="linenos">168</span></a>            <span class="p">),</span>
</span><span id="deconv2DBatchNormRelu.__init__-169"><a href="#deconv2DBatchNormRelu.__init__-169"><span class="linenos">169</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span><span class="p">)),</span>
</span><span id="deconv2DBatchNormRelu.__init__-170"><a href="#deconv2DBatchNormRelu.__init__-170"><span class="linenos">170</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="deconv2DBatchNormRelu.__init__-171"><a href="#deconv2DBatchNormRelu.__init__-171"><span class="linenos">171</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="deconv2DBatchNormRelu.forward" class="classattr">
                                        <input id="deconv2DBatchNormRelu.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="deconv2DBatchNormRelu.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#deconv2DBatchNormRelu.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="deconv2DBatchNormRelu.forward-173"><a href="#deconv2DBatchNormRelu.forward-173"><span class="linenos">173</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="deconv2DBatchNormRelu.forward-174"><a href="#deconv2DBatchNormRelu.forward-174"><span class="linenos">174</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dcbr_unit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="deconv2DBatchNormRelu.forward-175"><a href="#deconv2DBatchNormRelu.forward-175"><span class="linenos">175</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="deconv2DBatchNormRelu.dump_patches" class="variable">dump_patches</dd>
                <dd id="deconv2DBatchNormRelu.register_buffer" class="function">register_buffer</dd>
                <dd id="deconv2DBatchNormRelu.register_parameter" class="function">register_parameter</dd>
                <dd id="deconv2DBatchNormRelu.add_module" class="function">add_module</dd>
                <dd id="deconv2DBatchNormRelu.register_module" class="function">register_module</dd>
                <dd id="deconv2DBatchNormRelu.get_submodule" class="function">get_submodule</dd>
                <dd id="deconv2DBatchNormRelu.get_parameter" class="function">get_parameter</dd>
                <dd id="deconv2DBatchNormRelu.get_buffer" class="function">get_buffer</dd>
                <dd id="deconv2DBatchNormRelu.get_extra_state" class="function">get_extra_state</dd>
                <dd id="deconv2DBatchNormRelu.set_extra_state" class="function">set_extra_state</dd>
                <dd id="deconv2DBatchNormRelu.apply" class="function">apply</dd>
                <dd id="deconv2DBatchNormRelu.cuda" class="function">cuda</dd>
                <dd id="deconv2DBatchNormRelu.ipu" class="function">ipu</dd>
                <dd id="deconv2DBatchNormRelu.xpu" class="function">xpu</dd>
                <dd id="deconv2DBatchNormRelu.cpu" class="function">cpu</dd>
                <dd id="deconv2DBatchNormRelu.type" class="function">type</dd>
                <dd id="deconv2DBatchNormRelu.float" class="function">float</dd>
                <dd id="deconv2DBatchNormRelu.double" class="function">double</dd>
                <dd id="deconv2DBatchNormRelu.half" class="function">half</dd>
                <dd id="deconv2DBatchNormRelu.bfloat16" class="function">bfloat16</dd>
                <dd id="deconv2DBatchNormRelu.to_empty" class="function">to_empty</dd>
                <dd id="deconv2DBatchNormRelu.to" class="function">to</dd>
                <dd id="deconv2DBatchNormRelu.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="deconv2DBatchNormRelu.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="deconv2DBatchNormRelu.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="deconv2DBatchNormRelu.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="deconv2DBatchNormRelu.T_destination" class="variable">T_destination</dd>
                <dd id="deconv2DBatchNormRelu.state_dict" class="function">state_dict</dd>
                <dd id="deconv2DBatchNormRelu.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="deconv2DBatchNormRelu.load_state_dict" class="function">load_state_dict</dd>
                <dd id="deconv2DBatchNormRelu.parameters" class="function">parameters</dd>
                <dd id="deconv2DBatchNormRelu.named_parameters" class="function">named_parameters</dd>
                <dd id="deconv2DBatchNormRelu.buffers" class="function">buffers</dd>
                <dd id="deconv2DBatchNormRelu.named_buffers" class="function">named_buffers</dd>
                <dd id="deconv2DBatchNormRelu.children" class="function">children</dd>
                <dd id="deconv2DBatchNormRelu.named_children" class="function">named_children</dd>
                <dd id="deconv2DBatchNormRelu.modules" class="function">modules</dd>
                <dd id="deconv2DBatchNormRelu.named_modules" class="function">named_modules</dd>
                <dd id="deconv2DBatchNormRelu.train" class="function">train</dd>
                <dd id="deconv2DBatchNormRelu.eval" class="function">eval</dd>
                <dd id="deconv2DBatchNormRelu.requires_grad_" class="function">requires_grad_</dd>
                <dd id="deconv2DBatchNormRelu.zero_grad" class="function">zero_grad</dd>
                <dd id="deconv2DBatchNormRelu.share_memory" class="function">share_memory</dd>
                <dd id="deconv2DBatchNormRelu.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="unetConv2">
                            <input id="unetConv2-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">unetConv2</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="unetConv2-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#unetConv2"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="unetConv2-178"><a href="#unetConv2-178"><span class="linenos">178</span></a><span class="k">class</span> <span class="nc">unetConv2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="unetConv2-179"><a href="#unetConv2-179"><span class="linenos">179</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="p">):</span>
</span><span id="unetConv2-180"><a href="#unetConv2-180"><span class="linenos">180</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">unetConv2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="unetConv2-181"><a href="#unetConv2-181"><span class="linenos">181</span></a>
</span><span id="unetConv2-182"><a href="#unetConv2-182"><span class="linenos">182</span></a>        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
</span><span id="unetConv2-183"><a href="#unetConv2-183"><span class="linenos">183</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="unetConv2-184"><a href="#unetConv2-184"><span class="linenos">184</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="unetConv2-185"><a href="#unetConv2-185"><span class="linenos">185</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">),</span>
</span><span id="unetConv2-186"><a href="#unetConv2-186"><span class="linenos">186</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="unetConv2-187"><a href="#unetConv2-187"><span class="linenos">187</span></a>            <span class="p">)</span>
</span><span id="unetConv2-188"><a href="#unetConv2-188"><span class="linenos">188</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="unetConv2-189"><a href="#unetConv2-189"><span class="linenos">189</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="unetConv2-190"><a href="#unetConv2-190"><span class="linenos">190</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">),</span>
</span><span id="unetConv2-191"><a href="#unetConv2-191"><span class="linenos">191</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="unetConv2-192"><a href="#unetConv2-192"><span class="linenos">192</span></a>            <span class="p">)</span>
</span><span id="unetConv2-193"><a href="#unetConv2-193"><span class="linenos">193</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="unetConv2-194"><a href="#unetConv2-194"><span class="linenos">194</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
</span><span id="unetConv2-195"><a href="#unetConv2-195"><span class="linenos">195</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="unetConv2-196"><a href="#unetConv2-196"><span class="linenos">196</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span><span id="unetConv2-197"><a href="#unetConv2-197"><span class="linenos">197</span></a>            <span class="p">)</span>
</span><span id="unetConv2-198"><a href="#unetConv2-198"><span class="linenos">198</span></a>
</span><span id="unetConv2-199"><a href="#unetConv2-199"><span class="linenos">199</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="unetConv2-200"><a href="#unetConv2-200"><span class="linenos">200</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="unetConv2-201"><a href="#unetConv2-201"><span class="linenos">201</span></a>        <span class="c1">#print (outputs.shape)</span>
</span><span id="unetConv2-202"><a href="#unetConv2-202"><span class="linenos">202</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="unetConv2-203"><a href="#unetConv2-203"><span class="linenos">203</span></a>        <span class="c1">#print (outputs.shape)</span>
</span><span id="unetConv2-204"><a href="#unetConv2-204"><span class="linenos">204</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#unetConv2.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#unetConv2.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="unetConv2.__init__" class="classattr">
                                        <input id="unetConv2.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">unetConv2</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_size</span>, </span><span class="param"><span class="n">out_size</span>, </span><span class="param"><span class="n">is_batchnorm</span></span>)</span>

                <label class="view-source-button" for="unetConv2.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#unetConv2.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="unetConv2.__init__-179"><a href="#unetConv2.__init__-179"><span class="linenos">179</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="p">):</span>
</span><span id="unetConv2.__init__-180"><a href="#unetConv2.__init__-180"><span class="linenos">180</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">unetConv2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="unetConv2.__init__-181"><a href="#unetConv2.__init__-181"><span class="linenos">181</span></a>
</span><span id="unetConv2.__init__-182"><a href="#unetConv2.__init__-182"><span class="linenos">182</span></a>        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
</span><span id="unetConv2.__init__-183"><a href="#unetConv2.__init__-183"><span class="linenos">183</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="unetConv2.__init__-184"><a href="#unetConv2.__init__-184"><span class="linenos">184</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="unetConv2.__init__-185"><a href="#unetConv2.__init__-185"><span class="linenos">185</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">),</span>
</span><span id="unetConv2.__init__-186"><a href="#unetConv2.__init__-186"><span class="linenos">186</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="unetConv2.__init__-187"><a href="#unetConv2.__init__-187"><span class="linenos">187</span></a>            <span class="p">)</span>
</span><span id="unetConv2.__init__-188"><a href="#unetConv2.__init__-188"><span class="linenos">188</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="unetConv2.__init__-189"><a href="#unetConv2.__init__-189"><span class="linenos">189</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="unetConv2.__init__-190"><a href="#unetConv2.__init__-190"><span class="linenos">190</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">),</span>
</span><span id="unetConv2.__init__-191"><a href="#unetConv2.__init__-191"><span class="linenos">191</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="unetConv2.__init__-192"><a href="#unetConv2.__init__-192"><span class="linenos">192</span></a>            <span class="p">)</span>
</span><span id="unetConv2.__init__-193"><a href="#unetConv2.__init__-193"><span class="linenos">193</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="unetConv2.__init__-194"><a href="#unetConv2.__init__-194"><span class="linenos">194</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
</span><span id="unetConv2.__init__-195"><a href="#unetConv2.__init__-195"><span class="linenos">195</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="unetConv2.__init__-196"><a href="#unetConv2.__init__-196"><span class="linenos">196</span></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span><span id="unetConv2.__init__-197"><a href="#unetConv2.__init__-197"><span class="linenos">197</span></a>            <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="unetConv2.forward" class="classattr">
                                        <input id="unetConv2.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="unetConv2.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#unetConv2.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="unetConv2.forward-199"><a href="#unetConv2.forward-199"><span class="linenos">199</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="unetConv2.forward-200"><a href="#unetConv2.forward-200"><span class="linenos">200</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="unetConv2.forward-201"><a href="#unetConv2.forward-201"><span class="linenos">201</span></a>        <span class="c1">#print (outputs.shape)</span>
</span><span id="unetConv2.forward-202"><a href="#unetConv2.forward-202"><span class="linenos">202</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="unetConv2.forward-203"><a href="#unetConv2.forward-203"><span class="linenos">203</span></a>        <span class="c1">#print (outputs.shape)</span>
</span><span id="unetConv2.forward-204"><a href="#unetConv2.forward-204"><span class="linenos">204</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="unetConv2.dump_patches" class="variable">dump_patches</dd>
                <dd id="unetConv2.register_buffer" class="function">register_buffer</dd>
                <dd id="unetConv2.register_parameter" class="function">register_parameter</dd>
                <dd id="unetConv2.add_module" class="function">add_module</dd>
                <dd id="unetConv2.register_module" class="function">register_module</dd>
                <dd id="unetConv2.get_submodule" class="function">get_submodule</dd>
                <dd id="unetConv2.get_parameter" class="function">get_parameter</dd>
                <dd id="unetConv2.get_buffer" class="function">get_buffer</dd>
                <dd id="unetConv2.get_extra_state" class="function">get_extra_state</dd>
                <dd id="unetConv2.set_extra_state" class="function">set_extra_state</dd>
                <dd id="unetConv2.apply" class="function">apply</dd>
                <dd id="unetConv2.cuda" class="function">cuda</dd>
                <dd id="unetConv2.ipu" class="function">ipu</dd>
                <dd id="unetConv2.xpu" class="function">xpu</dd>
                <dd id="unetConv2.cpu" class="function">cpu</dd>
                <dd id="unetConv2.type" class="function">type</dd>
                <dd id="unetConv2.float" class="function">float</dd>
                <dd id="unetConv2.double" class="function">double</dd>
                <dd id="unetConv2.half" class="function">half</dd>
                <dd id="unetConv2.bfloat16" class="function">bfloat16</dd>
                <dd id="unetConv2.to_empty" class="function">to_empty</dd>
                <dd id="unetConv2.to" class="function">to</dd>
                <dd id="unetConv2.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="unetConv2.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="unetConv2.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="unetConv2.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="unetConv2.T_destination" class="variable">T_destination</dd>
                <dd id="unetConv2.state_dict" class="function">state_dict</dd>
                <dd id="unetConv2.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="unetConv2.load_state_dict" class="function">load_state_dict</dd>
                <dd id="unetConv2.parameters" class="function">parameters</dd>
                <dd id="unetConv2.named_parameters" class="function">named_parameters</dd>
                <dd id="unetConv2.buffers" class="function">buffers</dd>
                <dd id="unetConv2.named_buffers" class="function">named_buffers</dd>
                <dd id="unetConv2.children" class="function">children</dd>
                <dd id="unetConv2.named_children" class="function">named_children</dd>
                <dd id="unetConv2.modules" class="function">modules</dd>
                <dd id="unetConv2.named_modules" class="function">named_modules</dd>
                <dd id="unetConv2.train" class="function">train</dd>
                <dd id="unetConv2.eval" class="function">eval</dd>
                <dd id="unetConv2.requires_grad_" class="function">requires_grad_</dd>
                <dd id="unetConv2.zero_grad" class="function">zero_grad</dd>
                <dd id="unetConv2.share_memory" class="function">share_memory</dd>
                <dd id="unetConv2.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="unetUp">
                            <input id="unetUp-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">unetUp</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="unetUp-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#unetUp"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="unetUp-207"><a href="#unetUp-207"><span class="linenos">207</span></a><span class="k">class</span> <span class="nc">unetUp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="unetUp-208"><a href="#unetUp-208"><span class="linenos">208</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">is_deconv</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="p">):</span>
</span><span id="unetUp-209"><a href="#unetUp-209"><span class="linenos">209</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">unetUp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="unetUp-210"><a href="#unetUp-210"><span class="linenos">210</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">unetConv2</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="p">)</span>
</span><span id="unetUp-211"><a href="#unetUp-211"><span class="linenos">211</span></a>        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
</span><span id="unetUp-212"><a href="#unetUp-212"><span class="linenos">212</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="unetUp-213"><a href="#unetUp-213"><span class="linenos">213</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="unetUp-214"><a href="#unetUp-214"><span class="linenos">214</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UpsamplingBilinear2d</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="unetUp-215"><a href="#unetUp-215"><span class="linenos">215</span></a>
</span><span id="unetUp-216"><a href="#unetUp-216"><span class="linenos">216</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs1</span><span class="p">,</span> <span class="n">inputs2</span><span class="p">):</span>
</span><span id="unetUp-217"><a href="#unetUp-217"><span class="linenos">217</span></a>        <span class="n">outputs2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up</span><span class="p">(</span><span class="n">inputs2</span><span class="p">)</span>
</span><span id="unetUp-218"><a href="#unetUp-218"><span class="linenos">218</span></a>        <span class="n">offset</span> <span class="o">=</span> <span class="n">outputs2</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">inputs1</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span>
</span><span id="unetUp-219"><a href="#unetUp-219"><span class="linenos">219</span></a>        <span class="n">padding</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">[</span><span class="n">offset</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">offset</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>           
</span><span id="unetUp-220"><a href="#unetUp-220"><span class="linenos">220</span></a>        <span class="n">outputs1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
</span><span id="unetUp-221"><a href="#unetUp-221"><span class="linenos">221</span></a>               
</span><span id="unetUp-222"><a href="#unetUp-222"><span class="linenos">222</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">outputs1</span><span class="p">,</span> <span class="n">outputs2</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#unetUp.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#unetUp.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="unetUp.__init__" class="classattr">
                                        <input id="unetUp.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">unetUp</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_size</span>, </span><span class="param"><span class="n">out_size</span>, </span><span class="param"><span class="n">is_deconv</span>, </span><span class="param"><span class="n">is_batchnorm</span></span>)</span>

                <label class="view-source-button" for="unetUp.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#unetUp.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="unetUp.__init__-208"><a href="#unetUp.__init__-208"><span class="linenos">208</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">is_deconv</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="p">):</span>
</span><span id="unetUp.__init__-209"><a href="#unetUp.__init__-209"><span class="linenos">209</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">unetUp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="unetUp.__init__-210"><a href="#unetUp.__init__-210"><span class="linenos">210</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">unetConv2</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="p">)</span>
</span><span id="unetUp.__init__-211"><a href="#unetUp.__init__-211"><span class="linenos">211</span></a>        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
</span><span id="unetUp.__init__-212"><a href="#unetUp.__init__-212"><span class="linenos">212</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="unetUp.__init__-213"><a href="#unetUp.__init__-213"><span class="linenos">213</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="unetUp.__init__-214"><a href="#unetUp.__init__-214"><span class="linenos">214</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UpsamplingBilinear2d</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="unetUp.forward" class="classattr">
                                        <input id="unetUp.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs1</span>, </span><span class="param"><span class="n">inputs2</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="unetUp.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#unetUp.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="unetUp.forward-216"><a href="#unetUp.forward-216"><span class="linenos">216</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs1</span><span class="p">,</span> <span class="n">inputs2</span><span class="p">):</span>
</span><span id="unetUp.forward-217"><a href="#unetUp.forward-217"><span class="linenos">217</span></a>        <span class="n">outputs2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up</span><span class="p">(</span><span class="n">inputs2</span><span class="p">)</span>
</span><span id="unetUp.forward-218"><a href="#unetUp.forward-218"><span class="linenos">218</span></a>        <span class="n">offset</span> <span class="o">=</span> <span class="n">outputs2</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">inputs1</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span>
</span><span id="unetUp.forward-219"><a href="#unetUp.forward-219"><span class="linenos">219</span></a>        <span class="n">padding</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">[</span><span class="n">offset</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">offset</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>           
</span><span id="unetUp.forward-220"><a href="#unetUp.forward-220"><span class="linenos">220</span></a>        <span class="n">outputs1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
</span><span id="unetUp.forward-221"><a href="#unetUp.forward-221"><span class="linenos">221</span></a>               
</span><span id="unetUp.forward-222"><a href="#unetUp.forward-222"><span class="linenos">222</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">outputs1</span><span class="p">,</span> <span class="n">outputs2</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="unetUp.dump_patches" class="variable">dump_patches</dd>
                <dd id="unetUp.register_buffer" class="function">register_buffer</dd>
                <dd id="unetUp.register_parameter" class="function">register_parameter</dd>
                <dd id="unetUp.add_module" class="function">add_module</dd>
                <dd id="unetUp.register_module" class="function">register_module</dd>
                <dd id="unetUp.get_submodule" class="function">get_submodule</dd>
                <dd id="unetUp.get_parameter" class="function">get_parameter</dd>
                <dd id="unetUp.get_buffer" class="function">get_buffer</dd>
                <dd id="unetUp.get_extra_state" class="function">get_extra_state</dd>
                <dd id="unetUp.set_extra_state" class="function">set_extra_state</dd>
                <dd id="unetUp.apply" class="function">apply</dd>
                <dd id="unetUp.cuda" class="function">cuda</dd>
                <dd id="unetUp.ipu" class="function">ipu</dd>
                <dd id="unetUp.xpu" class="function">xpu</dd>
                <dd id="unetUp.cpu" class="function">cpu</dd>
                <dd id="unetUp.type" class="function">type</dd>
                <dd id="unetUp.float" class="function">float</dd>
                <dd id="unetUp.double" class="function">double</dd>
                <dd id="unetUp.half" class="function">half</dd>
                <dd id="unetUp.bfloat16" class="function">bfloat16</dd>
                <dd id="unetUp.to_empty" class="function">to_empty</dd>
                <dd id="unetUp.to" class="function">to</dd>
                <dd id="unetUp.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="unetUp.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="unetUp.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="unetUp.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="unetUp.T_destination" class="variable">T_destination</dd>
                <dd id="unetUp.state_dict" class="function">state_dict</dd>
                <dd id="unetUp.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="unetUp.load_state_dict" class="function">load_state_dict</dd>
                <dd id="unetUp.parameters" class="function">parameters</dd>
                <dd id="unetUp.named_parameters" class="function">named_parameters</dd>
                <dd id="unetUp.buffers" class="function">buffers</dd>
                <dd id="unetUp.named_buffers" class="function">named_buffers</dd>
                <dd id="unetUp.children" class="function">children</dd>
                <dd id="unetUp.named_children" class="function">named_children</dd>
                <dd id="unetUp.modules" class="function">modules</dd>
                <dd id="unetUp.named_modules" class="function">named_modules</dd>
                <dd id="unetUp.train" class="function">train</dd>
                <dd id="unetUp.eval" class="function">eval</dd>
                <dd id="unetUp.requires_grad_" class="function">requires_grad_</dd>
                <dd id="unetUp.zero_grad" class="function">zero_grad</dd>
                <dd id="unetUp.share_memory" class="function">share_memory</dd>
                <dd id="unetUp.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="segnetDown2">
                            <input id="segnetDown2-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">segnetDown2</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="segnetDown2-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetDown2"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetDown2-225"><a href="#segnetDown2-225"><span class="linenos">225</span></a><span class="k">class</span> <span class="nc">segnetDown2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="segnetDown2-226"><a href="#segnetDown2-226"><span class="linenos">226</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="segnetDown2-227"><a href="#segnetDown2-227"><span class="linenos">227</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetDown2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="segnetDown2-228"><a href="#segnetDown2-228"><span class="linenos">228</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown2-229"><a href="#segnetDown2-229"><span class="linenos">229</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown2-230"><a href="#segnetDown2-230"><span class="linenos">230</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="segnetDown2-231"><a href="#segnetDown2-231"><span class="linenos">231</span></a>
</span><span id="segnetDown2-232"><a href="#segnetDown2-232"><span class="linenos">232</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="segnetDown2-233"><a href="#segnetDown2-233"><span class="linenos">233</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="segnetDown2-234"><a href="#segnetDown2-234"><span class="linenos">234</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown2-235"><a href="#segnetDown2-235"><span class="linenos">235</span></a>        <span class="n">unpooled_shape</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="segnetDown2-236"><a href="#segnetDown2-236"><span class="linenos">236</span></a>        <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown2-237"><a href="#segnetDown2-237"><span class="linenos">237</span></a>        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">unpooled_shape</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#segnetDown2.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#segnetDown2.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="segnetDown2.__init__" class="classattr">
                                        <input id="segnetDown2.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">segnetDown2</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_size</span>, </span><span class="param"><span class="n">out_size</span></span>)</span>

                <label class="view-source-button" for="segnetDown2.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetDown2.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetDown2.__init__-226"><a href="#segnetDown2.__init__-226"><span class="linenos">226</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="segnetDown2.__init__-227"><a href="#segnetDown2.__init__-227"><span class="linenos">227</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetDown2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="segnetDown2.__init__-228"><a href="#segnetDown2.__init__-228"><span class="linenos">228</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown2.__init__-229"><a href="#segnetDown2.__init__-229"><span class="linenos">229</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown2.__init__-230"><a href="#segnetDown2.__init__-230"><span class="linenos">230</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="segnetDown2.forward" class="classattr">
                                        <input id="segnetDown2.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="segnetDown2.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetDown2.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetDown2.forward-232"><a href="#segnetDown2.forward-232"><span class="linenos">232</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="segnetDown2.forward-233"><a href="#segnetDown2.forward-233"><span class="linenos">233</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="segnetDown2.forward-234"><a href="#segnetDown2.forward-234"><span class="linenos">234</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown2.forward-235"><a href="#segnetDown2.forward-235"><span class="linenos">235</span></a>        <span class="n">unpooled_shape</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="segnetDown2.forward-236"><a href="#segnetDown2.forward-236"><span class="linenos">236</span></a>        <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown2.forward-237"><a href="#segnetDown2.forward-237"><span class="linenos">237</span></a>        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">unpooled_shape</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="segnetDown2.dump_patches" class="variable">dump_patches</dd>
                <dd id="segnetDown2.register_buffer" class="function">register_buffer</dd>
                <dd id="segnetDown2.register_parameter" class="function">register_parameter</dd>
                <dd id="segnetDown2.add_module" class="function">add_module</dd>
                <dd id="segnetDown2.register_module" class="function">register_module</dd>
                <dd id="segnetDown2.get_submodule" class="function">get_submodule</dd>
                <dd id="segnetDown2.get_parameter" class="function">get_parameter</dd>
                <dd id="segnetDown2.get_buffer" class="function">get_buffer</dd>
                <dd id="segnetDown2.get_extra_state" class="function">get_extra_state</dd>
                <dd id="segnetDown2.set_extra_state" class="function">set_extra_state</dd>
                <dd id="segnetDown2.apply" class="function">apply</dd>
                <dd id="segnetDown2.cuda" class="function">cuda</dd>
                <dd id="segnetDown2.ipu" class="function">ipu</dd>
                <dd id="segnetDown2.xpu" class="function">xpu</dd>
                <dd id="segnetDown2.cpu" class="function">cpu</dd>
                <dd id="segnetDown2.type" class="function">type</dd>
                <dd id="segnetDown2.float" class="function">float</dd>
                <dd id="segnetDown2.double" class="function">double</dd>
                <dd id="segnetDown2.half" class="function">half</dd>
                <dd id="segnetDown2.bfloat16" class="function">bfloat16</dd>
                <dd id="segnetDown2.to_empty" class="function">to_empty</dd>
                <dd id="segnetDown2.to" class="function">to</dd>
                <dd id="segnetDown2.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="segnetDown2.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="segnetDown2.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="segnetDown2.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="segnetDown2.T_destination" class="variable">T_destination</dd>
                <dd id="segnetDown2.state_dict" class="function">state_dict</dd>
                <dd id="segnetDown2.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="segnetDown2.load_state_dict" class="function">load_state_dict</dd>
                <dd id="segnetDown2.parameters" class="function">parameters</dd>
                <dd id="segnetDown2.named_parameters" class="function">named_parameters</dd>
                <dd id="segnetDown2.buffers" class="function">buffers</dd>
                <dd id="segnetDown2.named_buffers" class="function">named_buffers</dd>
                <dd id="segnetDown2.children" class="function">children</dd>
                <dd id="segnetDown2.named_children" class="function">named_children</dd>
                <dd id="segnetDown2.modules" class="function">modules</dd>
                <dd id="segnetDown2.named_modules" class="function">named_modules</dd>
                <dd id="segnetDown2.train" class="function">train</dd>
                <dd id="segnetDown2.eval" class="function">eval</dd>
                <dd id="segnetDown2.requires_grad_" class="function">requires_grad_</dd>
                <dd id="segnetDown2.zero_grad" class="function">zero_grad</dd>
                <dd id="segnetDown2.share_memory" class="function">share_memory</dd>
                <dd id="segnetDown2.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="segnetDown3">
                            <input id="segnetDown3-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">segnetDown3</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="segnetDown3-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetDown3"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetDown3-240"><a href="#segnetDown3-240"><span class="linenos">240</span></a><span class="k">class</span> <span class="nc">segnetDown3</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="segnetDown3-241"><a href="#segnetDown3-241"><span class="linenos">241</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="segnetDown3-242"><a href="#segnetDown3-242"><span class="linenos">242</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetDown3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="segnetDown3-243"><a href="#segnetDown3-243"><span class="linenos">243</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown3-244"><a href="#segnetDown3-244"><span class="linenos">244</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown3-245"><a href="#segnetDown3-245"><span class="linenos">245</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown3-246"><a href="#segnetDown3-246"><span class="linenos">246</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="segnetDown3-247"><a href="#segnetDown3-247"><span class="linenos">247</span></a>
</span><span id="segnetDown3-248"><a href="#segnetDown3-248"><span class="linenos">248</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="segnetDown3-249"><a href="#segnetDown3-249"><span class="linenos">249</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="segnetDown3-250"><a href="#segnetDown3-250"><span class="linenos">250</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown3-251"><a href="#segnetDown3-251"><span class="linenos">251</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown3-252"><a href="#segnetDown3-252"><span class="linenos">252</span></a>        <span class="n">unpooled_shape</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="segnetDown3-253"><a href="#segnetDown3-253"><span class="linenos">253</span></a>        <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown3-254"><a href="#segnetDown3-254"><span class="linenos">254</span></a>        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">unpooled_shape</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#segnetDown3.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#segnetDown3.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="segnetDown3.__init__" class="classattr">
                                        <input id="segnetDown3.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">segnetDown3</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_size</span>, </span><span class="param"><span class="n">out_size</span></span>)</span>

                <label class="view-source-button" for="segnetDown3.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetDown3.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetDown3.__init__-241"><a href="#segnetDown3.__init__-241"><span class="linenos">241</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="segnetDown3.__init__-242"><a href="#segnetDown3.__init__-242"><span class="linenos">242</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetDown3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="segnetDown3.__init__-243"><a href="#segnetDown3.__init__-243"><span class="linenos">243</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown3.__init__-244"><a href="#segnetDown3.__init__-244"><span class="linenos">244</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown3.__init__-245"><a href="#segnetDown3.__init__-245"><span class="linenos">245</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetDown3.__init__-246"><a href="#segnetDown3.__init__-246"><span class="linenos">246</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="segnetDown3.forward" class="classattr">
                                        <input id="segnetDown3.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="segnetDown3.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetDown3.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetDown3.forward-248"><a href="#segnetDown3.forward-248"><span class="linenos">248</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="segnetDown3.forward-249"><a href="#segnetDown3.forward-249"><span class="linenos">249</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="segnetDown3.forward-250"><a href="#segnetDown3.forward-250"><span class="linenos">250</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown3.forward-251"><a href="#segnetDown3.forward-251"><span class="linenos">251</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown3.forward-252"><a href="#segnetDown3.forward-252"><span class="linenos">252</span></a>        <span class="n">unpooled_shape</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="segnetDown3.forward-253"><a href="#segnetDown3.forward-253"><span class="linenos">253</span></a>        <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_with_argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetDown3.forward-254"><a href="#segnetDown3.forward-254"><span class="linenos">254</span></a>        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">unpooled_shape</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="segnetDown3.dump_patches" class="variable">dump_patches</dd>
                <dd id="segnetDown3.register_buffer" class="function">register_buffer</dd>
                <dd id="segnetDown3.register_parameter" class="function">register_parameter</dd>
                <dd id="segnetDown3.add_module" class="function">add_module</dd>
                <dd id="segnetDown3.register_module" class="function">register_module</dd>
                <dd id="segnetDown3.get_submodule" class="function">get_submodule</dd>
                <dd id="segnetDown3.get_parameter" class="function">get_parameter</dd>
                <dd id="segnetDown3.get_buffer" class="function">get_buffer</dd>
                <dd id="segnetDown3.get_extra_state" class="function">get_extra_state</dd>
                <dd id="segnetDown3.set_extra_state" class="function">set_extra_state</dd>
                <dd id="segnetDown3.apply" class="function">apply</dd>
                <dd id="segnetDown3.cuda" class="function">cuda</dd>
                <dd id="segnetDown3.ipu" class="function">ipu</dd>
                <dd id="segnetDown3.xpu" class="function">xpu</dd>
                <dd id="segnetDown3.cpu" class="function">cpu</dd>
                <dd id="segnetDown3.type" class="function">type</dd>
                <dd id="segnetDown3.float" class="function">float</dd>
                <dd id="segnetDown3.double" class="function">double</dd>
                <dd id="segnetDown3.half" class="function">half</dd>
                <dd id="segnetDown3.bfloat16" class="function">bfloat16</dd>
                <dd id="segnetDown3.to_empty" class="function">to_empty</dd>
                <dd id="segnetDown3.to" class="function">to</dd>
                <dd id="segnetDown3.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="segnetDown3.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="segnetDown3.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="segnetDown3.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="segnetDown3.T_destination" class="variable">T_destination</dd>
                <dd id="segnetDown3.state_dict" class="function">state_dict</dd>
                <dd id="segnetDown3.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="segnetDown3.load_state_dict" class="function">load_state_dict</dd>
                <dd id="segnetDown3.parameters" class="function">parameters</dd>
                <dd id="segnetDown3.named_parameters" class="function">named_parameters</dd>
                <dd id="segnetDown3.buffers" class="function">buffers</dd>
                <dd id="segnetDown3.named_buffers" class="function">named_buffers</dd>
                <dd id="segnetDown3.children" class="function">children</dd>
                <dd id="segnetDown3.named_children" class="function">named_children</dd>
                <dd id="segnetDown3.modules" class="function">modules</dd>
                <dd id="segnetDown3.named_modules" class="function">named_modules</dd>
                <dd id="segnetDown3.train" class="function">train</dd>
                <dd id="segnetDown3.eval" class="function">eval</dd>
                <dd id="segnetDown3.requires_grad_" class="function">requires_grad_</dd>
                <dd id="segnetDown3.zero_grad" class="function">zero_grad</dd>
                <dd id="segnetDown3.share_memory" class="function">share_memory</dd>
                <dd id="segnetDown3.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="segnetUp2">
                            <input id="segnetUp2-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">segnetUp2</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="segnetUp2-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetUp2"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetUp2-257"><a href="#segnetUp2-257"><span class="linenos">257</span></a><span class="k">class</span> <span class="nc">segnetUp2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="segnetUp2-258"><a href="#segnetUp2-258"><span class="linenos">258</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="segnetUp2-259"><a href="#segnetUp2-259"><span class="linenos">259</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetUp2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="segnetUp2-260"><a href="#segnetUp2-260"><span class="linenos">260</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxUnpool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="segnetUp2-261"><a href="#segnetUp2-261"><span class="linenos">261</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetUp2-262"><a href="#segnetUp2-262"><span class="linenos">262</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetUp2-263"><a href="#segnetUp2-263"><span class="linenos">263</span></a>
</span><span id="segnetUp2-264"><a href="#segnetUp2-264"><span class="linenos">264</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">):</span>
</span><span id="segnetUp2-265"><a href="#segnetUp2-265"><span class="linenos">265</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span>
</span><span id="segnetUp2-266"><a href="#segnetUp2-266"><span class="linenos">266</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp2-267"><a href="#segnetUp2-267"><span class="linenos">267</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp2-268"><a href="#segnetUp2-268"><span class="linenos">268</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#segnetUp2.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#segnetUp2.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="segnetUp2.__init__" class="classattr">
                                        <input id="segnetUp2.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">segnetUp2</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_size</span>, </span><span class="param"><span class="n">out_size</span></span>)</span>

                <label class="view-source-button" for="segnetUp2.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetUp2.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetUp2.__init__-258"><a href="#segnetUp2.__init__-258"><span class="linenos">258</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="segnetUp2.__init__-259"><a href="#segnetUp2.__init__-259"><span class="linenos">259</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetUp2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="segnetUp2.__init__-260"><a href="#segnetUp2.__init__-260"><span class="linenos">260</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxUnpool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="segnetUp2.__init__-261"><a href="#segnetUp2.__init__-261"><span class="linenos">261</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetUp2.__init__-262"><a href="#segnetUp2.__init__-262"><span class="linenos">262</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="segnetUp2.forward" class="classattr">
                                        <input id="segnetUp2.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span>, </span><span class="param"><span class="n">indices</span>, </span><span class="param"><span class="n">output_shape</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="segnetUp2.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetUp2.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetUp2.forward-264"><a href="#segnetUp2.forward-264"><span class="linenos">264</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">):</span>
</span><span id="segnetUp2.forward-265"><a href="#segnetUp2.forward-265"><span class="linenos">265</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span>
</span><span id="segnetUp2.forward-266"><a href="#segnetUp2.forward-266"><span class="linenos">266</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp2.forward-267"><a href="#segnetUp2.forward-267"><span class="linenos">267</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp2.forward-268"><a href="#segnetUp2.forward-268"><span class="linenos">268</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="segnetUp2.dump_patches" class="variable">dump_patches</dd>
                <dd id="segnetUp2.register_buffer" class="function">register_buffer</dd>
                <dd id="segnetUp2.register_parameter" class="function">register_parameter</dd>
                <dd id="segnetUp2.add_module" class="function">add_module</dd>
                <dd id="segnetUp2.register_module" class="function">register_module</dd>
                <dd id="segnetUp2.get_submodule" class="function">get_submodule</dd>
                <dd id="segnetUp2.get_parameter" class="function">get_parameter</dd>
                <dd id="segnetUp2.get_buffer" class="function">get_buffer</dd>
                <dd id="segnetUp2.get_extra_state" class="function">get_extra_state</dd>
                <dd id="segnetUp2.set_extra_state" class="function">set_extra_state</dd>
                <dd id="segnetUp2.apply" class="function">apply</dd>
                <dd id="segnetUp2.cuda" class="function">cuda</dd>
                <dd id="segnetUp2.ipu" class="function">ipu</dd>
                <dd id="segnetUp2.xpu" class="function">xpu</dd>
                <dd id="segnetUp2.cpu" class="function">cpu</dd>
                <dd id="segnetUp2.type" class="function">type</dd>
                <dd id="segnetUp2.float" class="function">float</dd>
                <dd id="segnetUp2.double" class="function">double</dd>
                <dd id="segnetUp2.half" class="function">half</dd>
                <dd id="segnetUp2.bfloat16" class="function">bfloat16</dd>
                <dd id="segnetUp2.to_empty" class="function">to_empty</dd>
                <dd id="segnetUp2.to" class="function">to</dd>
                <dd id="segnetUp2.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="segnetUp2.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="segnetUp2.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="segnetUp2.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="segnetUp2.T_destination" class="variable">T_destination</dd>
                <dd id="segnetUp2.state_dict" class="function">state_dict</dd>
                <dd id="segnetUp2.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="segnetUp2.load_state_dict" class="function">load_state_dict</dd>
                <dd id="segnetUp2.parameters" class="function">parameters</dd>
                <dd id="segnetUp2.named_parameters" class="function">named_parameters</dd>
                <dd id="segnetUp2.buffers" class="function">buffers</dd>
                <dd id="segnetUp2.named_buffers" class="function">named_buffers</dd>
                <dd id="segnetUp2.children" class="function">children</dd>
                <dd id="segnetUp2.named_children" class="function">named_children</dd>
                <dd id="segnetUp2.modules" class="function">modules</dd>
                <dd id="segnetUp2.named_modules" class="function">named_modules</dd>
                <dd id="segnetUp2.train" class="function">train</dd>
                <dd id="segnetUp2.eval" class="function">eval</dd>
                <dd id="segnetUp2.requires_grad_" class="function">requires_grad_</dd>
                <dd id="segnetUp2.zero_grad" class="function">zero_grad</dd>
                <dd id="segnetUp2.share_memory" class="function">share_memory</dd>
                <dd id="segnetUp2.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="segnetUp3">
                            <input id="segnetUp3-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">segnetUp3</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="segnetUp3-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetUp3"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetUp3-271"><a href="#segnetUp3-271"><span class="linenos">271</span></a><span class="k">class</span> <span class="nc">segnetUp3</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="segnetUp3-272"><a href="#segnetUp3-272"><span class="linenos">272</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="segnetUp3-273"><a href="#segnetUp3-273"><span class="linenos">273</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetUp3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="segnetUp3-274"><a href="#segnetUp3-274"><span class="linenos">274</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxUnpool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="segnetUp3-275"><a href="#segnetUp3-275"><span class="linenos">275</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetUp3-276"><a href="#segnetUp3-276"><span class="linenos">276</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetUp3-277"><a href="#segnetUp3-277"><span class="linenos">277</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetUp3-278"><a href="#segnetUp3-278"><span class="linenos">278</span></a>
</span><span id="segnetUp3-279"><a href="#segnetUp3-279"><span class="linenos">279</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">):</span>
</span><span id="segnetUp3-280"><a href="#segnetUp3-280"><span class="linenos">280</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span>
</span><span id="segnetUp3-281"><a href="#segnetUp3-281"><span class="linenos">281</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp3-282"><a href="#segnetUp3-282"><span class="linenos">282</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp3-283"><a href="#segnetUp3-283"><span class="linenos">283</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp3-284"><a href="#segnetUp3-284"><span class="linenos">284</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#segnetUp3.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#segnetUp3.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="segnetUp3.__init__" class="classattr">
                                        <input id="segnetUp3.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">segnetUp3</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_size</span>, </span><span class="param"><span class="n">out_size</span></span>)</span>

                <label class="view-source-button" for="segnetUp3.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetUp3.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetUp3.__init__-272"><a href="#segnetUp3.__init__-272"><span class="linenos">272</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
</span><span id="segnetUp3.__init__-273"><a href="#segnetUp3.__init__-273"><span class="linenos">273</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">segnetUp3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="segnetUp3.__init__-274"><a href="#segnetUp3.__init__-274"><span class="linenos">274</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxUnpool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="segnetUp3.__init__-275"><a href="#segnetUp3.__init__-275"><span class="linenos">275</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetUp3.__init__-276"><a href="#segnetUp3.__init__-276"><span class="linenos">276</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="segnetUp3.__init__-277"><a href="#segnetUp3.__init__-277"><span class="linenos">277</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="segnetUp3.forward" class="classattr">
                                        <input id="segnetUp3.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span>, </span><span class="param"><span class="n">indices</span>, </span><span class="param"><span class="n">output_shape</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="segnetUp3.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#segnetUp3.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="segnetUp3.forward-279"><a href="#segnetUp3.forward-279"><span class="linenos">279</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">):</span>
</span><span id="segnetUp3.forward-280"><a href="#segnetUp3.forward-280"><span class="linenos">280</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unpool</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span>
</span><span id="segnetUp3.forward-281"><a href="#segnetUp3.forward-281"><span class="linenos">281</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp3.forward-282"><a href="#segnetUp3.forward-282"><span class="linenos">282</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp3.forward-283"><a href="#segnetUp3.forward-283"><span class="linenos">283</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="segnetUp3.forward-284"><a href="#segnetUp3.forward-284"><span class="linenos">284</span></a>        <span class="k">return</span> <span class="n">outputs</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="segnetUp3.dump_patches" class="variable">dump_patches</dd>
                <dd id="segnetUp3.register_buffer" class="function">register_buffer</dd>
                <dd id="segnetUp3.register_parameter" class="function">register_parameter</dd>
                <dd id="segnetUp3.add_module" class="function">add_module</dd>
                <dd id="segnetUp3.register_module" class="function">register_module</dd>
                <dd id="segnetUp3.get_submodule" class="function">get_submodule</dd>
                <dd id="segnetUp3.get_parameter" class="function">get_parameter</dd>
                <dd id="segnetUp3.get_buffer" class="function">get_buffer</dd>
                <dd id="segnetUp3.get_extra_state" class="function">get_extra_state</dd>
                <dd id="segnetUp3.set_extra_state" class="function">set_extra_state</dd>
                <dd id="segnetUp3.apply" class="function">apply</dd>
                <dd id="segnetUp3.cuda" class="function">cuda</dd>
                <dd id="segnetUp3.ipu" class="function">ipu</dd>
                <dd id="segnetUp3.xpu" class="function">xpu</dd>
                <dd id="segnetUp3.cpu" class="function">cpu</dd>
                <dd id="segnetUp3.type" class="function">type</dd>
                <dd id="segnetUp3.float" class="function">float</dd>
                <dd id="segnetUp3.double" class="function">double</dd>
                <dd id="segnetUp3.half" class="function">half</dd>
                <dd id="segnetUp3.bfloat16" class="function">bfloat16</dd>
                <dd id="segnetUp3.to_empty" class="function">to_empty</dd>
                <dd id="segnetUp3.to" class="function">to</dd>
                <dd id="segnetUp3.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="segnetUp3.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="segnetUp3.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="segnetUp3.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="segnetUp3.T_destination" class="variable">T_destination</dd>
                <dd id="segnetUp3.state_dict" class="function">state_dict</dd>
                <dd id="segnetUp3.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="segnetUp3.load_state_dict" class="function">load_state_dict</dd>
                <dd id="segnetUp3.parameters" class="function">parameters</dd>
                <dd id="segnetUp3.named_parameters" class="function">named_parameters</dd>
                <dd id="segnetUp3.buffers" class="function">buffers</dd>
                <dd id="segnetUp3.named_buffers" class="function">named_buffers</dd>
                <dd id="segnetUp3.children" class="function">children</dd>
                <dd id="segnetUp3.named_children" class="function">named_children</dd>
                <dd id="segnetUp3.modules" class="function">modules</dd>
                <dd id="segnetUp3.named_modules" class="function">named_modules</dd>
                <dd id="segnetUp3.train" class="function">train</dd>
                <dd id="segnetUp3.eval" class="function">eval</dd>
                <dd id="segnetUp3.requires_grad_" class="function">requires_grad_</dd>
                <dd id="segnetUp3.zero_grad" class="function">zero_grad</dd>
                <dd id="segnetUp3.share_memory" class="function">share_memory</dd>
                <dd id="segnetUp3.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="residualBlock">
                            <input id="residualBlock-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">residualBlock</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="residualBlock-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualBlock"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualBlock-287"><a href="#residualBlock-287"><span class="linenos">287</span></a><span class="k">class</span> <span class="nc">residualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="residualBlock-288"><a href="#residualBlock-288"><span class="linenos">288</span></a>    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="residualBlock-289"><a href="#residualBlock-289"><span class="linenos">289</span></a>
</span><span id="residualBlock-290"><a href="#residualBlock-290"><span class="linenos">290</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="residualBlock-291"><a href="#residualBlock-291"><span class="linenos">291</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="residualBlock-292"><a href="#residualBlock-292"><span class="linenos">292</span></a>
</span><span id="residualBlock-293"><a href="#residualBlock-293"><span class="linenos">293</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="residualBlock-294"><a href="#residualBlock-294"><span class="linenos">294</span></a>            <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="residualBlock-295"><a href="#residualBlock-295"><span class="linenos">295</span></a>        <span class="p">)</span>
</span><span id="residualBlock-296"><a href="#residualBlock-296"><span class="linenos">296</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span><span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="residualBlock-297"><a href="#residualBlock-297"><span class="linenos">297</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
</span><span id="residualBlock-298"><a href="#residualBlock-298"><span class="linenos">298</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
</span><span id="residualBlock-299"><a href="#residualBlock-299"><span class="linenos">299</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="residualBlock-300"><a href="#residualBlock-300"><span class="linenos">300</span></a>
</span><span id="residualBlock-301"><a href="#residualBlock-301"><span class="linenos">301</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="residualBlock-302"><a href="#residualBlock-302"><span class="linenos">302</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="residualBlock-303"><a href="#residualBlock-303"><span class="linenos">303</span></a>
</span><span id="residualBlock-304"><a href="#residualBlock-304"><span class="linenos">304</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualBlock-305"><a href="#residualBlock-305"><span class="linenos">305</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBlock-306"><a href="#residualBlock-306"><span class="linenos">306</span></a>
</span><span id="residualBlock-307"><a href="#residualBlock-307"><span class="linenos">307</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="residualBlock-308"><a href="#residualBlock-308"><span class="linenos">308</span></a>            <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualBlock-309"><a href="#residualBlock-309"><span class="linenos">309</span></a>
</span><span id="residualBlock-310"><a href="#residualBlock-310"><span class="linenos">310</span></a>        <span class="n">out</span> <span class="o">+=</span> <span class="n">residual</span>
</span><span id="residualBlock-311"><a href="#residualBlock-311"><span class="linenos">311</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBlock-312"><a href="#residualBlock-312"><span class="linenos">312</span></a>        <span class="k">return</span> <span class="n">out</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#residualBlock.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#residualBlock.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="residualBlock.__init__" class="classattr">
                                        <input id="residualBlock.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">residualBlock</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_channels</span>, </span><span class="param"><span class="n">n_filters</span>, </span><span class="param"><span class="n">stride</span><span class="o">=</span><span class="mi">1</span>, </span><span class="param"><span class="n">downsample</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="residualBlock.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualBlock.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualBlock.__init__-290"><a href="#residualBlock.__init__-290"><span class="linenos">290</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="residualBlock.__init__-291"><a href="#residualBlock.__init__-291"><span class="linenos">291</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="residualBlock.__init__-292"><a href="#residualBlock.__init__-292"><span class="linenos">292</span></a>
</span><span id="residualBlock.__init__-293"><a href="#residualBlock.__init__-293"><span class="linenos">293</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="residualBlock.__init__-294"><a href="#residualBlock.__init__-294"><span class="linenos">294</span></a>            <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="residualBlock.__init__-295"><a href="#residualBlock.__init__-295"><span class="linenos">295</span></a>        <span class="p">)</span>
</span><span id="residualBlock.__init__-296"><a href="#residualBlock.__init__-296"><span class="linenos">296</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span><span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="residualBlock.__init__-297"><a href="#residualBlock.__init__-297"><span class="linenos">297</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
</span><span id="residualBlock.__init__-298"><a href="#residualBlock.__init__-298"><span class="linenos">298</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
</span><span id="residualBlock.__init__-299"><a href="#residualBlock.__init__-299"><span class="linenos">299</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="residualBlock.expansion" class="classattr">
                                <div class="attr variable">
            <span class="name">expansion</span><span class="default_value"> = 1</span>

        
    </div>
    <a class="headerlink" href="#residualBlock.expansion"></a>
    
    

                            </div>
                            <div id="residualBlock.forward" class="classattr">
                                        <input id="residualBlock.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="residualBlock.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualBlock.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualBlock.forward-301"><a href="#residualBlock.forward-301"><span class="linenos">301</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="residualBlock.forward-302"><a href="#residualBlock.forward-302"><span class="linenos">302</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="residualBlock.forward-303"><a href="#residualBlock.forward-303"><span class="linenos">303</span></a>
</span><span id="residualBlock.forward-304"><a href="#residualBlock.forward-304"><span class="linenos">304</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualBlock.forward-305"><a href="#residualBlock.forward-305"><span class="linenos">305</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBlock.forward-306"><a href="#residualBlock.forward-306"><span class="linenos">306</span></a>
</span><span id="residualBlock.forward-307"><a href="#residualBlock.forward-307"><span class="linenos">307</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="residualBlock.forward-308"><a href="#residualBlock.forward-308"><span class="linenos">308</span></a>            <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualBlock.forward-309"><a href="#residualBlock.forward-309"><span class="linenos">309</span></a>
</span><span id="residualBlock.forward-310"><a href="#residualBlock.forward-310"><span class="linenos">310</span></a>        <span class="n">out</span> <span class="o">+=</span> <span class="n">residual</span>
</span><span id="residualBlock.forward-311"><a href="#residualBlock.forward-311"><span class="linenos">311</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBlock.forward-312"><a href="#residualBlock.forward-312"><span class="linenos">312</span></a>        <span class="k">return</span> <span class="n">out</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="residualBlock.dump_patches" class="variable">dump_patches</dd>
                <dd id="residualBlock.register_buffer" class="function">register_buffer</dd>
                <dd id="residualBlock.register_parameter" class="function">register_parameter</dd>
                <dd id="residualBlock.add_module" class="function">add_module</dd>
                <dd id="residualBlock.register_module" class="function">register_module</dd>
                <dd id="residualBlock.get_submodule" class="function">get_submodule</dd>
                <dd id="residualBlock.get_parameter" class="function">get_parameter</dd>
                <dd id="residualBlock.get_buffer" class="function">get_buffer</dd>
                <dd id="residualBlock.get_extra_state" class="function">get_extra_state</dd>
                <dd id="residualBlock.set_extra_state" class="function">set_extra_state</dd>
                <dd id="residualBlock.apply" class="function">apply</dd>
                <dd id="residualBlock.cuda" class="function">cuda</dd>
                <dd id="residualBlock.ipu" class="function">ipu</dd>
                <dd id="residualBlock.xpu" class="function">xpu</dd>
                <dd id="residualBlock.cpu" class="function">cpu</dd>
                <dd id="residualBlock.type" class="function">type</dd>
                <dd id="residualBlock.float" class="function">float</dd>
                <dd id="residualBlock.double" class="function">double</dd>
                <dd id="residualBlock.half" class="function">half</dd>
                <dd id="residualBlock.bfloat16" class="function">bfloat16</dd>
                <dd id="residualBlock.to_empty" class="function">to_empty</dd>
                <dd id="residualBlock.to" class="function">to</dd>
                <dd id="residualBlock.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="residualBlock.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="residualBlock.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="residualBlock.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="residualBlock.T_destination" class="variable">T_destination</dd>
                <dd id="residualBlock.state_dict" class="function">state_dict</dd>
                <dd id="residualBlock.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="residualBlock.load_state_dict" class="function">load_state_dict</dd>
                <dd id="residualBlock.parameters" class="function">parameters</dd>
                <dd id="residualBlock.named_parameters" class="function">named_parameters</dd>
                <dd id="residualBlock.buffers" class="function">buffers</dd>
                <dd id="residualBlock.named_buffers" class="function">named_buffers</dd>
                <dd id="residualBlock.children" class="function">children</dd>
                <dd id="residualBlock.named_children" class="function">named_children</dd>
                <dd id="residualBlock.modules" class="function">modules</dd>
                <dd id="residualBlock.named_modules" class="function">named_modules</dd>
                <dd id="residualBlock.train" class="function">train</dd>
                <dd id="residualBlock.eval" class="function">eval</dd>
                <dd id="residualBlock.requires_grad_" class="function">requires_grad_</dd>
                <dd id="residualBlock.zero_grad" class="function">zero_grad</dd>
                <dd id="residualBlock.share_memory" class="function">share_memory</dd>
                <dd id="residualBlock.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="residualBottleneck">
                            <input id="residualBottleneck-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">residualBottleneck</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="residualBottleneck-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualBottleneck"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualBottleneck-315"><a href="#residualBottleneck-315"><span class="linenos">315</span></a><span class="k">class</span> <span class="nc">residualBottleneck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="residualBottleneck-316"><a href="#residualBottleneck-316"><span class="linenos">316</span></a>    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="residualBottleneck-317"><a href="#residualBottleneck-317"><span class="linenos">317</span></a>
</span><span id="residualBottleneck-318"><a href="#residualBottleneck-318"><span class="linenos">318</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="residualBottleneck-319"><a href="#residualBottleneck-319"><span class="linenos">319</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualBottleneck</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="residualBottleneck-320"><a href="#residualBottleneck-320"><span class="linenos">320</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2DBatchNorm</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="residualBottleneck-321"><a href="#residualBottleneck-321"><span class="linenos">321</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2DBatchNorm</span><span class="p">(</span>
</span><span id="residualBottleneck-322"><a href="#residualBottleneck-322"><span class="linenos">322</span></a>            <span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="residualBottleneck-323"><a href="#residualBottleneck-323"><span class="linenos">323</span></a>        <span class="p">)</span>
</span><span id="residualBottleneck-324"><a href="#residualBottleneck-324"><span class="linenos">324</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2DBatchNorm</span><span class="p">(</span>
</span><span id="residualBottleneck-325"><a href="#residualBottleneck-325"><span class="linenos">325</span></a>            <span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="residualBottleneck-326"><a href="#residualBottleneck-326"><span class="linenos">326</span></a>        <span class="p">)</span>
</span><span id="residualBottleneck-327"><a href="#residualBottleneck-327"><span class="linenos">327</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="residualBottleneck-328"><a href="#residualBottleneck-328"><span class="linenos">328</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
</span><span id="residualBottleneck-329"><a href="#residualBottleneck-329"><span class="linenos">329</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
</span><span id="residualBottleneck-330"><a href="#residualBottleneck-330"><span class="linenos">330</span></a>
</span><span id="residualBottleneck-331"><a href="#residualBottleneck-331"><span class="linenos">331</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="residualBottleneck-332"><a href="#residualBottleneck-332"><span class="linenos">332</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="residualBottleneck-333"><a href="#residualBottleneck-333"><span class="linenos">333</span></a>
</span><span id="residualBottleneck-334"><a href="#residualBottleneck-334"><span class="linenos">334</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualBottleneck-335"><a href="#residualBottleneck-335"><span class="linenos">335</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBottleneck-336"><a href="#residualBottleneck-336"><span class="linenos">336</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBottleneck-337"><a href="#residualBottleneck-337"><span class="linenos">337</span></a>
</span><span id="residualBottleneck-338"><a href="#residualBottleneck-338"><span class="linenos">338</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="residualBottleneck-339"><a href="#residualBottleneck-339"><span class="linenos">339</span></a>            <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualBottleneck-340"><a href="#residualBottleneck-340"><span class="linenos">340</span></a>
</span><span id="residualBottleneck-341"><a href="#residualBottleneck-341"><span class="linenos">341</span></a>        <span class="n">out</span> <span class="o">+=</span> <span class="n">residual</span>
</span><span id="residualBottleneck-342"><a href="#residualBottleneck-342"><span class="linenos">342</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBottleneck-343"><a href="#residualBottleneck-343"><span class="linenos">343</span></a>
</span><span id="residualBottleneck-344"><a href="#residualBottleneck-344"><span class="linenos">344</span></a>        <span class="k">return</span> <span class="n">out</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#residualBottleneck.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#residualBottleneck.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="residualBottleneck.__init__" class="classattr">
                                        <input id="residualBottleneck.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">residualBottleneck</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_channels</span>, </span><span class="param"><span class="n">n_filters</span>, </span><span class="param"><span class="n">stride</span><span class="o">=</span><span class="mi">1</span>, </span><span class="param"><span class="n">downsample</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="residualBottleneck.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualBottleneck.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualBottleneck.__init__-318"><a href="#residualBottleneck.__init__-318"><span class="linenos">318</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="residualBottleneck.__init__-319"><a href="#residualBottleneck.__init__-319"><span class="linenos">319</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualBottleneck</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="residualBottleneck.__init__-320"><a href="#residualBottleneck.__init__-320"><span class="linenos">320</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2DBatchNorm</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="residualBottleneck.__init__-321"><a href="#residualBottleneck.__init__-321"><span class="linenos">321</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2DBatchNorm</span><span class="p">(</span>
</span><span id="residualBottleneck.__init__-322"><a href="#residualBottleneck.__init__-322"><span class="linenos">322</span></a>            <span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="residualBottleneck.__init__-323"><a href="#residualBottleneck.__init__-323"><span class="linenos">323</span></a>        <span class="p">)</span>
</span><span id="residualBottleneck.__init__-324"><a href="#residualBottleneck.__init__-324"><span class="linenos">324</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2DBatchNorm</span><span class="p">(</span>
</span><span id="residualBottleneck.__init__-325"><a href="#residualBottleneck.__init__-325"><span class="linenos">325</span></a>            <span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="residualBottleneck.__init__-326"><a href="#residualBottleneck.__init__-326"><span class="linenos">326</span></a>        <span class="p">)</span>
</span><span id="residualBottleneck.__init__-327"><a href="#residualBottleneck.__init__-327"><span class="linenos">327</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="residualBottleneck.__init__-328"><a href="#residualBottleneck.__init__-328"><span class="linenos">328</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
</span><span id="residualBottleneck.__init__-329"><a href="#residualBottleneck.__init__-329"><span class="linenos">329</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="residualBottleneck.expansion" class="classattr">
                                <div class="attr variable">
            <span class="name">expansion</span><span class="default_value"> = 4</span>

        
    </div>
    <a class="headerlink" href="#residualBottleneck.expansion"></a>
    
    

                            </div>
                            <div id="residualBottleneck.forward" class="classattr">
                                        <input id="residualBottleneck.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="residualBottleneck.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualBottleneck.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualBottleneck.forward-331"><a href="#residualBottleneck.forward-331"><span class="linenos">331</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="residualBottleneck.forward-332"><a href="#residualBottleneck.forward-332"><span class="linenos">332</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="residualBottleneck.forward-333"><a href="#residualBottleneck.forward-333"><span class="linenos">333</span></a>
</span><span id="residualBottleneck.forward-334"><a href="#residualBottleneck.forward-334"><span class="linenos">334</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualBottleneck.forward-335"><a href="#residualBottleneck.forward-335"><span class="linenos">335</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBottleneck.forward-336"><a href="#residualBottleneck.forward-336"><span class="linenos">336</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBottleneck.forward-337"><a href="#residualBottleneck.forward-337"><span class="linenos">337</span></a>
</span><span id="residualBottleneck.forward-338"><a href="#residualBottleneck.forward-338"><span class="linenos">338</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="residualBottleneck.forward-339"><a href="#residualBottleneck.forward-339"><span class="linenos">339</span></a>            <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualBottleneck.forward-340"><a href="#residualBottleneck.forward-340"><span class="linenos">340</span></a>
</span><span id="residualBottleneck.forward-341"><a href="#residualBottleneck.forward-341"><span class="linenos">341</span></a>        <span class="n">out</span> <span class="o">+=</span> <span class="n">residual</span>
</span><span id="residualBottleneck.forward-342"><a href="#residualBottleneck.forward-342"><span class="linenos">342</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="residualBottleneck.forward-343"><a href="#residualBottleneck.forward-343"><span class="linenos">343</span></a>
</span><span id="residualBottleneck.forward-344"><a href="#residualBottleneck.forward-344"><span class="linenos">344</span></a>        <span class="k">return</span> <span class="n">out</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="residualBottleneck.dump_patches" class="variable">dump_patches</dd>
                <dd id="residualBottleneck.register_buffer" class="function">register_buffer</dd>
                <dd id="residualBottleneck.register_parameter" class="function">register_parameter</dd>
                <dd id="residualBottleneck.add_module" class="function">add_module</dd>
                <dd id="residualBottleneck.register_module" class="function">register_module</dd>
                <dd id="residualBottleneck.get_submodule" class="function">get_submodule</dd>
                <dd id="residualBottleneck.get_parameter" class="function">get_parameter</dd>
                <dd id="residualBottleneck.get_buffer" class="function">get_buffer</dd>
                <dd id="residualBottleneck.get_extra_state" class="function">get_extra_state</dd>
                <dd id="residualBottleneck.set_extra_state" class="function">set_extra_state</dd>
                <dd id="residualBottleneck.apply" class="function">apply</dd>
                <dd id="residualBottleneck.cuda" class="function">cuda</dd>
                <dd id="residualBottleneck.ipu" class="function">ipu</dd>
                <dd id="residualBottleneck.xpu" class="function">xpu</dd>
                <dd id="residualBottleneck.cpu" class="function">cpu</dd>
                <dd id="residualBottleneck.type" class="function">type</dd>
                <dd id="residualBottleneck.float" class="function">float</dd>
                <dd id="residualBottleneck.double" class="function">double</dd>
                <dd id="residualBottleneck.half" class="function">half</dd>
                <dd id="residualBottleneck.bfloat16" class="function">bfloat16</dd>
                <dd id="residualBottleneck.to_empty" class="function">to_empty</dd>
                <dd id="residualBottleneck.to" class="function">to</dd>
                <dd id="residualBottleneck.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="residualBottleneck.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="residualBottleneck.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="residualBottleneck.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="residualBottleneck.T_destination" class="variable">T_destination</dd>
                <dd id="residualBottleneck.state_dict" class="function">state_dict</dd>
                <dd id="residualBottleneck.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="residualBottleneck.load_state_dict" class="function">load_state_dict</dd>
                <dd id="residualBottleneck.parameters" class="function">parameters</dd>
                <dd id="residualBottleneck.named_parameters" class="function">named_parameters</dd>
                <dd id="residualBottleneck.buffers" class="function">buffers</dd>
                <dd id="residualBottleneck.named_buffers" class="function">named_buffers</dd>
                <dd id="residualBottleneck.children" class="function">children</dd>
                <dd id="residualBottleneck.named_children" class="function">named_children</dd>
                <dd id="residualBottleneck.modules" class="function">modules</dd>
                <dd id="residualBottleneck.named_modules" class="function">named_modules</dd>
                <dd id="residualBottleneck.train" class="function">train</dd>
                <dd id="residualBottleneck.eval" class="function">eval</dd>
                <dd id="residualBottleneck.requires_grad_" class="function">requires_grad_</dd>
                <dd id="residualBottleneck.zero_grad" class="function">zero_grad</dd>
                <dd id="residualBottleneck.share_memory" class="function">share_memory</dd>
                <dd id="residualBottleneck.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="linknetUp">
                            <input id="linknetUp-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">linknetUp</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="linknetUp-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#linknetUp"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="linknetUp-347"><a href="#linknetUp-347"><span class="linenos">347</span></a><span class="k">class</span> <span class="nc">linknetUp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="linknetUp-348"><a href="#linknetUp-348"><span class="linenos">348</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">):</span>
</span><span id="linknetUp-349"><a href="#linknetUp-349"><span class="linenos">349</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">linknetUp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="linknetUp-350"><a href="#linknetUp-350"><span class="linenos">350</span></a>
</span><span id="linknetUp-351"><a href="#linknetUp-351"><span class="linenos">351</span></a>        <span class="c1"># B, 2C, H, W -&gt; B, C/2, H, W</span>
</span><span id="linknetUp-352"><a href="#linknetUp-352"><span class="linenos">352</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="linknetUp-353"><a href="#linknetUp-353"><span class="linenos">353</span></a>            <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
</span><span id="linknetUp-354"><a href="#linknetUp-354"><span class="linenos">354</span></a>        <span class="p">)</span>
</span><span id="linknetUp-355"><a href="#linknetUp-355"><span class="linenos">355</span></a>
</span><span id="linknetUp-356"><a href="#linknetUp-356"><span class="linenos">356</span></a>        <span class="c1"># B, C/2, H, W -&gt; B, C/2, H, W</span>
</span><span id="linknetUp-357"><a href="#linknetUp-357"><span class="linenos">357</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">deconvbnrelu2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">deconv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="linknetUp-358"><a href="#linknetUp-358"><span class="linenos">358</span></a>            <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span>
</span><span id="linknetUp-359"><a href="#linknetUp-359"><span class="linenos">359</span></a>        <span class="p">)</span>
</span><span id="linknetUp-360"><a href="#linknetUp-360"><span class="linenos">360</span></a>
</span><span id="linknetUp-361"><a href="#linknetUp-361"><span class="linenos">361</span></a>        <span class="c1"># B, C/2, H, W -&gt; B, C, H, W</span>
</span><span id="linknetUp-362"><a href="#linknetUp-362"><span class="linenos">362</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu3</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="linknetUp-363"><a href="#linknetUp-363"><span class="linenos">363</span></a>            <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
</span><span id="linknetUp-364"><a href="#linknetUp-364"><span class="linenos">364</span></a>        <span class="p">)</span>
</span><span id="linknetUp-365"><a href="#linknetUp-365"><span class="linenos">365</span></a>
</span><span id="linknetUp-366"><a href="#linknetUp-366"><span class="linenos">366</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="linknetUp-367"><a href="#linknetUp-367"><span class="linenos">367</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="linknetUp-368"><a href="#linknetUp-368"><span class="linenos">368</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconvbnrelu2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="linknetUp-369"><a href="#linknetUp-369"><span class="linenos">369</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="linknetUp-370"><a href="#linknetUp-370"><span class="linenos">370</span></a>        <span class="k">return</span> <span class="n">x</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#linknetUp.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#linknetUp.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="linknetUp.__init__" class="classattr">
                                        <input id="linknetUp.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">linknetUp</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_channels</span>, </span><span class="param"><span class="n">n_filters</span></span>)</span>

                <label class="view-source-button" for="linknetUp.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#linknetUp.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="linknetUp.__init__-348"><a href="#linknetUp.__init__-348"><span class="linenos">348</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">):</span>
</span><span id="linknetUp.__init__-349"><a href="#linknetUp.__init__-349"><span class="linenos">349</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">linknetUp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="linknetUp.__init__-350"><a href="#linknetUp.__init__-350"><span class="linenos">350</span></a>
</span><span id="linknetUp.__init__-351"><a href="#linknetUp.__init__-351"><span class="linenos">351</span></a>        <span class="c1"># B, 2C, H, W -&gt; B, C/2, H, W</span>
</span><span id="linknetUp.__init__-352"><a href="#linknetUp.__init__-352"><span class="linenos">352</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="linknetUp.__init__-353"><a href="#linknetUp.__init__-353"><span class="linenos">353</span></a>            <span class="n">in_channels</span><span class="p">,</span> <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
</span><span id="linknetUp.__init__-354"><a href="#linknetUp.__init__-354"><span class="linenos">354</span></a>        <span class="p">)</span>
</span><span id="linknetUp.__init__-355"><a href="#linknetUp.__init__-355"><span class="linenos">355</span></a>
</span><span id="linknetUp.__init__-356"><a href="#linknetUp.__init__-356"><span class="linenos">356</span></a>        <span class="c1"># B, C/2, H, W -&gt; B, C/2, H, W</span>
</span><span id="linknetUp.__init__-357"><a href="#linknetUp.__init__-357"><span class="linenos">357</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">deconvbnrelu2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">deconv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="linknetUp.__init__-358"><a href="#linknetUp.__init__-358"><span class="linenos">358</span></a>            <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span>
</span><span id="linknetUp.__init__-359"><a href="#linknetUp.__init__-359"><span class="linenos">359</span></a>        <span class="p">)</span>
</span><span id="linknetUp.__init__-360"><a href="#linknetUp.__init__-360"><span class="linenos">360</span></a>
</span><span id="linknetUp.__init__-361"><a href="#linknetUp.__init__-361"><span class="linenos">361</span></a>        <span class="c1"># B, C/2, H, W -&gt; B, C, H, W</span>
</span><span id="linknetUp.__init__-362"><a href="#linknetUp.__init__-362"><span class="linenos">362</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu3</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="linknetUp.__init__-363"><a href="#linknetUp.__init__-363"><span class="linenos">363</span></a>            <span class="n">n_filters</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
</span><span id="linknetUp.__init__-364"><a href="#linknetUp.__init__-364"><span class="linenos">364</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="linknetUp.forward" class="classattr">
                                        <input id="linknetUp.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="linknetUp.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#linknetUp.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="linknetUp.forward-366"><a href="#linknetUp.forward-366"><span class="linenos">366</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="linknetUp.forward-367"><a href="#linknetUp.forward-367"><span class="linenos">367</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="linknetUp.forward-368"><a href="#linknetUp.forward-368"><span class="linenos">368</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconvbnrelu2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="linknetUp.forward-369"><a href="#linknetUp.forward-369"><span class="linenos">369</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convbnrelu3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="linknetUp.forward-370"><a href="#linknetUp.forward-370"><span class="linenos">370</span></a>        <span class="k">return</span> <span class="n">x</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="linknetUp.dump_patches" class="variable">dump_patches</dd>
                <dd id="linknetUp.register_buffer" class="function">register_buffer</dd>
                <dd id="linknetUp.register_parameter" class="function">register_parameter</dd>
                <dd id="linknetUp.add_module" class="function">add_module</dd>
                <dd id="linknetUp.register_module" class="function">register_module</dd>
                <dd id="linknetUp.get_submodule" class="function">get_submodule</dd>
                <dd id="linknetUp.get_parameter" class="function">get_parameter</dd>
                <dd id="linknetUp.get_buffer" class="function">get_buffer</dd>
                <dd id="linknetUp.get_extra_state" class="function">get_extra_state</dd>
                <dd id="linknetUp.set_extra_state" class="function">set_extra_state</dd>
                <dd id="linknetUp.apply" class="function">apply</dd>
                <dd id="linknetUp.cuda" class="function">cuda</dd>
                <dd id="linknetUp.ipu" class="function">ipu</dd>
                <dd id="linknetUp.xpu" class="function">xpu</dd>
                <dd id="linknetUp.cpu" class="function">cpu</dd>
                <dd id="linknetUp.type" class="function">type</dd>
                <dd id="linknetUp.float" class="function">float</dd>
                <dd id="linknetUp.double" class="function">double</dd>
                <dd id="linknetUp.half" class="function">half</dd>
                <dd id="linknetUp.bfloat16" class="function">bfloat16</dd>
                <dd id="linknetUp.to_empty" class="function">to_empty</dd>
                <dd id="linknetUp.to" class="function">to</dd>
                <dd id="linknetUp.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="linknetUp.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="linknetUp.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="linknetUp.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="linknetUp.T_destination" class="variable">T_destination</dd>
                <dd id="linknetUp.state_dict" class="function">state_dict</dd>
                <dd id="linknetUp.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="linknetUp.load_state_dict" class="function">load_state_dict</dd>
                <dd id="linknetUp.parameters" class="function">parameters</dd>
                <dd id="linknetUp.named_parameters" class="function">named_parameters</dd>
                <dd id="linknetUp.buffers" class="function">buffers</dd>
                <dd id="linknetUp.named_buffers" class="function">named_buffers</dd>
                <dd id="linknetUp.children" class="function">children</dd>
                <dd id="linknetUp.named_children" class="function">named_children</dd>
                <dd id="linknetUp.modules" class="function">modules</dd>
                <dd id="linknetUp.named_modules" class="function">named_modules</dd>
                <dd id="linknetUp.train" class="function">train</dd>
                <dd id="linknetUp.eval" class="function">eval</dd>
                <dd id="linknetUp.requires_grad_" class="function">requires_grad_</dd>
                <dd id="linknetUp.zero_grad" class="function">zero_grad</dd>
                <dd id="linknetUp.share_memory" class="function">share_memory</dd>
                <dd id="linknetUp.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="FRRU">
                            <input id="FRRU-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">FRRU</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="FRRU-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FRRU"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FRRU-373"><a href="#FRRU-373"><span class="linenos">373</span></a><span class="k">class</span> <span class="nc">FRRU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="FRRU-374"><a href="#FRRU-374"><span class="linenos">374</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="FRRU-375"><a href="#FRRU-375"><span class="linenos">375</span></a><span class="sd">    Full Resolution Residual Unit for FRRN</span>
</span><span id="FRRU-376"><a href="#FRRU-376"><span class="linenos">376</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="FRRU-377"><a href="#FRRU-377"><span class="linenos">377</span></a>
</span><span id="FRRU-378"><a href="#FRRU-378"><span class="linenos">378</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
</span><span id="FRRU-379"><a href="#FRRU-379"><span class="linenos">379</span></a>                 <span class="n">prev_channels</span><span class="p">,</span> 
</span><span id="FRRU-380"><a href="#FRRU-380"><span class="linenos">380</span></a>                 <span class="n">out_channels</span><span class="p">,</span> 
</span><span id="FRRU-381"><a href="#FRRU-381"><span class="linenos">381</span></a>                 <span class="n">scale</span><span class="p">,</span> 
</span><span id="FRRU-382"><a href="#FRRU-382"><span class="linenos">382</span></a>                 <span class="n">group_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="FRRU-383"><a href="#FRRU-383"><span class="linenos">383</span></a>                 <span class="n">n_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="FRRU-384"><a href="#FRRU-384"><span class="linenos">384</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">FRRU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="FRRU-385"><a href="#FRRU-385"><span class="linenos">385</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
</span><span id="FRRU-386"><a href="#FRRU-386"><span class="linenos">386</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prev_channels</span> <span class="o">=</span> <span class="n">prev_channels</span>
</span><span id="FRRU-387"><a href="#FRRU-387"><span class="linenos">387</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
</span><span id="FRRU-388"><a href="#FRRU-388"><span class="linenos">388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span> <span class="o">=</span> <span class="n">group_norm</span>
</span><span id="FRRU-389"><a href="#FRRU-389"><span class="linenos">389</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">=</span> <span class="n">n_groups</span>
</span><span id="FRRU-390"><a href="#FRRU-390"><span class="linenos">390</span></a>
</span><span id="FRRU-391"><a href="#FRRU-391"><span class="linenos">391</span></a>
</span><span id="FRRU-392"><a href="#FRRU-392"><span class="linenos">392</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span>
</span><span id="FRRU-393"><a href="#FRRU-393"><span class="linenos">393</span></a>            <span class="n">conv_unit</span> <span class="o">=</span> <span class="n">conv2DGroupNormRelu</span>
</span><span id="FRRU-394"><a href="#FRRU-394"><span class="linenos">394</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span>
</span><span id="FRRU-395"><a href="#FRRU-395"><span class="linenos">395</span></a>                <span class="n">prev_channels</span> <span class="o">+</span> <span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="FRRU-396"><a href="#FRRU-396"><span class="linenos">396</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span>
</span><span id="FRRU-397"><a href="#FRRU-397"><span class="linenos">397</span></a>            <span class="p">)</span>
</span><span id="FRRU-398"><a href="#FRRU-398"><span class="linenos">398</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span>
</span><span id="FRRU-399"><a href="#FRRU-399"><span class="linenos">399</span></a>                <span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="FRRU-400"><a href="#FRRU-400"><span class="linenos">400</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span>
</span><span id="FRRU-401"><a href="#FRRU-401"><span class="linenos">401</span></a>            <span class="p">)</span>
</span><span id="FRRU-402"><a href="#FRRU-402"><span class="linenos">402</span></a>
</span><span id="FRRU-403"><a href="#FRRU-403"><span class="linenos">403</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FRRU-404"><a href="#FRRU-404"><span class="linenos">404</span></a>            <span class="n">conv_unit</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span>
</span><span id="FRRU-405"><a href="#FRRU-405"><span class="linenos">405</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span><span class="n">prev_channels</span> <span class="o">+</span> <span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="FRRU-406"><a href="#FRRU-406"><span class="linenos">406</span></a>                                   <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="FRRU-407"><a href="#FRRU-407"><span class="linenos">407</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="FRRU-408"><a href="#FRRU-408"><span class="linenos">408</span></a>                                   <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="FRRU-409"><a href="#FRRU-409"><span class="linenos">409</span></a>
</span><span id="FRRU-410"><a href="#FRRU-410"><span class="linenos">410</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv_res</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="FRRU-411"><a href="#FRRU-411"><span class="linenos">411</span></a>
</span><span id="FRRU-412"><a href="#FRRU-412"><span class="linenos">412</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
</span><span id="FRRU-413"><a href="#FRRU-413"><span class="linenos">413</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)(</span><span class="n">z</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FRRU-414"><a href="#FRRU-414"><span class="linenos">414</span></a>        <span class="n">y_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="FRRU-415"><a href="#FRRU-415"><span class="linenos">415</span></a>        <span class="n">y_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">y_prime</span><span class="p">)</span>
</span><span id="FRRU-416"><a href="#FRRU-416"><span class="linenos">416</span></a>
</span><span id="FRRU-417"><a href="#FRRU-417"><span class="linenos">417</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_res</span><span class="p">(</span><span class="n">y_prime</span><span class="p">)</span>
</span><span id="FRRU-418"><a href="#FRRU-418"><span class="linenos">418</span></a>        <span class="n">upsample_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">_s</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="k">for</span> <span class="n">_s</span> <span class="ow">in</span> <span class="n">y_prime</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
</span><span id="FRRU-419"><a href="#FRRU-419"><span class="linenos">419</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">upsample_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">)</span>
</span><span id="FRRU-420"><a href="#FRRU-420"><span class="linenos">420</span></a>        <span class="n">z_prime</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="n">x</span>
</span><span id="FRRU-421"><a href="#FRRU-421"><span class="linenos">421</span></a>
</span><span id="FRRU-422"><a href="#FRRU-422"><span class="linenos">422</span></a>        <span class="k">return</span> <span class="n">y_prime</span><span class="p">,</span> <span class="n">z_prime</span>
</span></pre></div>


            <div class="docstring"><p>Full Resolution Residual Unit for FRRN</p>
</div>


                            <div id="FRRU.__init__" class="classattr">
                                        <input id="FRRU.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">FRRU</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">prev_channels</span>, </span><span class="param"><span class="n">out_channels</span>, </span><span class="param"><span class="n">scale</span>, </span><span class="param"><span class="n">group_norm</span><span class="o">=</span><span class="kc">False</span>, </span><span class="param"><span class="n">n_groups</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="FRRU.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FRRU.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FRRU.__init__-378"><a href="#FRRU.__init__-378"><span class="linenos">378</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
</span><span id="FRRU.__init__-379"><a href="#FRRU.__init__-379"><span class="linenos">379</span></a>                 <span class="n">prev_channels</span><span class="p">,</span> 
</span><span id="FRRU.__init__-380"><a href="#FRRU.__init__-380"><span class="linenos">380</span></a>                 <span class="n">out_channels</span><span class="p">,</span> 
</span><span id="FRRU.__init__-381"><a href="#FRRU.__init__-381"><span class="linenos">381</span></a>                 <span class="n">scale</span><span class="p">,</span> 
</span><span id="FRRU.__init__-382"><a href="#FRRU.__init__-382"><span class="linenos">382</span></a>                 <span class="n">group_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="FRRU.__init__-383"><a href="#FRRU.__init__-383"><span class="linenos">383</span></a>                 <span class="n">n_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="FRRU.__init__-384"><a href="#FRRU.__init__-384"><span class="linenos">384</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">FRRU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="FRRU.__init__-385"><a href="#FRRU.__init__-385"><span class="linenos">385</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
</span><span id="FRRU.__init__-386"><a href="#FRRU.__init__-386"><span class="linenos">386</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prev_channels</span> <span class="o">=</span> <span class="n">prev_channels</span>
</span><span id="FRRU.__init__-387"><a href="#FRRU.__init__-387"><span class="linenos">387</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
</span><span id="FRRU.__init__-388"><a href="#FRRU.__init__-388"><span class="linenos">388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span> <span class="o">=</span> <span class="n">group_norm</span>
</span><span id="FRRU.__init__-389"><a href="#FRRU.__init__-389"><span class="linenos">389</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">=</span> <span class="n">n_groups</span>
</span><span id="FRRU.__init__-390"><a href="#FRRU.__init__-390"><span class="linenos">390</span></a>
</span><span id="FRRU.__init__-391"><a href="#FRRU.__init__-391"><span class="linenos">391</span></a>
</span><span id="FRRU.__init__-392"><a href="#FRRU.__init__-392"><span class="linenos">392</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span>
</span><span id="FRRU.__init__-393"><a href="#FRRU.__init__-393"><span class="linenos">393</span></a>            <span class="n">conv_unit</span> <span class="o">=</span> <span class="n">conv2DGroupNormRelu</span>
</span><span id="FRRU.__init__-394"><a href="#FRRU.__init__-394"><span class="linenos">394</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span>
</span><span id="FRRU.__init__-395"><a href="#FRRU.__init__-395"><span class="linenos">395</span></a>                <span class="n">prev_channels</span> <span class="o">+</span> <span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="FRRU.__init__-396"><a href="#FRRU.__init__-396"><span class="linenos">396</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span>
</span><span id="FRRU.__init__-397"><a href="#FRRU.__init__-397"><span class="linenos">397</span></a>            <span class="p">)</span>
</span><span id="FRRU.__init__-398"><a href="#FRRU.__init__-398"><span class="linenos">398</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span>
</span><span id="FRRU.__init__-399"><a href="#FRRU.__init__-399"><span class="linenos">399</span></a>                <span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="FRRU.__init__-400"><a href="#FRRU.__init__-400"><span class="linenos">400</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span>
</span><span id="FRRU.__init__-401"><a href="#FRRU.__init__-401"><span class="linenos">401</span></a>            <span class="p">)</span>
</span><span id="FRRU.__init__-402"><a href="#FRRU.__init__-402"><span class="linenos">402</span></a>
</span><span id="FRRU.__init__-403"><a href="#FRRU.__init__-403"><span class="linenos">403</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FRRU.__init__-404"><a href="#FRRU.__init__-404"><span class="linenos">404</span></a>            <span class="n">conv_unit</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span>
</span><span id="FRRU.__init__-405"><a href="#FRRU.__init__-405"><span class="linenos">405</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span><span class="n">prev_channels</span> <span class="o">+</span> <span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="FRRU.__init__-406"><a href="#FRRU.__init__-406"><span class="linenos">406</span></a>                                   <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="FRRU.__init__-407"><a href="#FRRU.__init__-407"><span class="linenos">407</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv_unit</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="FRRU.__init__-408"><a href="#FRRU.__init__-408"><span class="linenos">408</span></a>                                   <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="FRRU.__init__-409"><a href="#FRRU.__init__-409"><span class="linenos">409</span></a>
</span><span id="FRRU.__init__-410"><a href="#FRRU.__init__-410"><span class="linenos">410</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv_res</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="FRRU.forward" class="classattr">
                                        <input id="FRRU.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="n">z</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FRRU.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FRRU.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FRRU.forward-412"><a href="#FRRU.forward-412"><span class="linenos">412</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
</span><span id="FRRU.forward-413"><a href="#FRRU.forward-413"><span class="linenos">413</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)(</span><span class="n">z</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FRRU.forward-414"><a href="#FRRU.forward-414"><span class="linenos">414</span></a>        <span class="n">y_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="FRRU.forward-415"><a href="#FRRU.forward-415"><span class="linenos">415</span></a>        <span class="n">y_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">y_prime</span><span class="p">)</span>
</span><span id="FRRU.forward-416"><a href="#FRRU.forward-416"><span class="linenos">416</span></a>
</span><span id="FRRU.forward-417"><a href="#FRRU.forward-417"><span class="linenos">417</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_res</span><span class="p">(</span><span class="n">y_prime</span><span class="p">)</span>
</span><span id="FRRU.forward-418"><a href="#FRRU.forward-418"><span class="linenos">418</span></a>        <span class="n">upsample_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">_s</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="k">for</span> <span class="n">_s</span> <span class="ow">in</span> <span class="n">y_prime</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
</span><span id="FRRU.forward-419"><a href="#FRRU.forward-419"><span class="linenos">419</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">upsample_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">)</span>
</span><span id="FRRU.forward-420"><a href="#FRRU.forward-420"><span class="linenos">420</span></a>        <span class="n">z_prime</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="n">x</span>
</span><span id="FRRU.forward-421"><a href="#FRRU.forward-421"><span class="linenos">421</span></a>
</span><span id="FRRU.forward-422"><a href="#FRRU.forward-422"><span class="linenos">422</span></a>        <span class="k">return</span> <span class="n">y_prime</span><span class="p">,</span> <span class="n">z_prime</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="FRRU.dump_patches" class="variable">dump_patches</dd>
                <dd id="FRRU.register_buffer" class="function">register_buffer</dd>
                <dd id="FRRU.register_parameter" class="function">register_parameter</dd>
                <dd id="FRRU.add_module" class="function">add_module</dd>
                <dd id="FRRU.register_module" class="function">register_module</dd>
                <dd id="FRRU.get_submodule" class="function">get_submodule</dd>
                <dd id="FRRU.get_parameter" class="function">get_parameter</dd>
                <dd id="FRRU.get_buffer" class="function">get_buffer</dd>
                <dd id="FRRU.get_extra_state" class="function">get_extra_state</dd>
                <dd id="FRRU.set_extra_state" class="function">set_extra_state</dd>
                <dd id="FRRU.apply" class="function">apply</dd>
                <dd id="FRRU.cuda" class="function">cuda</dd>
                <dd id="FRRU.ipu" class="function">ipu</dd>
                <dd id="FRRU.xpu" class="function">xpu</dd>
                <dd id="FRRU.cpu" class="function">cpu</dd>
                <dd id="FRRU.type" class="function">type</dd>
                <dd id="FRRU.float" class="function">float</dd>
                <dd id="FRRU.double" class="function">double</dd>
                <dd id="FRRU.half" class="function">half</dd>
                <dd id="FRRU.bfloat16" class="function">bfloat16</dd>
                <dd id="FRRU.to_empty" class="function">to_empty</dd>
                <dd id="FRRU.to" class="function">to</dd>
                <dd id="FRRU.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="FRRU.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="FRRU.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="FRRU.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="FRRU.T_destination" class="variable">T_destination</dd>
                <dd id="FRRU.state_dict" class="function">state_dict</dd>
                <dd id="FRRU.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="FRRU.load_state_dict" class="function">load_state_dict</dd>
                <dd id="FRRU.parameters" class="function">parameters</dd>
                <dd id="FRRU.named_parameters" class="function">named_parameters</dd>
                <dd id="FRRU.buffers" class="function">buffers</dd>
                <dd id="FRRU.named_buffers" class="function">named_buffers</dd>
                <dd id="FRRU.children" class="function">children</dd>
                <dd id="FRRU.named_children" class="function">named_children</dd>
                <dd id="FRRU.modules" class="function">modules</dd>
                <dd id="FRRU.named_modules" class="function">named_modules</dd>
                <dd id="FRRU.train" class="function">train</dd>
                <dd id="FRRU.eval" class="function">eval</dd>
                <dd id="FRRU.requires_grad_" class="function">requires_grad_</dd>
                <dd id="FRRU.zero_grad" class="function">zero_grad</dd>
                <dd id="FRRU.share_memory" class="function">share_memory</dd>
                <dd id="FRRU.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="RU">
                            <input id="RU-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">RU</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="RU-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RU"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RU-425"><a href="#RU-425"><span class="linenos">425</span></a><span class="k">class</span> <span class="nc">RU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="RU-426"><a href="#RU-426"><span class="linenos">426</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="RU-427"><a href="#RU-427"><span class="linenos">427</span></a><span class="sd">    Residual Unit for FRRN</span>
</span><span id="RU-428"><a href="#RU-428"><span class="linenos">428</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="RU-429"><a href="#RU-429"><span class="linenos">429</span></a>
</span><span id="RU-430"><a href="#RU-430"><span class="linenos">430</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
</span><span id="RU-431"><a href="#RU-431"><span class="linenos">431</span></a>                 <span class="n">channels</span><span class="p">,</span> 
</span><span id="RU-432"><a href="#RU-432"><span class="linenos">432</span></a>                 <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="RU-433"><a href="#RU-433"><span class="linenos">433</span></a>                 <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
</span><span id="RU-434"><a href="#RU-434"><span class="linenos">434</span></a>                 <span class="n">group_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="RU-435"><a href="#RU-435"><span class="linenos">435</span></a>                 <span class="n">n_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="RU-436"><a href="#RU-436"><span class="linenos">436</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">RU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="RU-437"><a href="#RU-437"><span class="linenos">437</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span> <span class="o">=</span> <span class="n">group_norm</span>
</span><span id="RU-438"><a href="#RU-438"><span class="linenos">438</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">=</span> <span class="n">n_groups</span>
</span><span id="RU-439"><a href="#RU-439"><span class="linenos">439</span></a>
</span><span id="RU-440"><a href="#RU-440"><span class="linenos">440</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span>
</span><span id="RU-441"><a href="#RU-441"><span class="linenos">441</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DGroupNormRelu</span><span class="p">(</span>
</span><span id="RU-442"><a href="#RU-442"><span class="linenos">442</span></a>               <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
</span><span id="RU-443"><a href="#RU-443"><span class="linenos">443</span></a>               <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">)</span>
</span><span id="RU-444"><a href="#RU-444"><span class="linenos">444</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DGroupNorm</span><span class="p">(</span>
</span><span id="RU-445"><a href="#RU-445"><span class="linenos">445</span></a>                <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
</span><span id="RU-446"><a href="#RU-446"><span class="linenos">446</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">)</span>
</span><span id="RU-447"><a href="#RU-447"><span class="linenos">447</span></a>
</span><span id="RU-448"><a href="#RU-448"><span class="linenos">448</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="RU-449"><a href="#RU-449"><span class="linenos">449</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="RU-450"><a href="#RU-450"><span class="linenos">450</span></a>               <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="RU-451"><a href="#RU-451"><span class="linenos">451</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="RU-452"><a href="#RU-452"><span class="linenos">452</span></a>                <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="RU-453"><a href="#RU-453"><span class="linenos">453</span></a>
</span><span id="RU-454"><a href="#RU-454"><span class="linenos">454</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="RU-455"><a href="#RU-455"><span class="linenos">455</span></a>        <span class="n">incoming</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="RU-456"><a href="#RU-456"><span class="linenos">456</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="RU-457"><a href="#RU-457"><span class="linenos">457</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="RU-458"><a href="#RU-458"><span class="linenos">458</span></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">incoming</span>
</span></pre></div>


            <div class="docstring"><p>Residual Unit for FRRN</p>
</div>


                            <div id="RU.__init__" class="classattr">
                                        <input id="RU.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">RU</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">channels</span>, </span><span class="param"><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span>, </span><span class="param"><span class="n">strides</span><span class="o">=</span><span class="mi">1</span>, </span><span class="param"><span class="n">group_norm</span><span class="o">=</span><span class="kc">False</span>, </span><span class="param"><span class="n">n_groups</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="RU.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RU.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RU.__init__-430"><a href="#RU.__init__-430"><span class="linenos">430</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
</span><span id="RU.__init__-431"><a href="#RU.__init__-431"><span class="linenos">431</span></a>                 <span class="n">channels</span><span class="p">,</span> 
</span><span id="RU.__init__-432"><a href="#RU.__init__-432"><span class="linenos">432</span></a>                 <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span><span id="RU.__init__-433"><a href="#RU.__init__-433"><span class="linenos">433</span></a>                 <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
</span><span id="RU.__init__-434"><a href="#RU.__init__-434"><span class="linenos">434</span></a>                 <span class="n">group_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="RU.__init__-435"><a href="#RU.__init__-435"><span class="linenos">435</span></a>                 <span class="n">n_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="RU.__init__-436"><a href="#RU.__init__-436"><span class="linenos">436</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">RU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="RU.__init__-437"><a href="#RU.__init__-437"><span class="linenos">437</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span> <span class="o">=</span> <span class="n">group_norm</span>
</span><span id="RU.__init__-438"><a href="#RU.__init__-438"><span class="linenos">438</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">=</span> <span class="n">n_groups</span>
</span><span id="RU.__init__-439"><a href="#RU.__init__-439"><span class="linenos">439</span></a>
</span><span id="RU.__init__-440"><a href="#RU.__init__-440"><span class="linenos">440</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span>
</span><span id="RU.__init__-441"><a href="#RU.__init__-441"><span class="linenos">441</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DGroupNormRelu</span><span class="p">(</span>
</span><span id="RU.__init__-442"><a href="#RU.__init__-442"><span class="linenos">442</span></a>               <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
</span><span id="RU.__init__-443"><a href="#RU.__init__-443"><span class="linenos">443</span></a>               <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">)</span>
</span><span id="RU.__init__-444"><a href="#RU.__init__-444"><span class="linenos">444</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DGroupNorm</span><span class="p">(</span>
</span><span id="RU.__init__-445"><a href="#RU.__init__-445"><span class="linenos">445</span></a>                <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
</span><span id="RU.__init__-446"><a href="#RU.__init__-446"><span class="linenos">446</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">n_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">)</span>
</span><span id="RU.__init__-447"><a href="#RU.__init__-447"><span class="linenos">447</span></a>
</span><span id="RU.__init__-448"><a href="#RU.__init__-448"><span class="linenos">448</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="RU.__init__-449"><a href="#RU.__init__-449"><span class="linenos">449</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="RU.__init__-450"><a href="#RU.__init__-450"><span class="linenos">450</span></a>               <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span><span id="RU.__init__-451"><a href="#RU.__init__-451"><span class="linenos">451</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="RU.__init__-452"><a href="#RU.__init__-452"><span class="linenos">452</span></a>                <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">k_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="RU.forward" class="classattr">
                                        <input id="RU.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="RU.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RU.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RU.forward-454"><a href="#RU.forward-454"><span class="linenos">454</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="RU.forward-455"><a href="#RU.forward-455"><span class="linenos">455</span></a>        <span class="n">incoming</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="RU.forward-456"><a href="#RU.forward-456"><span class="linenos">456</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="RU.forward-457"><a href="#RU.forward-457"><span class="linenos">457</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="RU.forward-458"><a href="#RU.forward-458"><span class="linenos">458</span></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">incoming</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="RU.dump_patches" class="variable">dump_patches</dd>
                <dd id="RU.register_buffer" class="function">register_buffer</dd>
                <dd id="RU.register_parameter" class="function">register_parameter</dd>
                <dd id="RU.add_module" class="function">add_module</dd>
                <dd id="RU.register_module" class="function">register_module</dd>
                <dd id="RU.get_submodule" class="function">get_submodule</dd>
                <dd id="RU.get_parameter" class="function">get_parameter</dd>
                <dd id="RU.get_buffer" class="function">get_buffer</dd>
                <dd id="RU.get_extra_state" class="function">get_extra_state</dd>
                <dd id="RU.set_extra_state" class="function">set_extra_state</dd>
                <dd id="RU.apply" class="function">apply</dd>
                <dd id="RU.cuda" class="function">cuda</dd>
                <dd id="RU.ipu" class="function">ipu</dd>
                <dd id="RU.xpu" class="function">xpu</dd>
                <dd id="RU.cpu" class="function">cpu</dd>
                <dd id="RU.type" class="function">type</dd>
                <dd id="RU.float" class="function">float</dd>
                <dd id="RU.double" class="function">double</dd>
                <dd id="RU.half" class="function">half</dd>
                <dd id="RU.bfloat16" class="function">bfloat16</dd>
                <dd id="RU.to_empty" class="function">to_empty</dd>
                <dd id="RU.to" class="function">to</dd>
                <dd id="RU.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="RU.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="RU.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="RU.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="RU.T_destination" class="variable">T_destination</dd>
                <dd id="RU.state_dict" class="function">state_dict</dd>
                <dd id="RU.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="RU.load_state_dict" class="function">load_state_dict</dd>
                <dd id="RU.parameters" class="function">parameters</dd>
                <dd id="RU.named_parameters" class="function">named_parameters</dd>
                <dd id="RU.buffers" class="function">buffers</dd>
                <dd id="RU.named_buffers" class="function">named_buffers</dd>
                <dd id="RU.children" class="function">children</dd>
                <dd id="RU.named_children" class="function">named_children</dd>
                <dd id="RU.modules" class="function">modules</dd>
                <dd id="RU.named_modules" class="function">named_modules</dd>
                <dd id="RU.train" class="function">train</dd>
                <dd id="RU.eval" class="function">eval</dd>
                <dd id="RU.requires_grad_" class="function">requires_grad_</dd>
                <dd id="RU.zero_grad" class="function">zero_grad</dd>
                <dd id="RU.share_memory" class="function">share_memory</dd>
                <dd id="RU.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="residualConvUnit">
                            <input id="residualConvUnit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">residualConvUnit</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="residualConvUnit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualConvUnit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualConvUnit-461"><a href="#residualConvUnit-461"><span class="linenos">461</span></a><span class="k">class</span> <span class="nc">residualConvUnit</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="residualConvUnit-462"><a href="#residualConvUnit-462"><span class="linenos">462</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
</span><span id="residualConvUnit-463"><a href="#residualConvUnit-463"><span class="linenos">463</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualConvUnit</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="residualConvUnit-464"><a href="#residualConvUnit-464"><span class="linenos">464</span></a>
</span><span id="residualConvUnit-465"><a href="#residualConvUnit-465"><span class="linenos">465</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">residual_conv_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="residualConvUnit-466"><a href="#residualConvUnit-466"><span class="linenos">466</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="residualConvUnit-467"><a href="#residualConvUnit-467"><span class="linenos">467</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="residualConvUnit-468"><a href="#residualConvUnit-468"><span class="linenos">468</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="residualConvUnit-469"><a href="#residualConvUnit-469"><span class="linenos">469</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="residualConvUnit-470"><a href="#residualConvUnit-470"><span class="linenos">470</span></a>        <span class="p">)</span>
</span><span id="residualConvUnit-471"><a href="#residualConvUnit-471"><span class="linenos">471</span></a>
</span><span id="residualConvUnit-472"><a href="#residualConvUnit-472"><span class="linenos">472</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="residualConvUnit-473"><a href="#residualConvUnit-473"><span class="linenos">473</span></a>        <span class="nb">input</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="residualConvUnit-474"><a href="#residualConvUnit-474"><span class="linenos">474</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_conv_unit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualConvUnit-475"><a href="#residualConvUnit-475"><span class="linenos">475</span></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="nb">input</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#residualConvUnit.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#residualConvUnit.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="residualConvUnit.__init__" class="classattr">
                                        <input id="residualConvUnit.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">residualConvUnit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">channels</span>, </span><span class="param"><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span></span>)</span>

                <label class="view-source-button" for="residualConvUnit.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualConvUnit.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualConvUnit.__init__-462"><a href="#residualConvUnit.__init__-462"><span class="linenos">462</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
</span><span id="residualConvUnit.__init__-463"><a href="#residualConvUnit.__init__-463"><span class="linenos">463</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualConvUnit</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="residualConvUnit.__init__-464"><a href="#residualConvUnit.__init__-464"><span class="linenos">464</span></a>
</span><span id="residualConvUnit.__init__-465"><a href="#residualConvUnit.__init__-465"><span class="linenos">465</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">residual_conv_unit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="residualConvUnit.__init__-466"><a href="#residualConvUnit.__init__-466"><span class="linenos">466</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="residualConvUnit.__init__-467"><a href="#residualConvUnit.__init__-467"><span class="linenos">467</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="residualConvUnit.__init__-468"><a href="#residualConvUnit.__init__-468"><span class="linenos">468</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="residualConvUnit.__init__-469"><a href="#residualConvUnit.__init__-469"><span class="linenos">469</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="residualConvUnit.__init__-470"><a href="#residualConvUnit.__init__-470"><span class="linenos">470</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="residualConvUnit.forward" class="classattr">
                                        <input id="residualConvUnit.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="residualConvUnit.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualConvUnit.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualConvUnit.forward-472"><a href="#residualConvUnit.forward-472"><span class="linenos">472</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="residualConvUnit.forward-473"><a href="#residualConvUnit.forward-473"><span class="linenos">473</span></a>        <span class="nb">input</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="residualConvUnit.forward-474"><a href="#residualConvUnit.forward-474"><span class="linenos">474</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_conv_unit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="residualConvUnit.forward-475"><a href="#residualConvUnit.forward-475"><span class="linenos">475</span></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="nb">input</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="residualConvUnit.dump_patches" class="variable">dump_patches</dd>
                <dd id="residualConvUnit.register_buffer" class="function">register_buffer</dd>
                <dd id="residualConvUnit.register_parameter" class="function">register_parameter</dd>
                <dd id="residualConvUnit.add_module" class="function">add_module</dd>
                <dd id="residualConvUnit.register_module" class="function">register_module</dd>
                <dd id="residualConvUnit.get_submodule" class="function">get_submodule</dd>
                <dd id="residualConvUnit.get_parameter" class="function">get_parameter</dd>
                <dd id="residualConvUnit.get_buffer" class="function">get_buffer</dd>
                <dd id="residualConvUnit.get_extra_state" class="function">get_extra_state</dd>
                <dd id="residualConvUnit.set_extra_state" class="function">set_extra_state</dd>
                <dd id="residualConvUnit.apply" class="function">apply</dd>
                <dd id="residualConvUnit.cuda" class="function">cuda</dd>
                <dd id="residualConvUnit.ipu" class="function">ipu</dd>
                <dd id="residualConvUnit.xpu" class="function">xpu</dd>
                <dd id="residualConvUnit.cpu" class="function">cpu</dd>
                <dd id="residualConvUnit.type" class="function">type</dd>
                <dd id="residualConvUnit.float" class="function">float</dd>
                <dd id="residualConvUnit.double" class="function">double</dd>
                <dd id="residualConvUnit.half" class="function">half</dd>
                <dd id="residualConvUnit.bfloat16" class="function">bfloat16</dd>
                <dd id="residualConvUnit.to_empty" class="function">to_empty</dd>
                <dd id="residualConvUnit.to" class="function">to</dd>
                <dd id="residualConvUnit.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="residualConvUnit.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="residualConvUnit.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="residualConvUnit.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="residualConvUnit.T_destination" class="variable">T_destination</dd>
                <dd id="residualConvUnit.state_dict" class="function">state_dict</dd>
                <dd id="residualConvUnit.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="residualConvUnit.load_state_dict" class="function">load_state_dict</dd>
                <dd id="residualConvUnit.parameters" class="function">parameters</dd>
                <dd id="residualConvUnit.named_parameters" class="function">named_parameters</dd>
                <dd id="residualConvUnit.buffers" class="function">buffers</dd>
                <dd id="residualConvUnit.named_buffers" class="function">named_buffers</dd>
                <dd id="residualConvUnit.children" class="function">children</dd>
                <dd id="residualConvUnit.named_children" class="function">named_children</dd>
                <dd id="residualConvUnit.modules" class="function">modules</dd>
                <dd id="residualConvUnit.named_modules" class="function">named_modules</dd>
                <dd id="residualConvUnit.train" class="function">train</dd>
                <dd id="residualConvUnit.eval" class="function">eval</dd>
                <dd id="residualConvUnit.requires_grad_" class="function">requires_grad_</dd>
                <dd id="residualConvUnit.zero_grad" class="function">zero_grad</dd>
                <dd id="residualConvUnit.share_memory" class="function">share_memory</dd>
                <dd id="residualConvUnit.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="multiResolutionFusion">
                            <input id="multiResolutionFusion-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">multiResolutionFusion</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="multiResolutionFusion-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#multiResolutionFusion"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="multiResolutionFusion-478"><a href="#multiResolutionFusion-478"><span class="linenos">478</span></a><span class="k">class</span> <span class="nc">multiResolutionFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="multiResolutionFusion-479"><a href="#multiResolutionFusion-479"><span class="linenos">479</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">up_scale_high</span><span class="p">,</span> <span class="n">up_scale_low</span><span class="p">,</span> <span class="n">high_shape</span><span class="p">,</span> <span class="n">low_shape</span><span class="p">):</span>
</span><span id="multiResolutionFusion-480"><a href="#multiResolutionFusion-480"><span class="linenos">480</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">multiResolutionFusion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="multiResolutionFusion-481"><a href="#multiResolutionFusion-481"><span class="linenos">481</span></a>
</span><span id="multiResolutionFusion-482"><a href="#multiResolutionFusion-482"><span class="linenos">482</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">up_scale_high</span> <span class="o">=</span> <span class="n">up_scale_high</span>
</span><span id="multiResolutionFusion-483"><a href="#multiResolutionFusion-483"><span class="linenos">483</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">up_scale_low</span> <span class="o">=</span> <span class="n">up_scale_low</span>
</span><span id="multiResolutionFusion-484"><a href="#multiResolutionFusion-484"><span class="linenos">484</span></a>
</span><span id="multiResolutionFusion-485"><a href="#multiResolutionFusion-485"><span class="linenos">485</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv_high</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">high_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span id="multiResolutionFusion-486"><a href="#multiResolutionFusion-486"><span class="linenos">486</span></a>
</span><span id="multiResolutionFusion-487"><a href="#multiResolutionFusion-487"><span class="linenos">487</span></a>        <span class="k">if</span> <span class="n">low_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="multiResolutionFusion-488"><a href="#multiResolutionFusion-488"><span class="linenos">488</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv_low</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">low_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span id="multiResolutionFusion-489"><a href="#multiResolutionFusion-489"><span class="linenos">489</span></a>
</span><span id="multiResolutionFusion-490"><a href="#multiResolutionFusion-490"><span class="linenos">490</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_high</span><span class="p">,</span> <span class="n">x_low</span><span class="p">):</span>
</span><span id="multiResolutionFusion-491"><a href="#multiResolutionFusion-491"><span class="linenos">491</span></a>        <span class="n">high_upsampled</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span>
</span><span id="multiResolutionFusion-492"><a href="#multiResolutionFusion-492"><span class="linenos">492</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv_high</span><span class="p">(</span><span class="n">x_high</span><span class="p">),</span> <span class="n">scale_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">up_scale_high</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span>
</span><span id="multiResolutionFusion-493"><a href="#multiResolutionFusion-493"><span class="linenos">493</span></a>        <span class="p">)</span>
</span><span id="multiResolutionFusion-494"><a href="#multiResolutionFusion-494"><span class="linenos">494</span></a>
</span><span id="multiResolutionFusion-495"><a href="#multiResolutionFusion-495"><span class="linenos">495</span></a>        <span class="k">if</span> <span class="n">x_low</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="multiResolutionFusion-496"><a href="#multiResolutionFusion-496"><span class="linenos">496</span></a>            <span class="k">return</span> <span class="n">high_upsampled</span>
</span><span id="multiResolutionFusion-497"><a href="#multiResolutionFusion-497"><span class="linenos">497</span></a>
</span><span id="multiResolutionFusion-498"><a href="#multiResolutionFusion-498"><span class="linenos">498</span></a>        <span class="n">low_upsampled</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span>
</span><span id="multiResolutionFusion-499"><a href="#multiResolutionFusion-499"><span class="linenos">499</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv_low</span><span class="p">(</span><span class="n">x_low</span><span class="p">),</span> <span class="n">scale_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">up_scale_low</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span>
</span><span id="multiResolutionFusion-500"><a href="#multiResolutionFusion-500"><span class="linenos">500</span></a>        <span class="p">)</span>
</span><span id="multiResolutionFusion-501"><a href="#multiResolutionFusion-501"><span class="linenos">501</span></a>
</span><span id="multiResolutionFusion-502"><a href="#multiResolutionFusion-502"><span class="linenos">502</span></a>        <span class="k">return</span> <span class="n">low_upsampled</span> <span class="o">+</span> <span class="n">high_upsampled</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#multiResolutionFusion.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#multiResolutionFusion.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="multiResolutionFusion.__init__" class="classattr">
                                        <input id="multiResolutionFusion.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">multiResolutionFusion</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">channels</span>, </span><span class="param"><span class="n">up_scale_high</span>, </span><span class="param"><span class="n">up_scale_low</span>, </span><span class="param"><span class="n">high_shape</span>, </span><span class="param"><span class="n">low_shape</span></span>)</span>

                <label class="view-source-button" for="multiResolutionFusion.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#multiResolutionFusion.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="multiResolutionFusion.__init__-479"><a href="#multiResolutionFusion.__init__-479"><span class="linenos">479</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">up_scale_high</span><span class="p">,</span> <span class="n">up_scale_low</span><span class="p">,</span> <span class="n">high_shape</span><span class="p">,</span> <span class="n">low_shape</span><span class="p">):</span>
</span><span id="multiResolutionFusion.__init__-480"><a href="#multiResolutionFusion.__init__-480"><span class="linenos">480</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">multiResolutionFusion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="multiResolutionFusion.__init__-481"><a href="#multiResolutionFusion.__init__-481"><span class="linenos">481</span></a>
</span><span id="multiResolutionFusion.__init__-482"><a href="#multiResolutionFusion.__init__-482"><span class="linenos">482</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">up_scale_high</span> <span class="o">=</span> <span class="n">up_scale_high</span>
</span><span id="multiResolutionFusion.__init__-483"><a href="#multiResolutionFusion.__init__-483"><span class="linenos">483</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">up_scale_low</span> <span class="o">=</span> <span class="n">up_scale_low</span>
</span><span id="multiResolutionFusion.__init__-484"><a href="#multiResolutionFusion.__init__-484"><span class="linenos">484</span></a>
</span><span id="multiResolutionFusion.__init__-485"><a href="#multiResolutionFusion.__init__-485"><span class="linenos">485</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv_high</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">high_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span id="multiResolutionFusion.__init__-486"><a href="#multiResolutionFusion.__init__-486"><span class="linenos">486</span></a>
</span><span id="multiResolutionFusion.__init__-487"><a href="#multiResolutionFusion.__init__-487"><span class="linenos">487</span></a>        <span class="k">if</span> <span class="n">low_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="multiResolutionFusion.__init__-488"><a href="#multiResolutionFusion.__init__-488"><span class="linenos">488</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv_low</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">low_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="multiResolutionFusion.forward" class="classattr">
                                        <input id="multiResolutionFusion.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x_high</span>, </span><span class="param"><span class="n">x_low</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="multiResolutionFusion.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#multiResolutionFusion.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="multiResolutionFusion.forward-490"><a href="#multiResolutionFusion.forward-490"><span class="linenos">490</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_high</span><span class="p">,</span> <span class="n">x_low</span><span class="p">):</span>
</span><span id="multiResolutionFusion.forward-491"><a href="#multiResolutionFusion.forward-491"><span class="linenos">491</span></a>        <span class="n">high_upsampled</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span>
</span><span id="multiResolutionFusion.forward-492"><a href="#multiResolutionFusion.forward-492"><span class="linenos">492</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv_high</span><span class="p">(</span><span class="n">x_high</span><span class="p">),</span> <span class="n">scale_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">up_scale_high</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span>
</span><span id="multiResolutionFusion.forward-493"><a href="#multiResolutionFusion.forward-493"><span class="linenos">493</span></a>        <span class="p">)</span>
</span><span id="multiResolutionFusion.forward-494"><a href="#multiResolutionFusion.forward-494"><span class="linenos">494</span></a>
</span><span id="multiResolutionFusion.forward-495"><a href="#multiResolutionFusion.forward-495"><span class="linenos">495</span></a>        <span class="k">if</span> <span class="n">x_low</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="multiResolutionFusion.forward-496"><a href="#multiResolutionFusion.forward-496"><span class="linenos">496</span></a>            <span class="k">return</span> <span class="n">high_upsampled</span>
</span><span id="multiResolutionFusion.forward-497"><a href="#multiResolutionFusion.forward-497"><span class="linenos">497</span></a>
</span><span id="multiResolutionFusion.forward-498"><a href="#multiResolutionFusion.forward-498"><span class="linenos">498</span></a>        <span class="n">low_upsampled</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span>
</span><span id="multiResolutionFusion.forward-499"><a href="#multiResolutionFusion.forward-499"><span class="linenos">499</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conv_low</span><span class="p">(</span><span class="n">x_low</span><span class="p">),</span> <span class="n">scale_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">up_scale_low</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span>
</span><span id="multiResolutionFusion.forward-500"><a href="#multiResolutionFusion.forward-500"><span class="linenos">500</span></a>        <span class="p">)</span>
</span><span id="multiResolutionFusion.forward-501"><a href="#multiResolutionFusion.forward-501"><span class="linenos">501</span></a>
</span><span id="multiResolutionFusion.forward-502"><a href="#multiResolutionFusion.forward-502"><span class="linenos">502</span></a>        <span class="k">return</span> <span class="n">low_upsampled</span> <span class="o">+</span> <span class="n">high_upsampled</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="multiResolutionFusion.dump_patches" class="variable">dump_patches</dd>
                <dd id="multiResolutionFusion.register_buffer" class="function">register_buffer</dd>
                <dd id="multiResolutionFusion.register_parameter" class="function">register_parameter</dd>
                <dd id="multiResolutionFusion.add_module" class="function">add_module</dd>
                <dd id="multiResolutionFusion.register_module" class="function">register_module</dd>
                <dd id="multiResolutionFusion.get_submodule" class="function">get_submodule</dd>
                <dd id="multiResolutionFusion.get_parameter" class="function">get_parameter</dd>
                <dd id="multiResolutionFusion.get_buffer" class="function">get_buffer</dd>
                <dd id="multiResolutionFusion.get_extra_state" class="function">get_extra_state</dd>
                <dd id="multiResolutionFusion.set_extra_state" class="function">set_extra_state</dd>
                <dd id="multiResolutionFusion.apply" class="function">apply</dd>
                <dd id="multiResolutionFusion.cuda" class="function">cuda</dd>
                <dd id="multiResolutionFusion.ipu" class="function">ipu</dd>
                <dd id="multiResolutionFusion.xpu" class="function">xpu</dd>
                <dd id="multiResolutionFusion.cpu" class="function">cpu</dd>
                <dd id="multiResolutionFusion.type" class="function">type</dd>
                <dd id="multiResolutionFusion.float" class="function">float</dd>
                <dd id="multiResolutionFusion.double" class="function">double</dd>
                <dd id="multiResolutionFusion.half" class="function">half</dd>
                <dd id="multiResolutionFusion.bfloat16" class="function">bfloat16</dd>
                <dd id="multiResolutionFusion.to_empty" class="function">to_empty</dd>
                <dd id="multiResolutionFusion.to" class="function">to</dd>
                <dd id="multiResolutionFusion.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="multiResolutionFusion.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="multiResolutionFusion.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="multiResolutionFusion.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="multiResolutionFusion.T_destination" class="variable">T_destination</dd>
                <dd id="multiResolutionFusion.state_dict" class="function">state_dict</dd>
                <dd id="multiResolutionFusion.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="multiResolutionFusion.load_state_dict" class="function">load_state_dict</dd>
                <dd id="multiResolutionFusion.parameters" class="function">parameters</dd>
                <dd id="multiResolutionFusion.named_parameters" class="function">named_parameters</dd>
                <dd id="multiResolutionFusion.buffers" class="function">buffers</dd>
                <dd id="multiResolutionFusion.named_buffers" class="function">named_buffers</dd>
                <dd id="multiResolutionFusion.children" class="function">children</dd>
                <dd id="multiResolutionFusion.named_children" class="function">named_children</dd>
                <dd id="multiResolutionFusion.modules" class="function">modules</dd>
                <dd id="multiResolutionFusion.named_modules" class="function">named_modules</dd>
                <dd id="multiResolutionFusion.train" class="function">train</dd>
                <dd id="multiResolutionFusion.eval" class="function">eval</dd>
                <dd id="multiResolutionFusion.requires_grad_" class="function">requires_grad_</dd>
                <dd id="multiResolutionFusion.zero_grad" class="function">zero_grad</dd>
                <dd id="multiResolutionFusion.share_memory" class="function">share_memory</dd>
                <dd id="multiResolutionFusion.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="chainedResidualPooling">
                            <input id="chainedResidualPooling-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">chainedResidualPooling</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="chainedResidualPooling-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#chainedResidualPooling"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="chainedResidualPooling-505"><a href="#chainedResidualPooling-505"><span class="linenos">505</span></a><span class="k">class</span> <span class="nc">chainedResidualPooling</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="chainedResidualPooling-506"><a href="#chainedResidualPooling-506"><span class="linenos">506</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
</span><span id="chainedResidualPooling-507"><a href="#chainedResidualPooling-507"><span class="linenos">507</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">chainedResidualPooling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="chainedResidualPooling-508"><a href="#chainedResidualPooling-508"><span class="linenos">508</span></a>
</span><span id="chainedResidualPooling-509"><a href="#chainedResidualPooling-509"><span class="linenos">509</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">chained_residual_pooling</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="chainedResidualPooling-510"><a href="#chainedResidualPooling-510"><span class="linenos">510</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="chainedResidualPooling-511"><a href="#chainedResidualPooling-511"><span class="linenos">511</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
</span><span id="chainedResidualPooling-512"><a href="#chainedResidualPooling-512"><span class="linenos">512</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
</span><span id="chainedResidualPooling-513"><a href="#chainedResidualPooling-513"><span class="linenos">513</span></a>        <span class="p">)</span>
</span><span id="chainedResidualPooling-514"><a href="#chainedResidualPooling-514"><span class="linenos">514</span></a>
</span><span id="chainedResidualPooling-515"><a href="#chainedResidualPooling-515"><span class="linenos">515</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="chainedResidualPooling-516"><a href="#chainedResidualPooling-516"><span class="linenos">516</span></a>        <span class="nb">input</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="chainedResidualPooling-517"><a href="#chainedResidualPooling-517"><span class="linenos">517</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chained_residual_pooling</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="chainedResidualPooling-518"><a href="#chainedResidualPooling-518"><span class="linenos">518</span></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="nb">input</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#chainedResidualPooling.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#chainedResidualPooling.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="chainedResidualPooling.__init__" class="classattr">
                                        <input id="chainedResidualPooling.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">chainedResidualPooling</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">channels</span>, </span><span class="param"><span class="n">input_shape</span></span>)</span>

                <label class="view-source-button" for="chainedResidualPooling.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#chainedResidualPooling.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="chainedResidualPooling.__init__-506"><a href="#chainedResidualPooling.__init__-506"><span class="linenos">506</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
</span><span id="chainedResidualPooling.__init__-507"><a href="#chainedResidualPooling.__init__-507"><span class="linenos">507</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">chainedResidualPooling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="chainedResidualPooling.__init__-508"><a href="#chainedResidualPooling.__init__-508"><span class="linenos">508</span></a>
</span><span id="chainedResidualPooling.__init__-509"><a href="#chainedResidualPooling.__init__-509"><span class="linenos">509</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">chained_residual_pooling</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="chainedResidualPooling.__init__-510"><a href="#chainedResidualPooling.__init__-510"><span class="linenos">510</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="chainedResidualPooling.__init__-511"><a href="#chainedResidualPooling.__init__-511"><span class="linenos">511</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
</span><span id="chainedResidualPooling.__init__-512"><a href="#chainedResidualPooling.__init__-512"><span class="linenos">512</span></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
</span><span id="chainedResidualPooling.__init__-513"><a href="#chainedResidualPooling.__init__-513"><span class="linenos">513</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="chainedResidualPooling.forward" class="classattr">
                                        <input id="chainedResidualPooling.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="chainedResidualPooling.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#chainedResidualPooling.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="chainedResidualPooling.forward-515"><a href="#chainedResidualPooling.forward-515"><span class="linenos">515</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="chainedResidualPooling.forward-516"><a href="#chainedResidualPooling.forward-516"><span class="linenos">516</span></a>        <span class="nb">input</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="chainedResidualPooling.forward-517"><a href="#chainedResidualPooling.forward-517"><span class="linenos">517</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chained_residual_pooling</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="chainedResidualPooling.forward-518"><a href="#chainedResidualPooling.forward-518"><span class="linenos">518</span></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="nb">input</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="chainedResidualPooling.dump_patches" class="variable">dump_patches</dd>
                <dd id="chainedResidualPooling.register_buffer" class="function">register_buffer</dd>
                <dd id="chainedResidualPooling.register_parameter" class="function">register_parameter</dd>
                <dd id="chainedResidualPooling.add_module" class="function">add_module</dd>
                <dd id="chainedResidualPooling.register_module" class="function">register_module</dd>
                <dd id="chainedResidualPooling.get_submodule" class="function">get_submodule</dd>
                <dd id="chainedResidualPooling.get_parameter" class="function">get_parameter</dd>
                <dd id="chainedResidualPooling.get_buffer" class="function">get_buffer</dd>
                <dd id="chainedResidualPooling.get_extra_state" class="function">get_extra_state</dd>
                <dd id="chainedResidualPooling.set_extra_state" class="function">set_extra_state</dd>
                <dd id="chainedResidualPooling.apply" class="function">apply</dd>
                <dd id="chainedResidualPooling.cuda" class="function">cuda</dd>
                <dd id="chainedResidualPooling.ipu" class="function">ipu</dd>
                <dd id="chainedResidualPooling.xpu" class="function">xpu</dd>
                <dd id="chainedResidualPooling.cpu" class="function">cpu</dd>
                <dd id="chainedResidualPooling.type" class="function">type</dd>
                <dd id="chainedResidualPooling.float" class="function">float</dd>
                <dd id="chainedResidualPooling.double" class="function">double</dd>
                <dd id="chainedResidualPooling.half" class="function">half</dd>
                <dd id="chainedResidualPooling.bfloat16" class="function">bfloat16</dd>
                <dd id="chainedResidualPooling.to_empty" class="function">to_empty</dd>
                <dd id="chainedResidualPooling.to" class="function">to</dd>
                <dd id="chainedResidualPooling.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="chainedResidualPooling.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="chainedResidualPooling.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="chainedResidualPooling.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="chainedResidualPooling.T_destination" class="variable">T_destination</dd>
                <dd id="chainedResidualPooling.state_dict" class="function">state_dict</dd>
                <dd id="chainedResidualPooling.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="chainedResidualPooling.load_state_dict" class="function">load_state_dict</dd>
                <dd id="chainedResidualPooling.parameters" class="function">parameters</dd>
                <dd id="chainedResidualPooling.named_parameters" class="function">named_parameters</dd>
                <dd id="chainedResidualPooling.buffers" class="function">buffers</dd>
                <dd id="chainedResidualPooling.named_buffers" class="function">named_buffers</dd>
                <dd id="chainedResidualPooling.children" class="function">children</dd>
                <dd id="chainedResidualPooling.named_children" class="function">named_children</dd>
                <dd id="chainedResidualPooling.modules" class="function">modules</dd>
                <dd id="chainedResidualPooling.named_modules" class="function">named_modules</dd>
                <dd id="chainedResidualPooling.train" class="function">train</dd>
                <dd id="chainedResidualPooling.eval" class="function">eval</dd>
                <dd id="chainedResidualPooling.requires_grad_" class="function">requires_grad_</dd>
                <dd id="chainedResidualPooling.zero_grad" class="function">zero_grad</dd>
                <dd id="chainedResidualPooling.share_memory" class="function">share_memory</dd>
                <dd id="chainedResidualPooling.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="pyramidPooling">
                            <input id="pyramidPooling-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">pyramidPooling</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="pyramidPooling-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#pyramidPooling"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="pyramidPooling-521"><a href="#pyramidPooling-521"><span class="linenos">521</span></a><span class="k">class</span> <span class="nc">pyramidPooling</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="pyramidPooling-522"><a href="#pyramidPooling-522"><span class="linenos">522</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="pyramidPooling-523"><a href="#pyramidPooling-523"><span class="linenos">523</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="pyramidPooling-524"><a href="#pyramidPooling-524"><span class="linenos">524</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="pyramidPooling-525"><a href="#pyramidPooling-525"><span class="linenos">525</span></a>        <span class="n">pool_sizes</span><span class="p">,</span>
</span><span id="pyramidPooling-526"><a href="#pyramidPooling-526"><span class="linenos">526</span></a>        <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;pspnet&quot;</span><span class="p">,</span>
</span><span id="pyramidPooling-527"><a href="#pyramidPooling-527"><span class="linenos">527</span></a>        <span class="n">fusion_mode</span><span class="o">=</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span>
</span><span id="pyramidPooling-528"><a href="#pyramidPooling-528"><span class="linenos">528</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="pyramidPooling-529"><a href="#pyramidPooling-529"><span class="linenos">529</span></a>    <span class="p">):</span>
</span><span id="pyramidPooling-530"><a href="#pyramidPooling-530"><span class="linenos">530</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">pyramidPooling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="pyramidPooling-531"><a href="#pyramidPooling-531"><span class="linenos">531</span></a>
</span><span id="pyramidPooling-532"><a href="#pyramidPooling-532"><span class="linenos">532</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="pyramidPooling-533"><a href="#pyramidPooling-533"><span class="linenos">533</span></a>
</span><span id="pyramidPooling-534"><a href="#pyramidPooling-534"><span class="linenos">534</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">paths</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="pyramidPooling-535"><a href="#pyramidPooling-535"><span class="linenos">535</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pool_sizes</span><span class="p">)):</span>
</span><span id="pyramidPooling-536"><a href="#pyramidPooling-536"><span class="linenos">536</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="pyramidPooling-537"><a href="#pyramidPooling-537"><span class="linenos">537</span></a>                <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="pyramidPooling-538"><a href="#pyramidPooling-538"><span class="linenos">538</span></a>                    <span class="n">in_channels</span><span class="p">,</span>
</span><span id="pyramidPooling-539"><a href="#pyramidPooling-539"><span class="linenos">539</span></a>                    <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">pool_sizes</span><span class="p">)),</span>
</span><span id="pyramidPooling-540"><a href="#pyramidPooling-540"><span class="linenos">540</span></a>                    <span class="mi">1</span><span class="p">,</span>
</span><span id="pyramidPooling-541"><a href="#pyramidPooling-541"><span class="linenos">541</span></a>                    <span class="mi">1</span><span class="p">,</span>
</span><span id="pyramidPooling-542"><a href="#pyramidPooling-542"><span class="linenos">542</span></a>                    <span class="mi">0</span><span class="p">,</span>
</span><span id="pyramidPooling-543"><a href="#pyramidPooling-543"><span class="linenos">543</span></a>                    <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="pyramidPooling-544"><a href="#pyramidPooling-544"><span class="linenos">544</span></a>                    <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="pyramidPooling-545"><a href="#pyramidPooling-545"><span class="linenos">545</span></a>                <span class="p">)</span>
</span><span id="pyramidPooling-546"><a href="#pyramidPooling-546"><span class="linenos">546</span></a>            <span class="p">)</span>
</span><span id="pyramidPooling-547"><a href="#pyramidPooling-547"><span class="linenos">547</span></a>
</span><span id="pyramidPooling-548"><a href="#pyramidPooling-548"><span class="linenos">548</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">path_module_list</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">paths</span><span class="p">)</span>
</span><span id="pyramidPooling-549"><a href="#pyramidPooling-549"><span class="linenos">549</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span> <span class="o">=</span> <span class="n">pool_sizes</span>
</span><span id="pyramidPooling-550"><a href="#pyramidPooling-550"><span class="linenos">550</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
</span><span id="pyramidPooling-551"><a href="#pyramidPooling-551"><span class="linenos">551</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_mode</span> <span class="o">=</span> <span class="n">fusion_mode</span>
</span><span id="pyramidPooling-552"><a href="#pyramidPooling-552"><span class="linenos">552</span></a>
</span><span id="pyramidPooling-553"><a href="#pyramidPooling-553"><span class="linenos">553</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="pyramidPooling-554"><a href="#pyramidPooling-554"><span class="linenos">554</span></a>        <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
</span><span id="pyramidPooling-555"><a href="#pyramidPooling-555"><span class="linenos">555</span></a>
</span><span id="pyramidPooling-556"><a href="#pyramidPooling-556"><span class="linenos">556</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">!=</span> <span class="s2">&quot;icnet&quot;</span><span class="p">:</span>  <span class="c1"># general settings or pspnet</span>
</span><span id="pyramidPooling-557"><a href="#pyramidPooling-557"><span class="linenos">557</span></a>            <span class="n">k_sizes</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="pyramidPooling-558"><a href="#pyramidPooling-558"><span class="linenos">558</span></a>            <span class="n">strides</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="pyramidPooling-559"><a href="#pyramidPooling-559"><span class="linenos">559</span></a>            <span class="k">for</span> <span class="n">pool_size</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span><span class="p">:</span>
</span><span id="pyramidPooling-560"><a href="#pyramidPooling-560"><span class="linenos">560</span></a>                <span class="n">k_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">h</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">)))</span>
</span><span id="pyramidPooling-561"><a href="#pyramidPooling-561"><span class="linenos">561</span></a>                <span class="n">strides</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">h</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">)))</span>
</span><span id="pyramidPooling-562"><a href="#pyramidPooling-562"><span class="linenos">562</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># eval mode and icnet: pre-trained for 1025 x 2049</span>
</span><span id="pyramidPooling-563"><a href="#pyramidPooling-563"><span class="linenos">563</span></a>            <span class="n">k_sizes</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">33</span><span class="p">),</span> <span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">65</span><span class="p">)]</span>
</span><span id="pyramidPooling-564"><a href="#pyramidPooling-564"><span class="linenos">564</span></a>            <span class="n">strides</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">65</span><span class="p">)]</span>
</span><span id="pyramidPooling-565"><a href="#pyramidPooling-565"><span class="linenos">565</span></a>
</span><span id="pyramidPooling-566"><a href="#pyramidPooling-566"><span class="linenos">566</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_mode</span> <span class="o">==</span> <span class="s2">&quot;cat&quot;</span><span class="p">:</span>  <span class="c1"># pspnet: concat (including x)</span>
</span><span id="pyramidPooling-567"><a href="#pyramidPooling-567"><span class="linenos">567</span></a>            <span class="n">output_slices</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
</span><span id="pyramidPooling-568"><a href="#pyramidPooling-568"><span class="linenos">568</span></a>
</span><span id="pyramidPooling-569"><a href="#pyramidPooling-569"><span class="linenos">569</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
</span><span id="pyramidPooling-570"><a href="#pyramidPooling-570"><span class="linenos">570</span></a>                <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path_module_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span><span class="p">)</span>
</span><span id="pyramidPooling-571"><a href="#pyramidPooling-571"><span class="linenos">571</span></a>            <span class="p">):</span>
</span><span id="pyramidPooling-572"><a href="#pyramidPooling-572"><span class="linenos">572</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="pyramidPooling-573"><a href="#pyramidPooling-573"><span class="linenos">573</span></a>                <span class="c1"># out = F.adaptive_avg_pool2d(x, output_size=(pool_size, pool_size))</span>
</span><span id="pyramidPooling-574"><a href="#pyramidPooling-574"><span class="linenos">574</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">!=</span> <span class="s2">&quot;icnet&quot;</span><span class="p">:</span>
</span><span id="pyramidPooling-575"><a href="#pyramidPooling-575"><span class="linenos">575</span></a>                    <span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="pyramidPooling-576"><a href="#pyramidPooling-576"><span class="linenos">576</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="pyramidPooling-577"><a href="#pyramidPooling-577"><span class="linenos">577</span></a>                <span class="n">output_slices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="pyramidPooling-578"><a href="#pyramidPooling-578"><span class="linenos">578</span></a>
</span><span id="pyramidPooling-579"><a href="#pyramidPooling-579"><span class="linenos">579</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">output_slices</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="pyramidPooling-580"><a href="#pyramidPooling-580"><span class="linenos">580</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># icnet: element-wise sum (including x)</span>
</span><span id="pyramidPooling-581"><a href="#pyramidPooling-581"><span class="linenos">581</span></a>            <span class="n">pp_sum</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="pyramidPooling-582"><a href="#pyramidPooling-582"><span class="linenos">582</span></a>
</span><span id="pyramidPooling-583"><a href="#pyramidPooling-583"><span class="linenos">583</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
</span><span id="pyramidPooling-584"><a href="#pyramidPooling-584"><span class="linenos">584</span></a>                <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path_module_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span><span class="p">)</span>
</span><span id="pyramidPooling-585"><a href="#pyramidPooling-585"><span class="linenos">585</span></a>            <span class="p">):</span>
</span><span id="pyramidPooling-586"><a href="#pyramidPooling-586"><span class="linenos">586</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="pyramidPooling-587"><a href="#pyramidPooling-587"><span class="linenos">587</span></a>                <span class="c1"># out = F.adaptive_avg_pool2d(x, output_size=(pool_size, pool_size))</span>
</span><span id="pyramidPooling-588"><a href="#pyramidPooling-588"><span class="linenos">588</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">!=</span> <span class="s2">&quot;icnet&quot;</span><span class="p">:</span>
</span><span id="pyramidPooling-589"><a href="#pyramidPooling-589"><span class="linenos">589</span></a>                    <span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="pyramidPooling-590"><a href="#pyramidPooling-590"><span class="linenos">590</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="pyramidPooling-591"><a href="#pyramidPooling-591"><span class="linenos">591</span></a>                <span class="n">pp_sum</span> <span class="o">=</span> <span class="n">pp_sum</span> <span class="o">+</span> <span class="n">out</span>
</span><span id="pyramidPooling-592"><a href="#pyramidPooling-592"><span class="linenos">592</span></a>
</span><span id="pyramidPooling-593"><a href="#pyramidPooling-593"><span class="linenos">593</span></a>            <span class="k">return</span> <span class="n">pp_sum</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#pyramidPooling.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#pyramidPooling.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="pyramidPooling.__init__" class="classattr">
                                        <input id="pyramidPooling.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">pyramidPooling</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">in_channels</span>,</span><span class="param">	<span class="n">pool_sizes</span>,</span><span class="param">	<span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;pspnet&#39;</span>,</span><span class="param">	<span class="n">fusion_mode</span><span class="o">=</span><span class="s1">&#39;cat&#39;</span>,</span><span class="param">	<span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="pyramidPooling.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#pyramidPooling.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="pyramidPooling.__init__-522"><a href="#pyramidPooling.__init__-522"><span class="linenos">522</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="pyramidPooling.__init__-523"><a href="#pyramidPooling.__init__-523"><span class="linenos">523</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-524"><a href="#pyramidPooling.__init__-524"><span class="linenos">524</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-525"><a href="#pyramidPooling.__init__-525"><span class="linenos">525</span></a>        <span class="n">pool_sizes</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-526"><a href="#pyramidPooling.__init__-526"><span class="linenos">526</span></a>        <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;pspnet&quot;</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-527"><a href="#pyramidPooling.__init__-527"><span class="linenos">527</span></a>        <span class="n">fusion_mode</span><span class="o">=</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-528"><a href="#pyramidPooling.__init__-528"><span class="linenos">528</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-529"><a href="#pyramidPooling.__init__-529"><span class="linenos">529</span></a>    <span class="p">):</span>
</span><span id="pyramidPooling.__init__-530"><a href="#pyramidPooling.__init__-530"><span class="linenos">530</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">pyramidPooling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="pyramidPooling.__init__-531"><a href="#pyramidPooling.__init__-531"><span class="linenos">531</span></a>
</span><span id="pyramidPooling.__init__-532"><a href="#pyramidPooling.__init__-532"><span class="linenos">532</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="pyramidPooling.__init__-533"><a href="#pyramidPooling.__init__-533"><span class="linenos">533</span></a>
</span><span id="pyramidPooling.__init__-534"><a href="#pyramidPooling.__init__-534"><span class="linenos">534</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">paths</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="pyramidPooling.__init__-535"><a href="#pyramidPooling.__init__-535"><span class="linenos">535</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pool_sizes</span><span class="p">)):</span>
</span><span id="pyramidPooling.__init__-536"><a href="#pyramidPooling.__init__-536"><span class="linenos">536</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="pyramidPooling.__init__-537"><a href="#pyramidPooling.__init__-537"><span class="linenos">537</span></a>                <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="pyramidPooling.__init__-538"><a href="#pyramidPooling.__init__-538"><span class="linenos">538</span></a>                    <span class="n">in_channels</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-539"><a href="#pyramidPooling.__init__-539"><span class="linenos">539</span></a>                    <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">pool_sizes</span><span class="p">)),</span>
</span><span id="pyramidPooling.__init__-540"><a href="#pyramidPooling.__init__-540"><span class="linenos">540</span></a>                    <span class="mi">1</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-541"><a href="#pyramidPooling.__init__-541"><span class="linenos">541</span></a>                    <span class="mi">1</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-542"><a href="#pyramidPooling.__init__-542"><span class="linenos">542</span></a>                    <span class="mi">0</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-543"><a href="#pyramidPooling.__init__-543"><span class="linenos">543</span></a>                    <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-544"><a href="#pyramidPooling.__init__-544"><span class="linenos">544</span></a>                    <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="pyramidPooling.__init__-545"><a href="#pyramidPooling.__init__-545"><span class="linenos">545</span></a>                <span class="p">)</span>
</span><span id="pyramidPooling.__init__-546"><a href="#pyramidPooling.__init__-546"><span class="linenos">546</span></a>            <span class="p">)</span>
</span><span id="pyramidPooling.__init__-547"><a href="#pyramidPooling.__init__-547"><span class="linenos">547</span></a>
</span><span id="pyramidPooling.__init__-548"><a href="#pyramidPooling.__init__-548"><span class="linenos">548</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">path_module_list</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">paths</span><span class="p">)</span>
</span><span id="pyramidPooling.__init__-549"><a href="#pyramidPooling.__init__-549"><span class="linenos">549</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span> <span class="o">=</span> <span class="n">pool_sizes</span>
</span><span id="pyramidPooling.__init__-550"><a href="#pyramidPooling.__init__-550"><span class="linenos">550</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
</span><span id="pyramidPooling.__init__-551"><a href="#pyramidPooling.__init__-551"><span class="linenos">551</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_mode</span> <span class="o">=</span> <span class="n">fusion_mode</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="pyramidPooling.forward" class="classattr">
                                        <input id="pyramidPooling.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="pyramidPooling.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#pyramidPooling.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="pyramidPooling.forward-553"><a href="#pyramidPooling.forward-553"><span class="linenos">553</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="pyramidPooling.forward-554"><a href="#pyramidPooling.forward-554"><span class="linenos">554</span></a>        <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
</span><span id="pyramidPooling.forward-555"><a href="#pyramidPooling.forward-555"><span class="linenos">555</span></a>
</span><span id="pyramidPooling.forward-556"><a href="#pyramidPooling.forward-556"><span class="linenos">556</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">!=</span> <span class="s2">&quot;icnet&quot;</span><span class="p">:</span>  <span class="c1"># general settings or pspnet</span>
</span><span id="pyramidPooling.forward-557"><a href="#pyramidPooling.forward-557"><span class="linenos">557</span></a>            <span class="n">k_sizes</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="pyramidPooling.forward-558"><a href="#pyramidPooling.forward-558"><span class="linenos">558</span></a>            <span class="n">strides</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="pyramidPooling.forward-559"><a href="#pyramidPooling.forward-559"><span class="linenos">559</span></a>            <span class="k">for</span> <span class="n">pool_size</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span><span class="p">:</span>
</span><span id="pyramidPooling.forward-560"><a href="#pyramidPooling.forward-560"><span class="linenos">560</span></a>                <span class="n">k_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">h</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">)))</span>
</span><span id="pyramidPooling.forward-561"><a href="#pyramidPooling.forward-561"><span class="linenos">561</span></a>                <span class="n">strides</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">h</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span> <span class="o">/</span> <span class="n">pool_size</span><span class="p">)))</span>
</span><span id="pyramidPooling.forward-562"><a href="#pyramidPooling.forward-562"><span class="linenos">562</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># eval mode and icnet: pre-trained for 1025 x 2049</span>
</span><span id="pyramidPooling.forward-563"><a href="#pyramidPooling.forward-563"><span class="linenos">563</span></a>            <span class="n">k_sizes</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">33</span><span class="p">),</span> <span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">65</span><span class="p">)]</span>
</span><span id="pyramidPooling.forward-564"><a href="#pyramidPooling.forward-564"><span class="linenos">564</span></a>            <span class="n">strides</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">65</span><span class="p">)]</span>
</span><span id="pyramidPooling.forward-565"><a href="#pyramidPooling.forward-565"><span class="linenos">565</span></a>
</span><span id="pyramidPooling.forward-566"><a href="#pyramidPooling.forward-566"><span class="linenos">566</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_mode</span> <span class="o">==</span> <span class="s2">&quot;cat&quot;</span><span class="p">:</span>  <span class="c1"># pspnet: concat (including x)</span>
</span><span id="pyramidPooling.forward-567"><a href="#pyramidPooling.forward-567"><span class="linenos">567</span></a>            <span class="n">output_slices</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
</span><span id="pyramidPooling.forward-568"><a href="#pyramidPooling.forward-568"><span class="linenos">568</span></a>
</span><span id="pyramidPooling.forward-569"><a href="#pyramidPooling.forward-569"><span class="linenos">569</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
</span><span id="pyramidPooling.forward-570"><a href="#pyramidPooling.forward-570"><span class="linenos">570</span></a>                <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path_module_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-571"><a href="#pyramidPooling.forward-571"><span class="linenos">571</span></a>            <span class="p">):</span>
</span><span id="pyramidPooling.forward-572"><a href="#pyramidPooling.forward-572"><span class="linenos">572</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-573"><a href="#pyramidPooling.forward-573"><span class="linenos">573</span></a>                <span class="c1"># out = F.adaptive_avg_pool2d(x, output_size=(pool_size, pool_size))</span>
</span><span id="pyramidPooling.forward-574"><a href="#pyramidPooling.forward-574"><span class="linenos">574</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">!=</span> <span class="s2">&quot;icnet&quot;</span><span class="p">:</span>
</span><span id="pyramidPooling.forward-575"><a href="#pyramidPooling.forward-575"><span class="linenos">575</span></a>                    <span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-576"><a href="#pyramidPooling.forward-576"><span class="linenos">576</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-577"><a href="#pyramidPooling.forward-577"><span class="linenos">577</span></a>                <span class="n">output_slices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-578"><a href="#pyramidPooling.forward-578"><span class="linenos">578</span></a>
</span><span id="pyramidPooling.forward-579"><a href="#pyramidPooling.forward-579"><span class="linenos">579</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">output_slices</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-580"><a href="#pyramidPooling.forward-580"><span class="linenos">580</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># icnet: element-wise sum (including x)</span>
</span><span id="pyramidPooling.forward-581"><a href="#pyramidPooling.forward-581"><span class="linenos">581</span></a>            <span class="n">pp_sum</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="pyramidPooling.forward-582"><a href="#pyramidPooling.forward-582"><span class="linenos">582</span></a>
</span><span id="pyramidPooling.forward-583"><a href="#pyramidPooling.forward-583"><span class="linenos">583</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
</span><span id="pyramidPooling.forward-584"><a href="#pyramidPooling.forward-584"><span class="linenos">584</span></a>                <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path_module_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_sizes</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-585"><a href="#pyramidPooling.forward-585"><span class="linenos">585</span></a>            <span class="p">):</span>
</span><span id="pyramidPooling.forward-586"><a href="#pyramidPooling.forward-586"><span class="linenos">586</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-587"><a href="#pyramidPooling.forward-587"><span class="linenos">587</span></a>                <span class="c1"># out = F.adaptive_avg_pool2d(x, output_size=(pool_size, pool_size))</span>
</span><span id="pyramidPooling.forward-588"><a href="#pyramidPooling.forward-588"><span class="linenos">588</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">!=</span> <span class="s2">&quot;icnet&quot;</span><span class="p">:</span>
</span><span id="pyramidPooling.forward-589"><a href="#pyramidPooling.forward-589"><span class="linenos">589</span></a>                    <span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-590"><a href="#pyramidPooling.forward-590"><span class="linenos">590</span></a>                <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="pyramidPooling.forward-591"><a href="#pyramidPooling.forward-591"><span class="linenos">591</span></a>                <span class="n">pp_sum</span> <span class="o">=</span> <span class="n">pp_sum</span> <span class="o">+</span> <span class="n">out</span>
</span><span id="pyramidPooling.forward-592"><a href="#pyramidPooling.forward-592"><span class="linenos">592</span></a>
</span><span id="pyramidPooling.forward-593"><a href="#pyramidPooling.forward-593"><span class="linenos">593</span></a>            <span class="k">return</span> <span class="n">pp_sum</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="pyramidPooling.dump_patches" class="variable">dump_patches</dd>
                <dd id="pyramidPooling.register_buffer" class="function">register_buffer</dd>
                <dd id="pyramidPooling.register_parameter" class="function">register_parameter</dd>
                <dd id="pyramidPooling.add_module" class="function">add_module</dd>
                <dd id="pyramidPooling.register_module" class="function">register_module</dd>
                <dd id="pyramidPooling.get_submodule" class="function">get_submodule</dd>
                <dd id="pyramidPooling.get_parameter" class="function">get_parameter</dd>
                <dd id="pyramidPooling.get_buffer" class="function">get_buffer</dd>
                <dd id="pyramidPooling.get_extra_state" class="function">get_extra_state</dd>
                <dd id="pyramidPooling.set_extra_state" class="function">set_extra_state</dd>
                <dd id="pyramidPooling.apply" class="function">apply</dd>
                <dd id="pyramidPooling.cuda" class="function">cuda</dd>
                <dd id="pyramidPooling.ipu" class="function">ipu</dd>
                <dd id="pyramidPooling.xpu" class="function">xpu</dd>
                <dd id="pyramidPooling.cpu" class="function">cpu</dd>
                <dd id="pyramidPooling.type" class="function">type</dd>
                <dd id="pyramidPooling.float" class="function">float</dd>
                <dd id="pyramidPooling.double" class="function">double</dd>
                <dd id="pyramidPooling.half" class="function">half</dd>
                <dd id="pyramidPooling.bfloat16" class="function">bfloat16</dd>
                <dd id="pyramidPooling.to_empty" class="function">to_empty</dd>
                <dd id="pyramidPooling.to" class="function">to</dd>
                <dd id="pyramidPooling.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="pyramidPooling.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="pyramidPooling.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="pyramidPooling.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="pyramidPooling.T_destination" class="variable">T_destination</dd>
                <dd id="pyramidPooling.state_dict" class="function">state_dict</dd>
                <dd id="pyramidPooling.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="pyramidPooling.load_state_dict" class="function">load_state_dict</dd>
                <dd id="pyramidPooling.parameters" class="function">parameters</dd>
                <dd id="pyramidPooling.named_parameters" class="function">named_parameters</dd>
                <dd id="pyramidPooling.buffers" class="function">buffers</dd>
                <dd id="pyramidPooling.named_buffers" class="function">named_buffers</dd>
                <dd id="pyramidPooling.children" class="function">children</dd>
                <dd id="pyramidPooling.named_children" class="function">named_children</dd>
                <dd id="pyramidPooling.modules" class="function">modules</dd>
                <dd id="pyramidPooling.named_modules" class="function">named_modules</dd>
                <dd id="pyramidPooling.train" class="function">train</dd>
                <dd id="pyramidPooling.eval" class="function">eval</dd>
                <dd id="pyramidPooling.requires_grad_" class="function">requires_grad_</dd>
                <dd id="pyramidPooling.zero_grad" class="function">zero_grad</dd>
                <dd id="pyramidPooling.share_memory" class="function">share_memory</dd>
                <dd id="pyramidPooling.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="bottleNeckPSP">
                            <input id="bottleNeckPSP-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">bottleNeckPSP</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="bottleNeckPSP-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#bottleNeckPSP"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="bottleNeckPSP-596"><a href="#bottleNeckPSP-596"><span class="linenos">596</span></a><span class="k">class</span> <span class="nc">bottleNeckPSP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="bottleNeckPSP-597"><a href="#bottleNeckPSP-597"><span class="linenos">597</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="bottleNeckPSP-598"><a href="#bottleNeckPSP-598"><span class="linenos">598</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span>
</span><span id="bottleNeckPSP-599"><a href="#bottleNeckPSP-599"><span class="linenos">599</span></a>    <span class="p">):</span>
</span><span id="bottleNeckPSP-600"><a href="#bottleNeckPSP-600"><span class="linenos">600</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">bottleNeckPSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="bottleNeckPSP-601"><a href="#bottleNeckPSP-601"><span class="linenos">601</span></a>
</span><span id="bottleNeckPSP-602"><a href="#bottleNeckPSP-602"><span class="linenos">602</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="bottleNeckPSP-603"><a href="#bottleNeckPSP-603"><span class="linenos">603</span></a>
</span><span id="bottleNeckPSP-604"><a href="#bottleNeckPSP-604"><span class="linenos">604</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckPSP-605"><a href="#bottleNeckPSP-605"><span class="linenos">605</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-606"><a href="#bottleNeckPSP-606"><span class="linenos">606</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-607"><a href="#bottleNeckPSP-607"><span class="linenos">607</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP-608"><a href="#bottleNeckPSP-608"><span class="linenos">608</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP-609"><a href="#bottleNeckPSP-609"><span class="linenos">609</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckPSP-610"><a href="#bottleNeckPSP-610"><span class="linenos">610</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP-611"><a href="#bottleNeckPSP-611"><span class="linenos">611</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP-612"><a href="#bottleNeckPSP-612"><span class="linenos">612</span></a>        <span class="p">)</span>
</span><span id="bottleNeckPSP-613"><a href="#bottleNeckPSP-613"><span class="linenos">613</span></a>        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="bottleNeckPSP-614"><a href="#bottleNeckPSP-614"><span class="linenos">614</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckPSP-615"><a href="#bottleNeckPSP-615"><span class="linenos">615</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-616"><a href="#bottleNeckPSP-616"><span class="linenos">616</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-617"><a href="#bottleNeckPSP-617"><span class="linenos">617</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="bottleNeckPSP-618"><a href="#bottleNeckPSP-618"><span class="linenos">618</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="bottleNeckPSP-619"><a href="#bottleNeckPSP-619"><span class="linenos">619</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="bottleNeckPSP-620"><a href="#bottleNeckPSP-620"><span class="linenos">620</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP-621"><a href="#bottleNeckPSP-621"><span class="linenos">621</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="bottleNeckPSP-622"><a href="#bottleNeckPSP-622"><span class="linenos">622</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP-623"><a href="#bottleNeckPSP-623"><span class="linenos">623</span></a>            <span class="p">)</span>
</span><span id="bottleNeckPSP-624"><a href="#bottleNeckPSP-624"><span class="linenos">624</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="bottleNeckPSP-625"><a href="#bottleNeckPSP-625"><span class="linenos">625</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckPSP-626"><a href="#bottleNeckPSP-626"><span class="linenos">626</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-627"><a href="#bottleNeckPSP-627"><span class="linenos">627</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-628"><a href="#bottleNeckPSP-628"><span class="linenos">628</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="bottleNeckPSP-629"><a href="#bottleNeckPSP-629"><span class="linenos">629</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="bottleNeckPSP-630"><a href="#bottleNeckPSP-630"><span class="linenos">630</span></a>                <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP-631"><a href="#bottleNeckPSP-631"><span class="linenos">631</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP-632"><a href="#bottleNeckPSP-632"><span class="linenos">632</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP-633"><a href="#bottleNeckPSP-633"><span class="linenos">633</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP-634"><a href="#bottleNeckPSP-634"><span class="linenos">634</span></a>            <span class="p">)</span>
</span><span id="bottleNeckPSP-635"><a href="#bottleNeckPSP-635"><span class="linenos">635</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="bottleNeckPSP-636"><a href="#bottleNeckPSP-636"><span class="linenos">636</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-637"><a href="#bottleNeckPSP-637"><span class="linenos">637</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-638"><a href="#bottleNeckPSP-638"><span class="linenos">638</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP-639"><a href="#bottleNeckPSP-639"><span class="linenos">639</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP-640"><a href="#bottleNeckPSP-640"><span class="linenos">640</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckPSP-641"><a href="#bottleNeckPSP-641"><span class="linenos">641</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP-642"><a href="#bottleNeckPSP-642"><span class="linenos">642</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP-643"><a href="#bottleNeckPSP-643"><span class="linenos">643</span></a>        <span class="p">)</span>
</span><span id="bottleNeckPSP-644"><a href="#bottleNeckPSP-644"><span class="linenos">644</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cb4</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="bottleNeckPSP-645"><a href="#bottleNeckPSP-645"><span class="linenos">645</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-646"><a href="#bottleNeckPSP-646"><span class="linenos">646</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP-647"><a href="#bottleNeckPSP-647"><span class="linenos">647</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP-648"><a href="#bottleNeckPSP-648"><span class="linenos">648</span></a>            <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="bottleNeckPSP-649"><a href="#bottleNeckPSP-649"><span class="linenos">649</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckPSP-650"><a href="#bottleNeckPSP-650"><span class="linenos">650</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP-651"><a href="#bottleNeckPSP-651"><span class="linenos">651</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP-652"><a href="#bottleNeckPSP-652"><span class="linenos">652</span></a>        <span class="p">)</span>
</span><span id="bottleNeckPSP-653"><a href="#bottleNeckPSP-653"><span class="linenos">653</span></a>
</span><span id="bottleNeckPSP-654"><a href="#bottleNeckPSP-654"><span class="linenos">654</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="bottleNeckPSP-655"><a href="#bottleNeckPSP-655"><span class="linenos">655</span></a>        <span class="n">conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="bottleNeckPSP-656"><a href="#bottleNeckPSP-656"><span class="linenos">656</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="bottleNeckPSP-657"><a href="#bottleNeckPSP-657"><span class="linenos">657</span></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv</span> <span class="o">+</span> <span class="n">residual</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#bottleNeckPSP.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#bottleNeckPSP.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="bottleNeckPSP.__init__" class="classattr">
                                        <input id="bottleNeckPSP.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">bottleNeckPSP</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">in_channels</span>,</span><span class="param">	<span class="n">mid_channels</span>,</span><span class="param">	<span class="n">out_channels</span>,</span><span class="param">	<span class="n">stride</span>,</span><span class="param">	<span class="n">dilation</span><span class="o">=</span><span class="mi">1</span>,</span><span class="param">	<span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="bottleNeckPSP.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#bottleNeckPSP.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="bottleNeckPSP.__init__-597"><a href="#bottleNeckPSP.__init__-597"><span class="linenos">597</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="bottleNeckPSP.__init__-598"><a href="#bottleNeckPSP.__init__-598"><span class="linenos">598</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span>
</span><span id="bottleNeckPSP.__init__-599"><a href="#bottleNeckPSP.__init__-599"><span class="linenos">599</span></a>    <span class="p">):</span>
</span><span id="bottleNeckPSP.__init__-600"><a href="#bottleNeckPSP.__init__-600"><span class="linenos">600</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">bottleNeckPSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="bottleNeckPSP.__init__-601"><a href="#bottleNeckPSP.__init__-601"><span class="linenos">601</span></a>
</span><span id="bottleNeckPSP.__init__-602"><a href="#bottleNeckPSP.__init__-602"><span class="linenos">602</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="bottleNeckPSP.__init__-603"><a href="#bottleNeckPSP.__init__-603"><span class="linenos">603</span></a>
</span><span id="bottleNeckPSP.__init__-604"><a href="#bottleNeckPSP.__init__-604"><span class="linenos">604</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckPSP.__init__-605"><a href="#bottleNeckPSP.__init__-605"><span class="linenos">605</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-606"><a href="#bottleNeckPSP.__init__-606"><span class="linenos">606</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-607"><a href="#bottleNeckPSP.__init__-607"><span class="linenos">607</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-608"><a href="#bottleNeckPSP.__init__-608"><span class="linenos">608</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-609"><a href="#bottleNeckPSP.__init__-609"><span class="linenos">609</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-610"><a href="#bottleNeckPSP.__init__-610"><span class="linenos">610</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-611"><a href="#bottleNeckPSP.__init__-611"><span class="linenos">611</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-612"><a href="#bottleNeckPSP.__init__-612"><span class="linenos">612</span></a>        <span class="p">)</span>
</span><span id="bottleNeckPSP.__init__-613"><a href="#bottleNeckPSP.__init__-613"><span class="linenos">613</span></a>        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="bottleNeckPSP.__init__-614"><a href="#bottleNeckPSP.__init__-614"><span class="linenos">614</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckPSP.__init__-615"><a href="#bottleNeckPSP.__init__-615"><span class="linenos">615</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-616"><a href="#bottleNeckPSP.__init__-616"><span class="linenos">616</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-617"><a href="#bottleNeckPSP.__init__-617"><span class="linenos">617</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-618"><a href="#bottleNeckPSP.__init__-618"><span class="linenos">618</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-619"><a href="#bottleNeckPSP.__init__-619"><span class="linenos">619</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-620"><a href="#bottleNeckPSP.__init__-620"><span class="linenos">620</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-621"><a href="#bottleNeckPSP.__init__-621"><span class="linenos">621</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-622"><a href="#bottleNeckPSP.__init__-622"><span class="linenos">622</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-623"><a href="#bottleNeckPSP.__init__-623"><span class="linenos">623</span></a>            <span class="p">)</span>
</span><span id="bottleNeckPSP.__init__-624"><a href="#bottleNeckPSP.__init__-624"><span class="linenos">624</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="bottleNeckPSP.__init__-625"><a href="#bottleNeckPSP.__init__-625"><span class="linenos">625</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckPSP.__init__-626"><a href="#bottleNeckPSP.__init__-626"><span class="linenos">626</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-627"><a href="#bottleNeckPSP.__init__-627"><span class="linenos">627</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-628"><a href="#bottleNeckPSP.__init__-628"><span class="linenos">628</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-629"><a href="#bottleNeckPSP.__init__-629"><span class="linenos">629</span></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-630"><a href="#bottleNeckPSP.__init__-630"><span class="linenos">630</span></a>                <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-631"><a href="#bottleNeckPSP.__init__-631"><span class="linenos">631</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-632"><a href="#bottleNeckPSP.__init__-632"><span class="linenos">632</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-633"><a href="#bottleNeckPSP.__init__-633"><span class="linenos">633</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-634"><a href="#bottleNeckPSP.__init__-634"><span class="linenos">634</span></a>            <span class="p">)</span>
</span><span id="bottleNeckPSP.__init__-635"><a href="#bottleNeckPSP.__init__-635"><span class="linenos">635</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="bottleNeckPSP.__init__-636"><a href="#bottleNeckPSP.__init__-636"><span class="linenos">636</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-637"><a href="#bottleNeckPSP.__init__-637"><span class="linenos">637</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-638"><a href="#bottleNeckPSP.__init__-638"><span class="linenos">638</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-639"><a href="#bottleNeckPSP.__init__-639"><span class="linenos">639</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-640"><a href="#bottleNeckPSP.__init__-640"><span class="linenos">640</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-641"><a href="#bottleNeckPSP.__init__-641"><span class="linenos">641</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-642"><a href="#bottleNeckPSP.__init__-642"><span class="linenos">642</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-643"><a href="#bottleNeckPSP.__init__-643"><span class="linenos">643</span></a>        <span class="p">)</span>
</span><span id="bottleNeckPSP.__init__-644"><a href="#bottleNeckPSP.__init__-644"><span class="linenos">644</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cb4</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="bottleNeckPSP.__init__-645"><a href="#bottleNeckPSP.__init__-645"><span class="linenos">645</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-646"><a href="#bottleNeckPSP.__init__-646"><span class="linenos">646</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-647"><a href="#bottleNeckPSP.__init__-647"><span class="linenos">647</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-648"><a href="#bottleNeckPSP.__init__-648"><span class="linenos">648</span></a>            <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-649"><a href="#bottleNeckPSP.__init__-649"><span class="linenos">649</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-650"><a href="#bottleNeckPSP.__init__-650"><span class="linenos">650</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-651"><a href="#bottleNeckPSP.__init__-651"><span class="linenos">651</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckPSP.__init__-652"><a href="#bottleNeckPSP.__init__-652"><span class="linenos">652</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="bottleNeckPSP.forward" class="classattr">
                                        <input id="bottleNeckPSP.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="bottleNeckPSP.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#bottleNeckPSP.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="bottleNeckPSP.forward-654"><a href="#bottleNeckPSP.forward-654"><span class="linenos">654</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="bottleNeckPSP.forward-655"><a href="#bottleNeckPSP.forward-655"><span class="linenos">655</span></a>        <span class="n">conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="bottleNeckPSP.forward-656"><a href="#bottleNeckPSP.forward-656"><span class="linenos">656</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="bottleNeckPSP.forward-657"><a href="#bottleNeckPSP.forward-657"><span class="linenos">657</span></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv</span> <span class="o">+</span> <span class="n">residual</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="bottleNeckPSP.dump_patches" class="variable">dump_patches</dd>
                <dd id="bottleNeckPSP.register_buffer" class="function">register_buffer</dd>
                <dd id="bottleNeckPSP.register_parameter" class="function">register_parameter</dd>
                <dd id="bottleNeckPSP.add_module" class="function">add_module</dd>
                <dd id="bottleNeckPSP.register_module" class="function">register_module</dd>
                <dd id="bottleNeckPSP.get_submodule" class="function">get_submodule</dd>
                <dd id="bottleNeckPSP.get_parameter" class="function">get_parameter</dd>
                <dd id="bottleNeckPSP.get_buffer" class="function">get_buffer</dd>
                <dd id="bottleNeckPSP.get_extra_state" class="function">get_extra_state</dd>
                <dd id="bottleNeckPSP.set_extra_state" class="function">set_extra_state</dd>
                <dd id="bottleNeckPSP.apply" class="function">apply</dd>
                <dd id="bottleNeckPSP.cuda" class="function">cuda</dd>
                <dd id="bottleNeckPSP.ipu" class="function">ipu</dd>
                <dd id="bottleNeckPSP.xpu" class="function">xpu</dd>
                <dd id="bottleNeckPSP.cpu" class="function">cpu</dd>
                <dd id="bottleNeckPSP.type" class="function">type</dd>
                <dd id="bottleNeckPSP.float" class="function">float</dd>
                <dd id="bottleNeckPSP.double" class="function">double</dd>
                <dd id="bottleNeckPSP.half" class="function">half</dd>
                <dd id="bottleNeckPSP.bfloat16" class="function">bfloat16</dd>
                <dd id="bottleNeckPSP.to_empty" class="function">to_empty</dd>
                <dd id="bottleNeckPSP.to" class="function">to</dd>
                <dd id="bottleNeckPSP.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="bottleNeckPSP.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="bottleNeckPSP.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="bottleNeckPSP.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="bottleNeckPSP.T_destination" class="variable">T_destination</dd>
                <dd id="bottleNeckPSP.state_dict" class="function">state_dict</dd>
                <dd id="bottleNeckPSP.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="bottleNeckPSP.load_state_dict" class="function">load_state_dict</dd>
                <dd id="bottleNeckPSP.parameters" class="function">parameters</dd>
                <dd id="bottleNeckPSP.named_parameters" class="function">named_parameters</dd>
                <dd id="bottleNeckPSP.buffers" class="function">buffers</dd>
                <dd id="bottleNeckPSP.named_buffers" class="function">named_buffers</dd>
                <dd id="bottleNeckPSP.children" class="function">children</dd>
                <dd id="bottleNeckPSP.named_children" class="function">named_children</dd>
                <dd id="bottleNeckPSP.modules" class="function">modules</dd>
                <dd id="bottleNeckPSP.named_modules" class="function">named_modules</dd>
                <dd id="bottleNeckPSP.train" class="function">train</dd>
                <dd id="bottleNeckPSP.eval" class="function">eval</dd>
                <dd id="bottleNeckPSP.requires_grad_" class="function">requires_grad_</dd>
                <dd id="bottleNeckPSP.zero_grad" class="function">zero_grad</dd>
                <dd id="bottleNeckPSP.share_memory" class="function">share_memory</dd>
                <dd id="bottleNeckPSP.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="bottleNeckIdentifyPSP">
                            <input id="bottleNeckIdentifyPSP-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">bottleNeckIdentifyPSP</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="bottleNeckIdentifyPSP-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#bottleNeckIdentifyPSP"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="bottleNeckIdentifyPSP-660"><a href="#bottleNeckIdentifyPSP-660"><span class="linenos">660</span></a><span class="k">class</span> <span class="nc">bottleNeckIdentifyPSP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="bottleNeckIdentifyPSP-661"><a href="#bottleNeckIdentifyPSP-661"><span class="linenos">661</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="bottleNeckIdentifyPSP-662"><a href="#bottleNeckIdentifyPSP-662"><span class="linenos">662</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">bottleNeckIdentifyPSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="bottleNeckIdentifyPSP-663"><a href="#bottleNeckIdentifyPSP-663"><span class="linenos">663</span></a>
</span><span id="bottleNeckIdentifyPSP-664"><a href="#bottleNeckIdentifyPSP-664"><span class="linenos">664</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="bottleNeckIdentifyPSP-665"><a href="#bottleNeckIdentifyPSP-665"><span class="linenos">665</span></a>
</span><span id="bottleNeckIdentifyPSP-666"><a href="#bottleNeckIdentifyPSP-666"><span class="linenos">666</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckIdentifyPSP-667"><a href="#bottleNeckIdentifyPSP-667"><span class="linenos">667</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-668"><a href="#bottleNeckIdentifyPSP-668"><span class="linenos">668</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-669"><a href="#bottleNeckIdentifyPSP-669"><span class="linenos">669</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-670"><a href="#bottleNeckIdentifyPSP-670"><span class="linenos">670</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-671"><a href="#bottleNeckIdentifyPSP-671"><span class="linenos">671</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-672"><a href="#bottleNeckIdentifyPSP-672"><span class="linenos">672</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-673"><a href="#bottleNeckIdentifyPSP-673"><span class="linenos">673</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-674"><a href="#bottleNeckIdentifyPSP-674"><span class="linenos">674</span></a>        <span class="p">)</span>
</span><span id="bottleNeckIdentifyPSP-675"><a href="#bottleNeckIdentifyPSP-675"><span class="linenos">675</span></a>        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="bottleNeckIdentifyPSP-676"><a href="#bottleNeckIdentifyPSP-676"><span class="linenos">676</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckIdentifyPSP-677"><a href="#bottleNeckIdentifyPSP-677"><span class="linenos">677</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-678"><a href="#bottleNeckIdentifyPSP-678"><span class="linenos">678</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-679"><a href="#bottleNeckIdentifyPSP-679"><span class="linenos">679</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-680"><a href="#bottleNeckIdentifyPSP-680"><span class="linenos">680</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-681"><a href="#bottleNeckIdentifyPSP-681"><span class="linenos">681</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-682"><a href="#bottleNeckIdentifyPSP-682"><span class="linenos">682</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-683"><a href="#bottleNeckIdentifyPSP-683"><span class="linenos">683</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-684"><a href="#bottleNeckIdentifyPSP-684"><span class="linenos">684</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-685"><a href="#bottleNeckIdentifyPSP-685"><span class="linenos">685</span></a>            <span class="p">)</span>
</span><span id="bottleNeckIdentifyPSP-686"><a href="#bottleNeckIdentifyPSP-686"><span class="linenos">686</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="bottleNeckIdentifyPSP-687"><a href="#bottleNeckIdentifyPSP-687"><span class="linenos">687</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckIdentifyPSP-688"><a href="#bottleNeckIdentifyPSP-688"><span class="linenos">688</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-689"><a href="#bottleNeckIdentifyPSP-689"><span class="linenos">689</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-690"><a href="#bottleNeckIdentifyPSP-690"><span class="linenos">690</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-691"><a href="#bottleNeckIdentifyPSP-691"><span class="linenos">691</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-692"><a href="#bottleNeckIdentifyPSP-692"><span class="linenos">692</span></a>                <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-693"><a href="#bottleNeckIdentifyPSP-693"><span class="linenos">693</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-694"><a href="#bottleNeckIdentifyPSP-694"><span class="linenos">694</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-695"><a href="#bottleNeckIdentifyPSP-695"><span class="linenos">695</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-696"><a href="#bottleNeckIdentifyPSP-696"><span class="linenos">696</span></a>            <span class="p">)</span>
</span><span id="bottleNeckIdentifyPSP-697"><a href="#bottleNeckIdentifyPSP-697"><span class="linenos">697</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="bottleNeckIdentifyPSP-698"><a href="#bottleNeckIdentifyPSP-698"><span class="linenos">698</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-699"><a href="#bottleNeckIdentifyPSP-699"><span class="linenos">699</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-700"><a href="#bottleNeckIdentifyPSP-700"><span class="linenos">700</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-701"><a href="#bottleNeckIdentifyPSP-701"><span class="linenos">701</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-702"><a href="#bottleNeckIdentifyPSP-702"><span class="linenos">702</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-703"><a href="#bottleNeckIdentifyPSP-703"><span class="linenos">703</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-704"><a href="#bottleNeckIdentifyPSP-704"><span class="linenos">704</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP-705"><a href="#bottleNeckIdentifyPSP-705"><span class="linenos">705</span></a>        <span class="p">)</span>
</span><span id="bottleNeckIdentifyPSP-706"><a href="#bottleNeckIdentifyPSP-706"><span class="linenos">706</span></a>
</span><span id="bottleNeckIdentifyPSP-707"><a href="#bottleNeckIdentifyPSP-707"><span class="linenos">707</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="bottleNeckIdentifyPSP-708"><a href="#bottleNeckIdentifyPSP-708"><span class="linenos">708</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="bottleNeckIdentifyPSP-709"><a href="#bottleNeckIdentifyPSP-709"><span class="linenos">709</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="bottleNeckIdentifyPSP-710"><a href="#bottleNeckIdentifyPSP-710"><span class="linenos">710</span></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">residual</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#bottleNeckIdentifyPSP.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#bottleNeckIdentifyPSP.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="bottleNeckIdentifyPSP.__init__" class="classattr">
                                        <input id="bottleNeckIdentifyPSP.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">bottleNeckIdentifyPSP</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_channels</span>, </span><span class="param"><span class="n">mid_channels</span>, </span><span class="param"><span class="n">stride</span>, </span><span class="param"><span class="n">dilation</span><span class="o">=</span><span class="mi">1</span>, </span><span class="param"><span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="bottleNeckIdentifyPSP.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#bottleNeckIdentifyPSP.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="bottleNeckIdentifyPSP.__init__-661"><a href="#bottleNeckIdentifyPSP.__init__-661"><span class="linenos">661</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="bottleNeckIdentifyPSP.__init__-662"><a href="#bottleNeckIdentifyPSP.__init__-662"><span class="linenos">662</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">bottleNeckIdentifyPSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="bottleNeckIdentifyPSP.__init__-663"><a href="#bottleNeckIdentifyPSP.__init__-663"><span class="linenos">663</span></a>
</span><span id="bottleNeckIdentifyPSP.__init__-664"><a href="#bottleNeckIdentifyPSP.__init__-664"><span class="linenos">664</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="bottleNeckIdentifyPSP.__init__-665"><a href="#bottleNeckIdentifyPSP.__init__-665"><span class="linenos">665</span></a>
</span><span id="bottleNeckIdentifyPSP.__init__-666"><a href="#bottleNeckIdentifyPSP.__init__-666"><span class="linenos">666</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckIdentifyPSP.__init__-667"><a href="#bottleNeckIdentifyPSP.__init__-667"><span class="linenos">667</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-668"><a href="#bottleNeckIdentifyPSP.__init__-668"><span class="linenos">668</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-669"><a href="#bottleNeckIdentifyPSP.__init__-669"><span class="linenos">669</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-670"><a href="#bottleNeckIdentifyPSP.__init__-670"><span class="linenos">670</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-671"><a href="#bottleNeckIdentifyPSP.__init__-671"><span class="linenos">671</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-672"><a href="#bottleNeckIdentifyPSP.__init__-672"><span class="linenos">672</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-673"><a href="#bottleNeckIdentifyPSP.__init__-673"><span class="linenos">673</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-674"><a href="#bottleNeckIdentifyPSP.__init__-674"><span class="linenos">674</span></a>        <span class="p">)</span>
</span><span id="bottleNeckIdentifyPSP.__init__-675"><a href="#bottleNeckIdentifyPSP.__init__-675"><span class="linenos">675</span></a>        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="bottleNeckIdentifyPSP.__init__-676"><a href="#bottleNeckIdentifyPSP.__init__-676"><span class="linenos">676</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckIdentifyPSP.__init__-677"><a href="#bottleNeckIdentifyPSP.__init__-677"><span class="linenos">677</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-678"><a href="#bottleNeckIdentifyPSP.__init__-678"><span class="linenos">678</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-679"><a href="#bottleNeckIdentifyPSP.__init__-679"><span class="linenos">679</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-680"><a href="#bottleNeckIdentifyPSP.__init__-680"><span class="linenos">680</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-681"><a href="#bottleNeckIdentifyPSP.__init__-681"><span class="linenos">681</span></a>                <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-682"><a href="#bottleNeckIdentifyPSP.__init__-682"><span class="linenos">682</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-683"><a href="#bottleNeckIdentifyPSP.__init__-683"><span class="linenos">683</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-684"><a href="#bottleNeckIdentifyPSP.__init__-684"><span class="linenos">684</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-685"><a href="#bottleNeckIdentifyPSP.__init__-685"><span class="linenos">685</span></a>            <span class="p">)</span>
</span><span id="bottleNeckIdentifyPSP.__init__-686"><a href="#bottleNeckIdentifyPSP.__init__-686"><span class="linenos">686</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="bottleNeckIdentifyPSP.__init__-687"><a href="#bottleNeckIdentifyPSP.__init__-687"><span class="linenos">687</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span> <span class="o">=</span> <span class="n">conv2DBatchNormRelu</span><span class="p">(</span>
</span><span id="bottleNeckIdentifyPSP.__init__-688"><a href="#bottleNeckIdentifyPSP.__init__-688"><span class="linenos">688</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-689"><a href="#bottleNeckIdentifyPSP.__init__-689"><span class="linenos">689</span></a>                <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-690"><a href="#bottleNeckIdentifyPSP.__init__-690"><span class="linenos">690</span></a>                <span class="mi">3</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-691"><a href="#bottleNeckIdentifyPSP.__init__-691"><span class="linenos">691</span></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-692"><a href="#bottleNeckIdentifyPSP.__init__-692"><span class="linenos">692</span></a>                <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-693"><a href="#bottleNeckIdentifyPSP.__init__-693"><span class="linenos">693</span></a>                <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-694"><a href="#bottleNeckIdentifyPSP.__init__-694"><span class="linenos">694</span></a>                <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-695"><a href="#bottleNeckIdentifyPSP.__init__-695"><span class="linenos">695</span></a>                <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-696"><a href="#bottleNeckIdentifyPSP.__init__-696"><span class="linenos">696</span></a>            <span class="p">)</span>
</span><span id="bottleNeckIdentifyPSP.__init__-697"><a href="#bottleNeckIdentifyPSP.__init__-697"><span class="linenos">697</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="bottleNeckIdentifyPSP.__init__-698"><a href="#bottleNeckIdentifyPSP.__init__-698"><span class="linenos">698</span></a>            <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-699"><a href="#bottleNeckIdentifyPSP.__init__-699"><span class="linenos">699</span></a>            <span class="n">in_channels</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-700"><a href="#bottleNeckIdentifyPSP.__init__-700"><span class="linenos">700</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-701"><a href="#bottleNeckIdentifyPSP.__init__-701"><span class="linenos">701</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-702"><a href="#bottleNeckIdentifyPSP.__init__-702"><span class="linenos">702</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-703"><a href="#bottleNeckIdentifyPSP.__init__-703"><span class="linenos">703</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-704"><a href="#bottleNeckIdentifyPSP.__init__-704"><span class="linenos">704</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="bottleNeckIdentifyPSP.__init__-705"><a href="#bottleNeckIdentifyPSP.__init__-705"><span class="linenos">705</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="bottleNeckIdentifyPSP.forward" class="classattr">
                                        <input id="bottleNeckIdentifyPSP.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="bottleNeckIdentifyPSP.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#bottleNeckIdentifyPSP.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="bottleNeckIdentifyPSP.forward-707"><a href="#bottleNeckIdentifyPSP.forward-707"><span class="linenos">707</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="bottleNeckIdentifyPSP.forward-708"><a href="#bottleNeckIdentifyPSP.forward-708"><span class="linenos">708</span></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="bottleNeckIdentifyPSP.forward-709"><a href="#bottleNeckIdentifyPSP.forward-709"><span class="linenos">709</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cb3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cbr1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="bottleNeckIdentifyPSP.forward-710"><a href="#bottleNeckIdentifyPSP.forward-710"><span class="linenos">710</span></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">residual</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="bottleNeckIdentifyPSP.dump_patches" class="variable">dump_patches</dd>
                <dd id="bottleNeckIdentifyPSP.register_buffer" class="function">register_buffer</dd>
                <dd id="bottleNeckIdentifyPSP.register_parameter" class="function">register_parameter</dd>
                <dd id="bottleNeckIdentifyPSP.add_module" class="function">add_module</dd>
                <dd id="bottleNeckIdentifyPSP.register_module" class="function">register_module</dd>
                <dd id="bottleNeckIdentifyPSP.get_submodule" class="function">get_submodule</dd>
                <dd id="bottleNeckIdentifyPSP.get_parameter" class="function">get_parameter</dd>
                <dd id="bottleNeckIdentifyPSP.get_buffer" class="function">get_buffer</dd>
                <dd id="bottleNeckIdentifyPSP.get_extra_state" class="function">get_extra_state</dd>
                <dd id="bottleNeckIdentifyPSP.set_extra_state" class="function">set_extra_state</dd>
                <dd id="bottleNeckIdentifyPSP.apply" class="function">apply</dd>
                <dd id="bottleNeckIdentifyPSP.cuda" class="function">cuda</dd>
                <dd id="bottleNeckIdentifyPSP.ipu" class="function">ipu</dd>
                <dd id="bottleNeckIdentifyPSP.xpu" class="function">xpu</dd>
                <dd id="bottleNeckIdentifyPSP.cpu" class="function">cpu</dd>
                <dd id="bottleNeckIdentifyPSP.type" class="function">type</dd>
                <dd id="bottleNeckIdentifyPSP.float" class="function">float</dd>
                <dd id="bottleNeckIdentifyPSP.double" class="function">double</dd>
                <dd id="bottleNeckIdentifyPSP.half" class="function">half</dd>
                <dd id="bottleNeckIdentifyPSP.bfloat16" class="function">bfloat16</dd>
                <dd id="bottleNeckIdentifyPSP.to_empty" class="function">to_empty</dd>
                <dd id="bottleNeckIdentifyPSP.to" class="function">to</dd>
                <dd id="bottleNeckIdentifyPSP.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="bottleNeckIdentifyPSP.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="bottleNeckIdentifyPSP.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="bottleNeckIdentifyPSP.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="bottleNeckIdentifyPSP.T_destination" class="variable">T_destination</dd>
                <dd id="bottleNeckIdentifyPSP.state_dict" class="function">state_dict</dd>
                <dd id="bottleNeckIdentifyPSP.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="bottleNeckIdentifyPSP.load_state_dict" class="function">load_state_dict</dd>
                <dd id="bottleNeckIdentifyPSP.parameters" class="function">parameters</dd>
                <dd id="bottleNeckIdentifyPSP.named_parameters" class="function">named_parameters</dd>
                <dd id="bottleNeckIdentifyPSP.buffers" class="function">buffers</dd>
                <dd id="bottleNeckIdentifyPSP.named_buffers" class="function">named_buffers</dd>
                <dd id="bottleNeckIdentifyPSP.children" class="function">children</dd>
                <dd id="bottleNeckIdentifyPSP.named_children" class="function">named_children</dd>
                <dd id="bottleNeckIdentifyPSP.modules" class="function">modules</dd>
                <dd id="bottleNeckIdentifyPSP.named_modules" class="function">named_modules</dd>
                <dd id="bottleNeckIdentifyPSP.train" class="function">train</dd>
                <dd id="bottleNeckIdentifyPSP.eval" class="function">eval</dd>
                <dd id="bottleNeckIdentifyPSP.requires_grad_" class="function">requires_grad_</dd>
                <dd id="bottleNeckIdentifyPSP.zero_grad" class="function">zero_grad</dd>
                <dd id="bottleNeckIdentifyPSP.share_memory" class="function">share_memory</dd>
                <dd id="bottleNeckIdentifyPSP.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="residualBlockPSP">
                            <input id="residualBlockPSP-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">residualBlockPSP</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="residualBlockPSP-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualBlockPSP"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualBlockPSP-713"><a href="#residualBlockPSP-713"><span class="linenos">713</span></a><span class="k">class</span> <span class="nc">residualBlockPSP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="residualBlockPSP-714"><a href="#residualBlockPSP-714"><span class="linenos">714</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="residualBlockPSP-715"><a href="#residualBlockPSP-715"><span class="linenos">715</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="residualBlockPSP-716"><a href="#residualBlockPSP-716"><span class="linenos">716</span></a>        <span class="n">n_blocks</span><span class="p">,</span>
</span><span id="residualBlockPSP-717"><a href="#residualBlockPSP-717"><span class="linenos">717</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP-718"><a href="#residualBlockPSP-718"><span class="linenos">718</span></a>        <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP-719"><a href="#residualBlockPSP-719"><span class="linenos">719</span></a>        <span class="n">out_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP-720"><a href="#residualBlockPSP-720"><span class="linenos">720</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="residualBlockPSP-721"><a href="#residualBlockPSP-721"><span class="linenos">721</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="residualBlockPSP-722"><a href="#residualBlockPSP-722"><span class="linenos">722</span></a>        <span class="n">include_range</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
</span><span id="residualBlockPSP-723"><a href="#residualBlockPSP-723"><span class="linenos">723</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="residualBlockPSP-724"><a href="#residualBlockPSP-724"><span class="linenos">724</span></a>    <span class="p">):</span>
</span><span id="residualBlockPSP-725"><a href="#residualBlockPSP-725"><span class="linenos">725</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualBlockPSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="residualBlockPSP-726"><a href="#residualBlockPSP-726"><span class="linenos">726</span></a>
</span><span id="residualBlockPSP-727"><a href="#residualBlockPSP-727"><span class="linenos">727</span></a>        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="residualBlockPSP-728"><a href="#residualBlockPSP-728"><span class="linenos">728</span></a>            <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="residualBlockPSP-729"><a href="#residualBlockPSP-729"><span class="linenos">729</span></a>
</span><span id="residualBlockPSP-730"><a href="#residualBlockPSP-730"><span class="linenos">730</span></a>        <span class="c1"># residualBlockPSP = convBlockPSP + identityBlockPSPs</span>
</span><span id="residualBlockPSP-731"><a href="#residualBlockPSP-731"><span class="linenos">731</span></a>        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="residualBlockPSP-732"><a href="#residualBlockPSP-732"><span class="linenos">732</span></a>        <span class="k">if</span> <span class="n">include_range</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="s2">&quot;conv&quot;</span><span class="p">]:</span>
</span><span id="residualBlockPSP-733"><a href="#residualBlockPSP-733"><span class="linenos">733</span></a>            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="residualBlockPSP-734"><a href="#residualBlockPSP-734"><span class="linenos">734</span></a>                <span class="n">bottleNeckPSP</span><span class="p">(</span>
</span><span id="residualBlockPSP-735"><a href="#residualBlockPSP-735"><span class="linenos">735</span></a>                    <span class="n">in_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP-736"><a href="#residualBlockPSP-736"><span class="linenos">736</span></a>                    <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP-737"><a href="#residualBlockPSP-737"><span class="linenos">737</span></a>                    <span class="n">out_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP-738"><a href="#residualBlockPSP-738"><span class="linenos">738</span></a>                    <span class="n">stride</span><span class="p">,</span>
</span><span id="residualBlockPSP-739"><a href="#residualBlockPSP-739"><span class="linenos">739</span></a>                    <span class="n">dilation</span><span class="p">,</span>
</span><span id="residualBlockPSP-740"><a href="#residualBlockPSP-740"><span class="linenos">740</span></a>                    <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="residualBlockPSP-741"><a href="#residualBlockPSP-741"><span class="linenos">741</span></a>                <span class="p">)</span>
</span><span id="residualBlockPSP-742"><a href="#residualBlockPSP-742"><span class="linenos">742</span></a>            <span class="p">)</span>
</span><span id="residualBlockPSP-743"><a href="#residualBlockPSP-743"><span class="linenos">743</span></a>        <span class="k">if</span> <span class="n">include_range</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="s2">&quot;identity&quot;</span><span class="p">]:</span>
</span><span id="residualBlockPSP-744"><a href="#residualBlockPSP-744"><span class="linenos">744</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="residualBlockPSP-745"><a href="#residualBlockPSP-745"><span class="linenos">745</span></a>                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="residualBlockPSP-746"><a href="#residualBlockPSP-746"><span class="linenos">746</span></a>                    <span class="n">bottleNeckIdentifyPSP</span><span class="p">(</span>
</span><span id="residualBlockPSP-747"><a href="#residualBlockPSP-747"><span class="linenos">747</span></a>                        <span class="n">out_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span>
</span><span id="residualBlockPSP-748"><a href="#residualBlockPSP-748"><span class="linenos">748</span></a>                    <span class="p">)</span>
</span><span id="residualBlockPSP-749"><a href="#residualBlockPSP-749"><span class="linenos">749</span></a>                <span class="p">)</span>
</span><span id="residualBlockPSP-750"><a href="#residualBlockPSP-750"><span class="linenos">750</span></a>
</span><span id="residualBlockPSP-751"><a href="#residualBlockPSP-751"><span class="linenos">751</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</span><span id="residualBlockPSP-752"><a href="#residualBlockPSP-752"><span class="linenos">752</span></a>
</span><span id="residualBlockPSP-753"><a href="#residualBlockPSP-753"><span class="linenos">753</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="residualBlockPSP-754"><a href="#residualBlockPSP-754"><span class="linenos">754</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#residualBlockPSP.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#residualBlockPSP.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="residualBlockPSP.__init__" class="classattr">
                                        <input id="residualBlockPSP.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">residualBlockPSP</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">n_blocks</span>,</span><span class="param">	<span class="n">in_channels</span>,</span><span class="param">	<span class="n">mid_channels</span>,</span><span class="param">	<span class="n">out_channels</span>,</span><span class="param">	<span class="n">stride</span>,</span><span class="param">	<span class="n">dilation</span><span class="o">=</span><span class="mi">1</span>,</span><span class="param">	<span class="n">include_range</span><span class="o">=</span><span class="s1">&#39;all&#39;</span>,</span><span class="param">	<span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="residualBlockPSP.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualBlockPSP.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualBlockPSP.__init__-714"><a href="#residualBlockPSP.__init__-714"><span class="linenos">714</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="residualBlockPSP.__init__-715"><a href="#residualBlockPSP.__init__-715"><span class="linenos">715</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-716"><a href="#residualBlockPSP.__init__-716"><span class="linenos">716</span></a>        <span class="n">n_blocks</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-717"><a href="#residualBlockPSP.__init__-717"><span class="linenos">717</span></a>        <span class="n">in_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-718"><a href="#residualBlockPSP.__init__-718"><span class="linenos">718</span></a>        <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-719"><a href="#residualBlockPSP.__init__-719"><span class="linenos">719</span></a>        <span class="n">out_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-720"><a href="#residualBlockPSP.__init__-720"><span class="linenos">720</span></a>        <span class="n">stride</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-721"><a href="#residualBlockPSP.__init__-721"><span class="linenos">721</span></a>        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-722"><a href="#residualBlockPSP.__init__-722"><span class="linenos">722</span></a>        <span class="n">include_range</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-723"><a href="#residualBlockPSP.__init__-723"><span class="linenos">723</span></a>        <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-724"><a href="#residualBlockPSP.__init__-724"><span class="linenos">724</span></a>    <span class="p">):</span>
</span><span id="residualBlockPSP.__init__-725"><a href="#residualBlockPSP.__init__-725"><span class="linenos">725</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">residualBlockPSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="residualBlockPSP.__init__-726"><a href="#residualBlockPSP.__init__-726"><span class="linenos">726</span></a>
</span><span id="residualBlockPSP.__init__-727"><a href="#residualBlockPSP.__init__-727"><span class="linenos">727</span></a>        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="residualBlockPSP.__init__-728"><a href="#residualBlockPSP.__init__-728"><span class="linenos">728</span></a>            <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="residualBlockPSP.__init__-729"><a href="#residualBlockPSP.__init__-729"><span class="linenos">729</span></a>
</span><span id="residualBlockPSP.__init__-730"><a href="#residualBlockPSP.__init__-730"><span class="linenos">730</span></a>        <span class="c1"># residualBlockPSP = convBlockPSP + identityBlockPSPs</span>
</span><span id="residualBlockPSP.__init__-731"><a href="#residualBlockPSP.__init__-731"><span class="linenos">731</span></a>        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="residualBlockPSP.__init__-732"><a href="#residualBlockPSP.__init__-732"><span class="linenos">732</span></a>        <span class="k">if</span> <span class="n">include_range</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="s2">&quot;conv&quot;</span><span class="p">]:</span>
</span><span id="residualBlockPSP.__init__-733"><a href="#residualBlockPSP.__init__-733"><span class="linenos">733</span></a>            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="residualBlockPSP.__init__-734"><a href="#residualBlockPSP.__init__-734"><span class="linenos">734</span></a>                <span class="n">bottleNeckPSP</span><span class="p">(</span>
</span><span id="residualBlockPSP.__init__-735"><a href="#residualBlockPSP.__init__-735"><span class="linenos">735</span></a>                    <span class="n">in_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-736"><a href="#residualBlockPSP.__init__-736"><span class="linenos">736</span></a>                    <span class="n">mid_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-737"><a href="#residualBlockPSP.__init__-737"><span class="linenos">737</span></a>                    <span class="n">out_channels</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-738"><a href="#residualBlockPSP.__init__-738"><span class="linenos">738</span></a>                    <span class="n">stride</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-739"><a href="#residualBlockPSP.__init__-739"><span class="linenos">739</span></a>                    <span class="n">dilation</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-740"><a href="#residualBlockPSP.__init__-740"><span class="linenos">740</span></a>                    <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="residualBlockPSP.__init__-741"><a href="#residualBlockPSP.__init__-741"><span class="linenos">741</span></a>                <span class="p">)</span>
</span><span id="residualBlockPSP.__init__-742"><a href="#residualBlockPSP.__init__-742"><span class="linenos">742</span></a>            <span class="p">)</span>
</span><span id="residualBlockPSP.__init__-743"><a href="#residualBlockPSP.__init__-743"><span class="linenos">743</span></a>        <span class="k">if</span> <span class="n">include_range</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="s2">&quot;identity&quot;</span><span class="p">]:</span>
</span><span id="residualBlockPSP.__init__-744"><a href="#residualBlockPSP.__init__-744"><span class="linenos">744</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="residualBlockPSP.__init__-745"><a href="#residualBlockPSP.__init__-745"><span class="linenos">745</span></a>                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="residualBlockPSP.__init__-746"><a href="#residualBlockPSP.__init__-746"><span class="linenos">746</span></a>                    <span class="n">bottleNeckIdentifyPSP</span><span class="p">(</span>
</span><span id="residualBlockPSP.__init__-747"><a href="#residualBlockPSP.__init__-747"><span class="linenos">747</span></a>                        <span class="n">out_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span>
</span><span id="residualBlockPSP.__init__-748"><a href="#residualBlockPSP.__init__-748"><span class="linenos">748</span></a>                    <span class="p">)</span>
</span><span id="residualBlockPSP.__init__-749"><a href="#residualBlockPSP.__init__-749"><span class="linenos">749</span></a>                <span class="p">)</span>
</span><span id="residualBlockPSP.__init__-750"><a href="#residualBlockPSP.__init__-750"><span class="linenos">750</span></a>
</span><span id="residualBlockPSP.__init__-751"><a href="#residualBlockPSP.__init__-751"><span class="linenos">751</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="residualBlockPSP.forward" class="classattr">
                                        <input id="residualBlockPSP.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="residualBlockPSP.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#residualBlockPSP.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="residualBlockPSP.forward-753"><a href="#residualBlockPSP.forward-753"><span class="linenos">753</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="residualBlockPSP.forward-754"><a href="#residualBlockPSP.forward-754"><span class="linenos">754</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="residualBlockPSP.dump_patches" class="variable">dump_patches</dd>
                <dd id="residualBlockPSP.register_buffer" class="function">register_buffer</dd>
                <dd id="residualBlockPSP.register_parameter" class="function">register_parameter</dd>
                <dd id="residualBlockPSP.add_module" class="function">add_module</dd>
                <dd id="residualBlockPSP.register_module" class="function">register_module</dd>
                <dd id="residualBlockPSP.get_submodule" class="function">get_submodule</dd>
                <dd id="residualBlockPSP.get_parameter" class="function">get_parameter</dd>
                <dd id="residualBlockPSP.get_buffer" class="function">get_buffer</dd>
                <dd id="residualBlockPSP.get_extra_state" class="function">get_extra_state</dd>
                <dd id="residualBlockPSP.set_extra_state" class="function">set_extra_state</dd>
                <dd id="residualBlockPSP.apply" class="function">apply</dd>
                <dd id="residualBlockPSP.cuda" class="function">cuda</dd>
                <dd id="residualBlockPSP.ipu" class="function">ipu</dd>
                <dd id="residualBlockPSP.xpu" class="function">xpu</dd>
                <dd id="residualBlockPSP.cpu" class="function">cpu</dd>
                <dd id="residualBlockPSP.type" class="function">type</dd>
                <dd id="residualBlockPSP.float" class="function">float</dd>
                <dd id="residualBlockPSP.double" class="function">double</dd>
                <dd id="residualBlockPSP.half" class="function">half</dd>
                <dd id="residualBlockPSP.bfloat16" class="function">bfloat16</dd>
                <dd id="residualBlockPSP.to_empty" class="function">to_empty</dd>
                <dd id="residualBlockPSP.to" class="function">to</dd>
                <dd id="residualBlockPSP.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="residualBlockPSP.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="residualBlockPSP.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="residualBlockPSP.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="residualBlockPSP.T_destination" class="variable">T_destination</dd>
                <dd id="residualBlockPSP.state_dict" class="function">state_dict</dd>
                <dd id="residualBlockPSP.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="residualBlockPSP.load_state_dict" class="function">load_state_dict</dd>
                <dd id="residualBlockPSP.parameters" class="function">parameters</dd>
                <dd id="residualBlockPSP.named_parameters" class="function">named_parameters</dd>
                <dd id="residualBlockPSP.buffers" class="function">buffers</dd>
                <dd id="residualBlockPSP.named_buffers" class="function">named_buffers</dd>
                <dd id="residualBlockPSP.children" class="function">children</dd>
                <dd id="residualBlockPSP.named_children" class="function">named_children</dd>
                <dd id="residualBlockPSP.modules" class="function">modules</dd>
                <dd id="residualBlockPSP.named_modules" class="function">named_modules</dd>
                <dd id="residualBlockPSP.train" class="function">train</dd>
                <dd id="residualBlockPSP.eval" class="function">eval</dd>
                <dd id="residualBlockPSP.requires_grad_" class="function">requires_grad_</dd>
                <dd id="residualBlockPSP.zero_grad" class="function">zero_grad</dd>
                <dd id="residualBlockPSP.share_memory" class="function">share_memory</dd>
                <dd id="residualBlockPSP.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="cascadeFeatureFusion">
                            <input id="cascadeFeatureFusion-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">cascadeFeatureFusion</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="cascadeFeatureFusion-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#cascadeFeatureFusion"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="cascadeFeatureFusion-757"><a href="#cascadeFeatureFusion-757"><span class="linenos">757</span></a><span class="k">class</span> <span class="nc">cascadeFeatureFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="cascadeFeatureFusion-758"><a href="#cascadeFeatureFusion-758"><span class="linenos">758</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion-759"><a href="#cascadeFeatureFusion-759"><span class="linenos">759</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">low_in_channels</span><span class="p">,</span> <span class="n">high_in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span>
</span><span id="cascadeFeatureFusion-760"><a href="#cascadeFeatureFusion-760"><span class="linenos">760</span></a>    <span class="p">):</span>
</span><span id="cascadeFeatureFusion-761"><a href="#cascadeFeatureFusion-761"><span class="linenos">761</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">cascadeFeatureFusion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="cascadeFeatureFusion-762"><a href="#cascadeFeatureFusion-762"><span class="linenos">762</span></a>
</span><span id="cascadeFeatureFusion-763"><a href="#cascadeFeatureFusion-763"><span class="linenos">763</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="cascadeFeatureFusion-764"><a href="#cascadeFeatureFusion-764"><span class="linenos">764</span></a>
</span><span id="cascadeFeatureFusion-765"><a href="#cascadeFeatureFusion-765"><span class="linenos">765</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">low_dilated_conv_bn</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion-766"><a href="#cascadeFeatureFusion-766"><span class="linenos">766</span></a>            <span class="n">low_in_channels</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-767"><a href="#cascadeFeatureFusion-767"><span class="linenos">767</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-768"><a href="#cascadeFeatureFusion-768"><span class="linenos">768</span></a>            <span class="mi">3</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-769"><a href="#cascadeFeatureFusion-769"><span class="linenos">769</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-770"><a href="#cascadeFeatureFusion-770"><span class="linenos">770</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-771"><a href="#cascadeFeatureFusion-771"><span class="linenos">771</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-772"><a href="#cascadeFeatureFusion-772"><span class="linenos">772</span></a>            <span class="n">dilation</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-773"><a href="#cascadeFeatureFusion-773"><span class="linenos">773</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-774"><a href="#cascadeFeatureFusion-774"><span class="linenos">774</span></a>        <span class="p">)</span>
</span><span id="cascadeFeatureFusion-775"><a href="#cascadeFeatureFusion-775"><span class="linenos">775</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">low_classifier_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion-776"><a href="#cascadeFeatureFusion-776"><span class="linenos">776</span></a>            <span class="nb">int</span><span class="p">(</span><span class="n">low_in_channels</span><span class="p">),</span>
</span><span id="cascadeFeatureFusion-777"><a href="#cascadeFeatureFusion-777"><span class="linenos">777</span></a>            <span class="nb">int</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span>
</span><span id="cascadeFeatureFusion-778"><a href="#cascadeFeatureFusion-778"><span class="linenos">778</span></a>            <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-779"><a href="#cascadeFeatureFusion-779"><span class="linenos">779</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-780"><a href="#cascadeFeatureFusion-780"><span class="linenos">780</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-781"><a href="#cascadeFeatureFusion-781"><span class="linenos">781</span></a>            <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-782"><a href="#cascadeFeatureFusion-782"><span class="linenos">782</span></a>            <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-783"><a href="#cascadeFeatureFusion-783"><span class="linenos">783</span></a>        <span class="p">)</span>  <span class="c1"># Train only</span>
</span><span id="cascadeFeatureFusion-784"><a href="#cascadeFeatureFusion-784"><span class="linenos">784</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">high_proj_conv_bn</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion-785"><a href="#cascadeFeatureFusion-785"><span class="linenos">785</span></a>            <span class="n">high_in_channels</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-786"><a href="#cascadeFeatureFusion-786"><span class="linenos">786</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-787"><a href="#cascadeFeatureFusion-787"><span class="linenos">787</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-788"><a href="#cascadeFeatureFusion-788"><span class="linenos">788</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-789"><a href="#cascadeFeatureFusion-789"><span class="linenos">789</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-790"><a href="#cascadeFeatureFusion-790"><span class="linenos">790</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-791"><a href="#cascadeFeatureFusion-791"><span class="linenos">791</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion-792"><a href="#cascadeFeatureFusion-792"><span class="linenos">792</span></a>        <span class="p">)</span>
</span><span id="cascadeFeatureFusion-793"><a href="#cascadeFeatureFusion-793"><span class="linenos">793</span></a>
</span><span id="cascadeFeatureFusion-794"><a href="#cascadeFeatureFusion-794"><span class="linenos">794</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_low</span><span class="p">,</span> <span class="n">x_high</span><span class="p">):</span>
</span><span id="cascadeFeatureFusion-795"><a href="#cascadeFeatureFusion-795"><span class="linenos">795</span></a>        <span class="n">x_low_upsampled</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion-796"><a href="#cascadeFeatureFusion-796"><span class="linenos">796</span></a>            <span class="n">x_low</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">get_interp_size</span><span class="p">(</span><span class="n">x_low</span><span class="p">,</span> <span class="n">z_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span>
</span><span id="cascadeFeatureFusion-797"><a href="#cascadeFeatureFusion-797"><span class="linenos">797</span></a>        <span class="p">)</span>
</span><span id="cascadeFeatureFusion-798"><a href="#cascadeFeatureFusion-798"><span class="linenos">798</span></a>
</span><span id="cascadeFeatureFusion-799"><a href="#cascadeFeatureFusion-799"><span class="linenos">799</span></a>        <span class="n">low_cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_classifier_conv</span><span class="p">(</span><span class="n">x_low_upsampled</span><span class="p">)</span>
</span><span id="cascadeFeatureFusion-800"><a href="#cascadeFeatureFusion-800"><span class="linenos">800</span></a>
</span><span id="cascadeFeatureFusion-801"><a href="#cascadeFeatureFusion-801"><span class="linenos">801</span></a>        <span class="n">low_fm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_dilated_conv_bn</span><span class="p">(</span><span class="n">x_low_upsampled</span><span class="p">)</span>
</span><span id="cascadeFeatureFusion-802"><a href="#cascadeFeatureFusion-802"><span class="linenos">802</span></a>        <span class="n">high_fm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_proj_conv_bn</span><span class="p">(</span><span class="n">x_high</span><span class="p">)</span>
</span><span id="cascadeFeatureFusion-803"><a href="#cascadeFeatureFusion-803"><span class="linenos">803</span></a>        <span class="n">high_fused_fm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">low_fm</span> <span class="o">+</span> <span class="n">high_fm</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="cascadeFeatureFusion-804"><a href="#cascadeFeatureFusion-804"><span class="linenos">804</span></a>
</span><span id="cascadeFeatureFusion-805"><a href="#cascadeFeatureFusion-805"><span class="linenos">805</span></a>        <span class="k">return</span> <span class="n">high_fused_fm</span><span class="p">,</span> <span class="n">low_cls</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all neural network modules.</p>

<p>Your models should also subclass this class.</p>

<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>

<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <code><a href="#cascadeFeatureFusion.to">to</a></code>, etc.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>As per the example above, an <code><a href="#cascadeFeatureFusion.__init__">__init__()</a></code> call to the parent class
must be made before assignment on the child.</p>

</div>

<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>
</div>


                            <div id="cascadeFeatureFusion.__init__" class="classattr">
                                        <input id="cascadeFeatureFusion.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">cascadeFeatureFusion</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">n_classes</span>,</span><span class="param">	<span class="n">low_in_channels</span>,</span><span class="param">	<span class="n">high_in_channels</span>,</span><span class="param">	<span class="n">out_channels</span>,</span><span class="param">	<span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="cascadeFeatureFusion.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#cascadeFeatureFusion.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="cascadeFeatureFusion.__init__-758"><a href="#cascadeFeatureFusion.__init__-758"><span class="linenos">758</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion.__init__-759"><a href="#cascadeFeatureFusion.__init__-759"><span class="linenos">759</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">low_in_channels</span><span class="p">,</span> <span class="n">high_in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">is_batchnorm</span><span class="o">=</span><span class="kc">True</span>
</span><span id="cascadeFeatureFusion.__init__-760"><a href="#cascadeFeatureFusion.__init__-760"><span class="linenos">760</span></a>    <span class="p">):</span>
</span><span id="cascadeFeatureFusion.__init__-761"><a href="#cascadeFeatureFusion.__init__-761"><span class="linenos">761</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">cascadeFeatureFusion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="cascadeFeatureFusion.__init__-762"><a href="#cascadeFeatureFusion.__init__-762"><span class="linenos">762</span></a>
</span><span id="cascadeFeatureFusion.__init__-763"><a href="#cascadeFeatureFusion.__init__-763"><span class="linenos">763</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_batchnorm</span>
</span><span id="cascadeFeatureFusion.__init__-764"><a href="#cascadeFeatureFusion.__init__-764"><span class="linenos">764</span></a>
</span><span id="cascadeFeatureFusion.__init__-765"><a href="#cascadeFeatureFusion.__init__-765"><span class="linenos">765</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">low_dilated_conv_bn</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion.__init__-766"><a href="#cascadeFeatureFusion.__init__-766"><span class="linenos">766</span></a>            <span class="n">low_in_channels</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-767"><a href="#cascadeFeatureFusion.__init__-767"><span class="linenos">767</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-768"><a href="#cascadeFeatureFusion.__init__-768"><span class="linenos">768</span></a>            <span class="mi">3</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-769"><a href="#cascadeFeatureFusion.__init__-769"><span class="linenos">769</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-770"><a href="#cascadeFeatureFusion.__init__-770"><span class="linenos">770</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-771"><a href="#cascadeFeatureFusion.__init__-771"><span class="linenos">771</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-772"><a href="#cascadeFeatureFusion.__init__-772"><span class="linenos">772</span></a>            <span class="n">dilation</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-773"><a href="#cascadeFeatureFusion.__init__-773"><span class="linenos">773</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-774"><a href="#cascadeFeatureFusion.__init__-774"><span class="linenos">774</span></a>        <span class="p">)</span>
</span><span id="cascadeFeatureFusion.__init__-775"><a href="#cascadeFeatureFusion.__init__-775"><span class="linenos">775</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">low_classifier_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion.__init__-776"><a href="#cascadeFeatureFusion.__init__-776"><span class="linenos">776</span></a>            <span class="nb">int</span><span class="p">(</span><span class="n">low_in_channels</span><span class="p">),</span>
</span><span id="cascadeFeatureFusion.__init__-777"><a href="#cascadeFeatureFusion.__init__-777"><span class="linenos">777</span></a>            <span class="nb">int</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span>
</span><span id="cascadeFeatureFusion.__init__-778"><a href="#cascadeFeatureFusion.__init__-778"><span class="linenos">778</span></a>            <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-779"><a href="#cascadeFeatureFusion.__init__-779"><span class="linenos">779</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-780"><a href="#cascadeFeatureFusion.__init__-780"><span class="linenos">780</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-781"><a href="#cascadeFeatureFusion.__init__-781"><span class="linenos">781</span></a>            <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-782"><a href="#cascadeFeatureFusion.__init__-782"><span class="linenos">782</span></a>            <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-783"><a href="#cascadeFeatureFusion.__init__-783"><span class="linenos">783</span></a>        <span class="p">)</span>  <span class="c1"># Train only</span>
</span><span id="cascadeFeatureFusion.__init__-784"><a href="#cascadeFeatureFusion.__init__-784"><span class="linenos">784</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">high_proj_conv_bn</span> <span class="o">=</span> <span class="n">conv2DBatchNorm</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion.__init__-785"><a href="#cascadeFeatureFusion.__init__-785"><span class="linenos">785</span></a>            <span class="n">high_in_channels</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-786"><a href="#cascadeFeatureFusion.__init__-786"><span class="linenos">786</span></a>            <span class="n">out_channels</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-787"><a href="#cascadeFeatureFusion.__init__-787"><span class="linenos">787</span></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-788"><a href="#cascadeFeatureFusion.__init__-788"><span class="linenos">788</span></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-789"><a href="#cascadeFeatureFusion.__init__-789"><span class="linenos">789</span></a>            <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-790"><a href="#cascadeFeatureFusion.__init__-790"><span class="linenos">790</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-791"><a href="#cascadeFeatureFusion.__init__-791"><span class="linenos">791</span></a>            <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
</span><span id="cascadeFeatureFusion.__init__-792"><a href="#cascadeFeatureFusion.__init__-792"><span class="linenos">792</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="cascadeFeatureFusion.forward" class="classattr">
                                        <input id="cascadeFeatureFusion.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x_low</span>, </span><span class="param"><span class="n">x_high</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="cascadeFeatureFusion.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#cascadeFeatureFusion.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="cascadeFeatureFusion.forward-794"><a href="#cascadeFeatureFusion.forward-794"><span class="linenos">794</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_low</span><span class="p">,</span> <span class="n">x_high</span><span class="p">):</span>
</span><span id="cascadeFeatureFusion.forward-795"><a href="#cascadeFeatureFusion.forward-795"><span class="linenos">795</span></a>        <span class="n">x_low_upsampled</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span>
</span><span id="cascadeFeatureFusion.forward-796"><a href="#cascadeFeatureFusion.forward-796"><span class="linenos">796</span></a>            <span class="n">x_low</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">get_interp_size</span><span class="p">(</span><span class="n">x_low</span><span class="p">,</span> <span class="n">z_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span>
</span><span id="cascadeFeatureFusion.forward-797"><a href="#cascadeFeatureFusion.forward-797"><span class="linenos">797</span></a>        <span class="p">)</span>
</span><span id="cascadeFeatureFusion.forward-798"><a href="#cascadeFeatureFusion.forward-798"><span class="linenos">798</span></a>
</span><span id="cascadeFeatureFusion.forward-799"><a href="#cascadeFeatureFusion.forward-799"><span class="linenos">799</span></a>        <span class="n">low_cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_classifier_conv</span><span class="p">(</span><span class="n">x_low_upsampled</span><span class="p">)</span>
</span><span id="cascadeFeatureFusion.forward-800"><a href="#cascadeFeatureFusion.forward-800"><span class="linenos">800</span></a>
</span><span id="cascadeFeatureFusion.forward-801"><a href="#cascadeFeatureFusion.forward-801"><span class="linenos">801</span></a>        <span class="n">low_fm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_dilated_conv_bn</span><span class="p">(</span><span class="n">x_low_upsampled</span><span class="p">)</span>
</span><span id="cascadeFeatureFusion.forward-802"><a href="#cascadeFeatureFusion.forward-802"><span class="linenos">802</span></a>        <span class="n">high_fm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_proj_conv_bn</span><span class="p">(</span><span class="n">x_high</span><span class="p">)</span>
</span><span id="cascadeFeatureFusion.forward-803"><a href="#cascadeFeatureFusion.forward-803"><span class="linenos">803</span></a>        <span class="n">high_fused_fm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">low_fm</span> <span class="o">+</span> <span class="n">high_fm</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="cascadeFeatureFusion.forward-804"><a href="#cascadeFeatureFusion.forward-804"><span class="linenos">804</span></a>
</span><span id="cascadeFeatureFusion.forward-805"><a href="#cascadeFeatureFusion.forward-805"><span class="linenos">805</span></a>        <span class="k">return</span> <span class="n">high_fused_fm</span><span class="p">,</span> <span class="n">low_cls</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="cascadeFeatureFusion.dump_patches" class="variable">dump_patches</dd>
                <dd id="cascadeFeatureFusion.register_buffer" class="function">register_buffer</dd>
                <dd id="cascadeFeatureFusion.register_parameter" class="function">register_parameter</dd>
                <dd id="cascadeFeatureFusion.add_module" class="function">add_module</dd>
                <dd id="cascadeFeatureFusion.register_module" class="function">register_module</dd>
                <dd id="cascadeFeatureFusion.get_submodule" class="function">get_submodule</dd>
                <dd id="cascadeFeatureFusion.get_parameter" class="function">get_parameter</dd>
                <dd id="cascadeFeatureFusion.get_buffer" class="function">get_buffer</dd>
                <dd id="cascadeFeatureFusion.get_extra_state" class="function">get_extra_state</dd>
                <dd id="cascadeFeatureFusion.set_extra_state" class="function">set_extra_state</dd>
                <dd id="cascadeFeatureFusion.apply" class="function">apply</dd>
                <dd id="cascadeFeatureFusion.cuda" class="function">cuda</dd>
                <dd id="cascadeFeatureFusion.ipu" class="function">ipu</dd>
                <dd id="cascadeFeatureFusion.xpu" class="function">xpu</dd>
                <dd id="cascadeFeatureFusion.cpu" class="function">cpu</dd>
                <dd id="cascadeFeatureFusion.type" class="function">type</dd>
                <dd id="cascadeFeatureFusion.float" class="function">float</dd>
                <dd id="cascadeFeatureFusion.double" class="function">double</dd>
                <dd id="cascadeFeatureFusion.half" class="function">half</dd>
                <dd id="cascadeFeatureFusion.bfloat16" class="function">bfloat16</dd>
                <dd id="cascadeFeatureFusion.to_empty" class="function">to_empty</dd>
                <dd id="cascadeFeatureFusion.to" class="function">to</dd>
                <dd id="cascadeFeatureFusion.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="cascadeFeatureFusion.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="cascadeFeatureFusion.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="cascadeFeatureFusion.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="cascadeFeatureFusion.T_destination" class="variable">T_destination</dd>
                <dd id="cascadeFeatureFusion.state_dict" class="function">state_dict</dd>
                <dd id="cascadeFeatureFusion.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="cascadeFeatureFusion.load_state_dict" class="function">load_state_dict</dd>
                <dd id="cascadeFeatureFusion.parameters" class="function">parameters</dd>
                <dd id="cascadeFeatureFusion.named_parameters" class="function">named_parameters</dd>
                <dd id="cascadeFeatureFusion.buffers" class="function">buffers</dd>
                <dd id="cascadeFeatureFusion.named_buffers" class="function">named_buffers</dd>
                <dd id="cascadeFeatureFusion.children" class="function">children</dd>
                <dd id="cascadeFeatureFusion.named_children" class="function">named_children</dd>
                <dd id="cascadeFeatureFusion.modules" class="function">modules</dd>
                <dd id="cascadeFeatureFusion.named_modules" class="function">named_modules</dd>
                <dd id="cascadeFeatureFusion.train" class="function">train</dd>
                <dd id="cascadeFeatureFusion.eval" class="function">eval</dd>
                <dd id="cascadeFeatureFusion.requires_grad_" class="function">requires_grad_</dd>
                <dd id="cascadeFeatureFusion.zero_grad" class="function">zero_grad</dd>
                <dd id="cascadeFeatureFusion.share_memory" class="function">share_memory</dd>
                <dd id="cascadeFeatureFusion.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="get_interp_size">
                            <input id="get_interp_size-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_interp_size</span><span class="signature pdoc-code condensed">(<span class="param"><span class="nb">input</span>, </span><span class="param"><span class="n">s_factor</span><span class="o">=</span><span class="mi">1</span>, </span><span class="param"><span class="n">z_factor</span><span class="o">=</span><span class="mi">1</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="get_interp_size-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_interp_size"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_interp_size-808"><a href="#get_interp_size-808"><span class="linenos">808</span></a><span class="k">def</span> <span class="nf">get_interp_size</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">s_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">z_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># for caffe</span>
</span><span id="get_interp_size-809"><a href="#get_interp_size-809"><span class="linenos">809</span></a>    <span class="n">ori_h</span><span class="p">,</span> <span class="n">ori_w</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
</span><span id="get_interp_size-810"><a href="#get_interp_size-810"><span class="linenos">810</span></a>
</span><span id="get_interp_size-811"><a href="#get_interp_size-811"><span class="linenos">811</span></a>    <span class="c1"># shrink (s_factor &gt;= 1)</span>
</span><span id="get_interp_size-812"><a href="#get_interp_size-812"><span class="linenos">812</span></a>    <span class="n">ori_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">ori_h</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">s_factor</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="get_interp_size-813"><a href="#get_interp_size-813"><span class="linenos">813</span></a>    <span class="n">ori_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">ori_w</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">s_factor</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="get_interp_size-814"><a href="#get_interp_size-814"><span class="linenos">814</span></a>
</span><span id="get_interp_size-815"><a href="#get_interp_size-815"><span class="linenos">815</span></a>    <span class="c1"># zoom (z_factor &gt;= 1)</span>
</span><span id="get_interp_size-816"><a href="#get_interp_size-816"><span class="linenos">816</span></a>    <span class="n">ori_h</span> <span class="o">=</span> <span class="n">ori_h</span> <span class="o">+</span> <span class="p">(</span><span class="n">ori_h</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">z_factor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="get_interp_size-817"><a href="#get_interp_size-817"><span class="linenos">817</span></a>    <span class="n">ori_w</span> <span class="o">=</span> <span class="n">ori_w</span> <span class="o">+</span> <span class="p">(</span><span class="n">ori_w</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">z_factor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="get_interp_size-818"><a href="#get_interp_size-818"><span class="linenos">818</span></a>
</span><span id="get_interp_size-819"><a href="#get_interp_size-819"><span class="linenos">819</span></a>    <span class="n">resize_shape</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ori_h</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">ori_w</span><span class="p">))</span>
</span><span id="get_interp_size-820"><a href="#get_interp_size-820"><span class="linenos">820</span></a>    <span class="k">return</span> <span class="n">resize_shape</span>
</span></pre></div>


    

                </section>
                <section id="interp">
                            <input id="interp-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">interp</span><span class="signature pdoc-code condensed">(<span class="param"><span class="nb">input</span>, </span><span class="param"><span class="n">output_size</span>, </span><span class="param"><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="interp-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#interp"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="interp-823"><a href="#interp-823"><span class="linenos">823</span></a><span class="k">def</span> <span class="nf">interp</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">):</span>
</span><span id="interp-824"><a href="#interp-824"><span class="linenos">824</span></a>    <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">ih</span><span class="p">,</span> <span class="n">iw</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
</span><span id="interp-825"><a href="#interp-825"><span class="linenos">825</span></a>    <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span> <span class="o">=</span> <span class="n">output_size</span>
</span><span id="interp-826"><a href="#interp-826"><span class="linenos">826</span></a>
</span><span id="interp-827"><a href="#interp-827"><span class="linenos">827</span></a>    <span class="c1"># normalize to [-1, 1]</span>
</span><span id="interp-828"><a href="#interp-828"><span class="linenos">828</span></a>    <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="nb">input</span><span class="o">.</span><span class="n">is_cuda</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">oh</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="interp-829"><a href="#interp-829"><span class="linenos">829</span></a>    <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ow</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="nb">input</span><span class="o">.</span><span class="n">is_cuda</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">ow</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="interp-830"><a href="#interp-830"><span class="linenos">830</span></a>
</span><span id="interp-831"><a href="#interp-831"><span class="linenos">831</span></a>    <span class="n">grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="nb">input</span><span class="o">.</span><span class="n">is_cuda</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</span><span id="interp-832"><a href="#interp-832"><span class="linenos">832</span></a>    <span class="n">grid</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">oh</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="interp-833"><a href="#interp-833"><span class="linenos">833</span></a>    <span class="n">grid</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">ow</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="interp-834"><a href="#interp-834"><span class="linenos">834</span></a>    <span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># grid.shape: [n, oh, ow, 2]</span>
</span><span id="interp-835"><a href="#interp-835"><span class="linenos">835</span></a>
</span><span id="interp-836"><a href="#interp-836"><span class="linenos">836</span></a>    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">grid_sample</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
</span></pre></div>


    

                </section>
                <section id="get_upsampling_weight">
                            <input id="get_upsampling_weight-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_upsampling_weight</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">in_channels</span>, </span><span class="param"><span class="n">out_channels</span>, </span><span class="param"><span class="n">kernel_size</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="get_upsampling_weight-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_upsampling_weight"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_upsampling_weight-839"><a href="#get_upsampling_weight-839"><span class="linenos">839</span></a><span class="k">def</span> <span class="nf">get_upsampling_weight</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">):</span>
</span><span id="get_upsampling_weight-840"><a href="#get_upsampling_weight-840"><span class="linenos">840</span></a>    <span class="sd">&quot;&quot;&quot;Make a 2D bilinear kernel suitable for upsampling&quot;&quot;&quot;</span>
</span><span id="get_upsampling_weight-841"><a href="#get_upsampling_weight-841"><span class="linenos">841</span></a>    <span class="n">factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
</span><span id="get_upsampling_weight-842"><a href="#get_upsampling_weight-842"><span class="linenos">842</span></a>    <span class="k">if</span> <span class="n">kernel_size</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="get_upsampling_weight-843"><a href="#get_upsampling_weight-843"><span class="linenos">843</span></a>        <span class="n">center</span> <span class="o">=</span> <span class="n">factor</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="get_upsampling_weight-844"><a href="#get_upsampling_weight-844"><span class="linenos">844</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="get_upsampling_weight-845"><a href="#get_upsampling_weight-845"><span class="linenos">845</span></a>        <span class="n">center</span> <span class="o">=</span> <span class="n">factor</span> <span class="o">-</span> <span class="mf">0.5</span>
</span><span id="get_upsampling_weight-846"><a href="#get_upsampling_weight-846"><span class="linenos">846</span></a>    <span class="n">og</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ogrid</span><span class="p">[:</span><span class="n">kernel_size</span><span class="p">,</span> <span class="p">:</span><span class="n">kernel_size</span><span class="p">]</span>
</span><span id="get_upsampling_weight-847"><a href="#get_upsampling_weight-847"><span class="linenos">847</span></a>    <span class="n">filt</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="nb">abs</span><span class="p">(</span><span class="n">og</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span> <span class="o">/</span> <span class="n">factor</span><span class="p">)</span> <span class="o">*</span> \
</span><span id="get_upsampling_weight-848"><a href="#get_upsampling_weight-848"><span class="linenos">848</span></a>           <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="nb">abs</span><span class="p">(</span><span class="n">og</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span> <span class="o">/</span> <span class="n">factor</span><span class="p">)</span>
</span><span id="get_upsampling_weight-849"><a href="#get_upsampling_weight-849"><span class="linenos">849</span></a>    <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">),</span>
</span><span id="get_upsampling_weight-850"><a href="#get_upsampling_weight-850"><span class="linenos">850</span></a>                      <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="get_upsampling_weight-851"><a href="#get_upsampling_weight-851"><span class="linenos">851</span></a>    <span class="n">weight</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">in_channels</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_channels</span><span class="p">),</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">filt</span>
</span><span id="get_upsampling_weight-852"><a href="#get_upsampling_weight-852"><span class="linenos">852</span></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Make a 2D bilinear kernel suitable for upsampling</p>
</div>


                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.type) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value">${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.type}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>