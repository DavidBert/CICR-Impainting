window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "impaintingLib", "modulename": "impaintingLib", "type": "module", "doc": "<h1 id=\"cicr-impainting\">CICR-Impainting</h1>\n\n<h2 id=\"presentation\">Pr\u00e9sentation</h2>\n\n<p>Ce repo \u00e0 \u00e9t\u00e9 cr\u00e9e en juin 2022 \u00e0 l'occasion d'un stage en partenariat entre l'INSA et le CICR. L'objectif \u00e9tait de produire un mod\u00e8le capable de reconstruire un visage abim\u00e9. </p>\n\n<p><img src=\"./examples.png\" alt=\"examples\" /> </br></p>\n\n<h2 id=\"installation\">Installation</h2>\n\n<h3 id=\"installation-des-libraries\">Installation des libraries</h3>\n\n<p>Utiliser la commande <strong>pip install -r ./requirements.txt</strong> </p>\n\n<h3 id=\"telechargement-des-datasets\">T\u00e9l\u00e9chargement des datasets</h3>\n\n<ul>\n<li>Lancer un inviter de commande et \u00e9xecuter <a href=\"dataset.sh\">./dataset.sh</a> t\u00e9l\u00e9chargera tous les datasets que nous avons utilis\u00e9s</li>\n<li>Attention \u00e0 avoir assez de place sur la machine</li>\n<li>Si tous ces dossiers ne sont pas dans data alors leur .zip doit se trouver dans le repertoire racine et peuvent \u00eatre extrait manuellement</li>\n<li>Attention \u00e0 donner le m\u00eame nom que ceux suivants pour que la librairie les retrouve bien : </br>\n<strong>data/ </br>\n\u251c\u2500 utk/</br>\n\u251c\u2500 test/</br>\n\u251c\u2500 masks/</br>\n\u251c\u2500 flickr/</br>\n\u251c\u2500 lfw/</br>\n\u251c\u2500 celeba/</strong></li>\n</ul>\n\n<p>En cas d'erreur liens de t\u00e9l\u00e9chargement : </p>\n\n<ul>\n<li><a href=\"https://drive.google.com/file/d/0B7EVK8r0v71pZjFTYXZWM3FlRnM/view?usp=sharing&amp;resourcekey=0-dYn9z10tMJOBAkviAcfdyQ\">Celeba</a></li>\n<li><a href=\"https://drive.google.com/drive/folders/1tg-Ur7d4vk1T8Bn0pPpUSQPxlPGBlGfv\">Flickr</a> </li>\n<li><a href=\"http://vis-www.cs.umass.edu/lfw/lfw.tgz\">Lfw</a> </li>\n<li><a href=\"https://drive.google.com/drive/folders/0BxYys69jI14kU0I1YUQyY1ZDRUE?resourcekey=0-01Pth1hq20K4kuGVkp3oBw\">Utk</a> </li>\n<li><a href=\"https://www.dropbox.com/s/01dfayns9s0kevy/test_mask.zip\">Nvidia mask test</a> </li>\n<li><a href=\"https://www.dropbox.com/s/qp8cxqttta4zi70/irregular_mask.zip\">Nvidia mask training</a> (non utilis\u00e9) </li>\n</ul>\n\n<h2 id=\"application\">Application</h2>\n\n<h3 id=\"lancement\">Lancement</h3>\n\n<p>...........</p>\n\n<h3 id=\"utilisation\">Utilisation</h3>\n\n<p><img src=\"./guide.gif\" alt=\"Gif d'utilisation de l'application\" /> </br></p>\n\n<p>Plusieurs options ne sont pas pr\u00e9sent\u00e9 dans le gif ci-dessus: </p>\n\n<ul>\n<li><strong>Image's resizing</strong> : Faire glisser le curseur vers la gauche fera \"d\u00e9zoomer\" et inversement en allant \u00e0 droite.  Il faudra appuyer sur le bouton \u00e0 c\u00f4t\u00e9 apr\u00e8s modification du curseur. Un resizing entraine la perte de la segmentation et des keypoints courants.</li>\n<li><strong>Autres curseurs</strong> : Ils servent \u00e0 modifier la taille de la brosse lors du dessin.</li>\n<li><strong>Boutons gris dans l'onglet segmentation</strong> : Ils permettent de changer le type de brosse en fonction d'un type de zone du visage.</li>\n<li><strong>Enhance</strong> : Utilisera un mod\u00e8le ESRGAN sur le r\u00e9sultat pour am\u00e9liorer la r\u00e9solution (ne marche pas tr\u00e8s bien sur les zones reconstruites.</li>\n</ul>\n\n<p>Une version de test est disponible \u00e0 l'adresse : <a href=\"https://heinekayn.me\">https://heinekayn.me</a></br>\nMises en garde quant \u00e0 l'application web : </p>\n\n<ul>\n<li>Il peut y avoir quelques bugs (il faut parfois refresh la page ou rappuyer une autre fois sur un bouton)  </li>\n<li>Le serveur peut \u00eatre arr\u00eat\u00e9 de temps en temps pour des updates ou \u00e0 cause d'un bug (il y'aura alors une erreur 502 bad gateway)  </li>\n<li>Si plusieurs personnes utilisent le site en m\u00eame temps il peut y avoir des conflicts</li>\n<li>Le serveur stock la derni\u00e8re image impaint\u00e9 (et seulement elle). En modifier une suivante \u00e9crasera celle pr\u00e9cedemment stock\u00e9.</li>\n</ul>\n\n<h2 id=\"presentation-de-la-librairie\">Pr\u00e9sentation de la librairie</h2>\n\n<ul>\n<li>Un tutoriel est disponible dans le notebook <a href=\"tutorial.ipynb\">tutorial.ipynb</a></li>\n<li>La documentation est disponible <a href=\"documentation/\">ici</a> ou en utilisant <strong>pdoc .\\impaintingLib</strong> apr\u00e8s avoir <strong>pip install pdoc</strong></li>\n</ul>\n\n<h3 id=\"historique-des-pistes-envisages\">Historique des pistes envisag\u00e9s</h3>\n\n<p>Disponible <a href=\"historique.md\">ici</a></p>\n\n<h3 id=\"references\">R\u00e9f\u00e9rences</h3>\n\n<pre><code>ESRGAN : \n@InProceedings{wang2018esrgan,\n    author = {Wang, Xintao and Yu, Ke and Wu, Shixiang and Gu, Jinjin and Liu, Yihao and Dong, Chao and Qiao, Yu and Loy, Chen Change},\n    title = {ESRGAN: Enhanced super-resolution generative adversarial networks},\n    booktitle = {The European Conference on Computer Vision Workshops (ECCVW)},\n    month = {September},\n    year = {2018}\n}\n\nSegmentation\n@inproceedings{CelebAMask-HQ,\n  title={MaskGAN: Towards Diverse and Interactive Facial Image Manipulation},\n  author={Lee, Cheng-Han and Liu, Ziwei and Wu, Lingyun and Luo, Ping},\n  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n  year={2020}\n}\n</code></pre>\n"}, {"fullname": "impaintingLib.components", "modulename": "impaintingLib.components", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.components.get_segmentation", "modulename": "impaintingLib.components", "qualname": "get_segmentation", "type": "function", "doc": "<p>Converti des images RGB en images \u00e0 1 couche contenant des informations sur les zones du visage (yeux, nez, bouche...)</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n<li><strong>scale_factor</strong> : En fonction du factorResize. Le but est de re-multiplier encore la taille de l'image par scale_factor pour l'amener \u00e0 256x256 et avoir une meilleure segmentation. Pour un factorResize=1 il faudra un scale_factor de 4 (64x64) x 1 x 4 = 256 et pour factorResize=2 il faudra un scale_factor de 2</li>\n<li><strong>simplify</strong> Fait appel \u00e0 <code>simplifyChannels</code> si <code>True</code></li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>1</strong>, w, h])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span>, </span><span class=\"param\"><span class=\"n\">scale_factor</span><span class=\"o\">=</span><span class=\"mi\">4</span>, </span><span class=\"param\"><span class=\"n\">simplify</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.components.getKeypoints", "modulename": "impaintingLib.components", "qualname": "getKeypoints", "type": "function", "doc": "<p>Converti des images RGB en images \u00e0 1 couche contenant les points cl\u00e9s du visage</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, <strong>3</strong>, w, h]) </li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>1</strong>, w, h])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.components.superRes", "modulename": "impaintingLib.components", "qualname": "superRes", "type": "function", "doc": "<p>Am\u00e9liore la r\u00e9solution des images RGB fournies</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, <strong>3</strong>, w, h]) </li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.components.simplifyChannels", "modulename": "impaintingLib.components", "qualname": "simplifyChannels", "type": "function", "doc": "<p>Enl\u00e8ve les zones qu'on a jug\u00e9 inutiles (cheveux, lunettes, habits...) et fusionne les doublons (oeil gauche / oeil droit)</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, <strong>1</strong>, w, h])</li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>1</strong>, w, h])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.data", "modulename": "impaintingLib.data", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.data.getDataset", "modulename": "impaintingLib.data", "qualname": "getDataset", "type": "function", "doc": "<p>Cr\u00e9e un objet <code>ImageFolder</code> que l'on transforme ensuite en dataloader</p>\n\n<ul>\n<li><strong>file</strong> : Chemin vers un dossier de data </li>\n<li><strong>factorResize</strong> : Les images de ce dataset auront une taille de 64*factorResize</li>\n<li><strong>doCrop</strong> : Si <code>True</code> effectue un zoom sur le centre de l'image</li>\n<li><strong>return</strong> : ImageFolder</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">file</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">factorResize</span><span class=\"o\">=</span><span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">doCrop</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.data.getTestImages", "modulename": "impaintingLib.data", "qualname": "getTestImages", "type": "function", "doc": "<p>Renvoie un unique batch de taille 16 utile pour tester un mod\u00e8le</p>\n\n<ul>\n<li><strong>file</strong> : Chemin vers un dossier de data </li>\n<li><strong>factorResize</strong> : Les images de ce dataset auront une taille de 64*factorResize</li>\n<li><strong>doCrop</strong> : Si <code>True</code> effectue un zoom sur le centre de l'image</li>\n<li><strong>doShuffle</strong> Si <code>True</code> m\u00e9lange al\u00e9atoirement le dataset, sinon renvoie toujours les premieres images du dossier</li>\n<li><strong>return</strong> : torch.Size([16, 3, 64*factorResize, 64*factorResize])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">file</span>, </span><span class=\"param\"><span class=\"n\">factorResize</span><span class=\"o\">=</span><span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">doCrop</span><span class=\"o\">=</span><span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">doShuffle</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.data.testReal", "modulename": "impaintingLib.data", "qualname": "testReal", "type": "function", "doc": "<p>Va chercher les images, masques et segmentations usuelles pr\u00e9sentes dans le dossier <strong>/data/test</strong> pour tester directement un mod\u00e8le donn\u00e9 dessus</p>\n\n<ul>\n<li><strong>impainter</strong> : Mod\u00e8le \u00e0 tester</li>\n<li><strong>base</strong> : Si <code>True</code> affiche l'image originale</li>\n<li><strong>altered</strong> : Si <code>True</code> affiche l'image masqu\u00e9e</li>\n<li><strong>segmented</strong> : Si <code>True</code> affiche l'image segment\u00e9</li>\n<li><strong>keypoints</strong> : Si <code>True</code> affiche les keypoints</li>\n<li><strong>predicted</strong> : Si <code>True</code> affiche l'image reconstruite</li>\n<li><strong>return</strong> : <code>None</code></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">impainter</span>,</span><span class=\"param\">\t<span class=\"n\">base</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">altered</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">segmented</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">keypoints</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">predicted</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.data.randomTransfo", "modulename": "impaintingLib.data", "qualname": "randomTransfo", "type": "function", "doc": "<p>Fais de la data augmentation (avec une certaine probabilit\u00e9) sur les imgs donn\u00e9es en entr\u00e9e </p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, <strong>3</strong>, w, h]) </li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n</ul>\n\n<p>Augmentations impl\u00e9ment\u00e9s : </p>\n\n<ul>\n<li>crop </li>\n<li>rotation</li>\n<li>mirroir</li>\n<li>luminosit\u00e9 - <em>(d\u00e9sactiv\u00e9)</em></li>\n<li>contraste - <em>(d\u00e9sactiv\u00e9)</em></li>\n<li>couleurs - <em>(d\u00e9sactiv\u00e9)</em></li>\n<li>sharpness - <em>(d\u00e9sactiv\u00e9)</em></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">imgs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.loss", "modulename": "impaintingLib.loss", "type": "module", "doc": "<p>Plusieurs loss sont impl\u00e9ment\u00e9s dans la librairie :</p>\n\n<ul>\n<li>keypointLoss</li>\n<li>totalVariation</li>\n<li>perceptualVGG</li>\n<li>perceptualClassifier</li>\n</ul>\n"}, {"fullname": "impaintingLib.loss.classifierUtils", "modulename": "impaintingLib.loss.classifierUtils", "type": "module", "doc": "<p>Utilis\u00e9 par le classifier, il n'y a rien \u00e0 prendre ici</p>\n"}, {"fullname": "impaintingLib.loss.common", "modulename": "impaintingLib.loss.common", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.loss.common.totalVariation", "modulename": "impaintingLib.loss.common", "qualname": "totalVariation", "type": "function", "doc": "<p>La Total variation est la mesure de complexit\u00e9 d'une image, elle est utile en combinaison avec une loss perceptuel</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, c, w, h])</li>\n<li><strong>return</strong> : int</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.loss.common.keypointLoss", "modulename": "impaintingLib.loss.common", "qualname": "keypointLoss", "type": "function", "doc": "<p>Compare les keypoints de l'image originale avec ceux de l'image reconstruite (marche pas tr\u00e8s bien)</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, c, w, h])</li>\n<li><strong>x_hat</strong> : torch.Size([batch_size, c, w, h])</li>\n<li><strong>return</strong> : int</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span>, </span><span class=\"param\"><span class=\"n\">x_hat</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.loss.gan", "modulename": "impaintingLib.loss.gan", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.loss.gan.ganLoss", "modulename": "impaintingLib.loss.gan", "qualname": "ganLoss", "type": "function", "doc": "<p>Loss utilis\u00e9 par le GAN simpliste que nous avons impl\u00e9ment\u00e9</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, c, w, h])</li>\n<li><strong>x_hat</strong> : torch.Size([batch_size, c, w, h])</li>\n<li><strong>discriminator</strong> : un discriminateur</li>\n<li><strong>return</strong> : int</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span>, </span><span class=\"param\"><span class=\"n\">x_hat</span>, </span><span class=\"param\"><span class=\"n\">discriminator</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.loss.perceptualClassifier", "modulename": "impaintingLib.loss.perceptualClassifier", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.loss.perceptualClassifier.perceptualClassifier", "modulename": "impaintingLib.loss.perceptualClassifier", "qualname": "perceptualClassifier", "type": "function", "doc": "<p>Compare les segmentations de l'originale et de la reconstruction pour les faire correspondre (marche pas tr\u00e8s bien)</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, c, w, h])</li>\n<li><strong>x_hat</strong> : torch.Size([batch_size, c, w, h])</li>\n<li><strong>return</strong> : int</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span>, </span><span class=\"param\"><span class=\"n\">x_hat</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.loss.perceptualVGG", "modulename": "impaintingLib.loss.perceptualVGG", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.loss.perceptualVGG.perceptualVGG", "modulename": "impaintingLib.loss.perceptualVGG", "qualname": "perceptualVGG", "type": "function", "doc": "<p>Compare l'image originale et la reconstruite et essaie de les faire tendre vers un visage normale</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, c, w, h])</li>\n<li><strong>x_hat</strong> : torch.Size([batch_size, c, w, h])</li>\n<li><strong>return</strong> : int</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span>, </span><span class=\"param\"><span class=\"n\">x_hat</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.mask", "modulename": "impaintingLib.mask", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.mask.propagate", "modulename": "impaintingLib.mask", "qualname": "propagate", "type": "function", "doc": "<p>Propage un masque g\u00e9n\u00e9r\u00e9 sur toutes les couche d'une image RGB</p>\n\n<ul>\n<li><strong>imgs</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n<li><strong>masks</strong> : torch.Size([batch_size, <strong>1</strong>, w, h])</li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">imgs</span>, </span><span class=\"param\"><span class=\"n\">masks</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.mask.Alter", "modulename": "impaintingLib.mask", "qualname": "Alter", "type": "class", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.mask.Alter.__init__", "modulename": "impaintingLib.mask", "qualname": "Alter.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">min_cut</span><span class=\"o\">=</span><span class=\"mi\">15</span>, </span><span class=\"param\"><span class=\"n\">max_cut</span><span class=\"o\">=</span><span class=\"mi\">45</span>, </span><span class=\"param\"><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">0</span>, </span><span class=\"param\"><span class=\"n\">resize</span><span class=\"o\">=</span><span class=\"mi\">1</span></span>)</span>"}, {"fullname": "impaintingLib.mask.Alter.max_cut", "modulename": "impaintingLib.mask", "qualname": "Alter.max_cut", "type": "variable", "doc": "<p>Mincut et Maxcut conditionnent la position des masques carr\u00e9s. Si les deux sont \u00e0 0 il peut y'avoir un carr\u00e9 noir partout sur l'image mais si les deux sont \u00e0 50 il ne pourra pas y avoir de carr\u00e9 sur les bords par exemple</p>\n"}, {"fullname": "impaintingLib.mask.Alter.seed", "modulename": "impaintingLib.mask", "qualname": "Alter.seed", "type": "variable", "doc": "<p>Si la seed est \u00e0 0 alors le masque sera al\u00e9atoire. Si elle est diff\u00e9rente de 0 alors une m\u00eame seed donnera toujours le m\u00eame r\u00e9sultat</p>\n"}, {"fullname": "impaintingLib.mask.Alter.resize", "modulename": "impaintingLib.mask", "qualname": "Alter.resize", "type": "variable", "doc": "<p>Coefficient de taille de l'image. La taille des masques sera toujours resize*64</p>\n"}, {"fullname": "impaintingLib.mask.Alter.squareMask", "modulename": "impaintingLib.mask", "qualname": "Alter.squareMask", "type": "function", "doc": "<p>Cr\u00e9e un masque carr\u00e9 al\u00e9atoire et le propage sur l'image</p>\n\n<ul>\n<li><strong>imgs</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n<li><strong>masks</strong> : torch.Size([batch_size, <strong>1</strong>, w, h])</li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">imgs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.mask.Alter.fullMask", "modulename": "impaintingLib.mask", "qualname": "Alter.fullMask", "type": "function", "doc": "<p>Remplace chaque pixel de l'image par du noire</p>\n\n<ul>\n<li><strong>imgs</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">imgs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.mask.Alter.downScale", "modulename": "impaintingLib.mask", "qualname": "Alter.downScale", "type": "function", "doc": "<p>Baisse la r\u00e9solution de l'image</p>\n\n<ul>\n<li><strong>imgs</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n<li><strong>scale_factor</strong> : En fonction de la taille de l'image</li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">imgs</span>, </span><span class=\"param\"><span class=\"n\">scale_factor</span><span class=\"o\">=</span><span class=\"mi\">2</span>, </span><span class=\"param\"><span class=\"n\">upscale</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.mask.Alter.irregularMask", "modulename": "impaintingLib.mask", "qualname": "Alter.irregularMask", "type": "function", "doc": "<p>R\u00e9cup\u00e8re des masques irr\u00e9guliers dans le dossier /data/masks et les applique sur les images</p>\n\n<ul>\n<li><strong>imgs</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n<li><strong>return</strong> : torch.Size([batch_size, <strong>3</strong>, w, h])</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">imgs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model", "modulename": "impaintingLib.model", "type": "module", "doc": "<p>Diff\u00e9rents mod\u00e8les sont d\u00e9j\u00e0 disponibles dans la librairie mais il est toujours possible d'en ajouter de nouveaux\nActuellement impl\u00e9ment\u00e9s : </p>\n\n<ul>\n<li>UNet (avec diff\u00e9rentes convolutions)</li>\n<li>AutoEncoder (un Unet en moins pouss\u00e9)</li>\n<li>SubpixelNetwork (= pixelShuffle)</li>\n<li>ClassifierUNet (pour la segmentation)</li>\n<li>XceptionNet (pour les keypoints)</li>\n<li>RRDBNet (pour la super r\u00e9solution)</li>\n</ul>\n"}, {"fullname": "impaintingLib.model.GAN", "modulename": "impaintingLib.model.GAN", "type": "module", "doc": "<p>Utilisation : </p>\n\n<pre><code>discriminator = imp.model.Discriminator(cnum_in=5, cnum=64)\n</code></pre>\n\n<ul>\n<li><strong>cnum_in</strong> : Nombre de channel en entr\u00e9e</li>\n<li><strong>cnum</strong> : Taille de l'image</li>\n</ul>\n\n<hr />\n"}, {"fullname": "impaintingLib.model.RRDBNet_arch", "modulename": "impaintingLib.model.RRDBNet_arch", "type": "module", "doc": "<p>Utilis\u00e9 par le module components</p>\n"}, {"fullname": "impaintingLib.model.autoEncoder", "modulename": "impaintingLib.model.autoEncoder", "type": "module", "doc": "<p>Utilisation : </p>\n\n<pre><code>model = AutoEncoder(in_channels)\n</code></pre>\n\n<hr />\n"}, {"fullname": "impaintingLib.model.classifierUNet", "modulename": "impaintingLib.model.classifierUNet", "type": "module", "doc": "<p>Utilis\u00e9 par le module components, un peu technique ne pas trop fouiller</p>\n"}, {"fullname": "impaintingLib.model.keypoint", "modulename": "impaintingLib.model.keypoint", "type": "module", "doc": "<p>Utilis\u00e9 par le module components</p>\n"}, {"fullname": "impaintingLib.model.layer", "modulename": "impaintingLib.model.layer", "type": "module", "doc": "<p>Emplacement des diff\u00e9rentes convolutions trouv\u00e9es sur internet</p>\n"}, {"fullname": "impaintingLib.model.layer.gatedConvo", "modulename": "impaintingLib.model.layer.gatedConvo", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.model.layer.gatedConvo.GatedConv2dWithActivation", "modulename": "impaintingLib.model.layer.gatedConvo", "qualname": "GatedConv2dWithActivation", "type": "class", "doc": "<p>Gated Convlution layer with activation (default activation:LeakyReLU)\nParams: same as conv2d\nInput: The feature from last layer \"I\"\nOutput:\\phi(f(I))*\\sigmoid(g(I))</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.gatedConvo.GatedConv2dWithActivation.__init__", "modulename": "impaintingLib.model.layer.gatedConvo", "qualname": "GatedConv2dWithActivation.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">out_channels</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_size</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">groups</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">batch_norm</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">LeakyReLU</span><span class=\"p\">(</span><span class=\"n\">negative_slope</span><span class=\"o\">=</span><span class=\"mf\">0.2</span><span class=\"p\">,</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.gatedConvo.GatedConv2dWithActivation.gated", "modulename": "impaintingLib.model.layer.gatedConvo", "qualname": "GatedConv2dWithActivation.gated", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">mask</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.gatedConvo.GatedConv2dWithActivation.forward", "modulename": "impaintingLib.model.layer.gatedConvo", "qualname": "GatedConv2dWithActivation.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"nb\">input</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils", "modulename": "impaintingLib.model.layer.model_utils", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DBatchNorm", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DBatchNorm", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DBatchNorm.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DBatchNorm.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">n_filters</span>,</span><span class=\"param\">\t<span class=\"n\">k_size</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">is_batchnorm</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DBatchNorm.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DBatchNorm.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DGroupNorm", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DGroupNorm", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DGroupNorm.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DGroupNorm.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">n_filters</span>,</span><span class=\"param\">\t<span class=\"n\">k_size</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">n_groups</span><span class=\"o\">=</span><span class=\"mi\">16</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DGroupNorm.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DGroupNorm.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.deconv2DBatchNorm", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "deconv2DBatchNorm", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.deconv2DBatchNorm.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "deconv2DBatchNorm.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_channels</span>, </span><span class=\"param\"><span class=\"n\">n_filters</span>, </span><span class=\"param\"><span class=\"n\">k_size</span>, </span><span class=\"param\"><span class=\"n\">stride</span>, </span><span class=\"param\"><span class=\"n\">padding</span>, </span><span class=\"param\"><span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.deconv2DBatchNorm.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "deconv2DBatchNorm.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DBatchNormRelu", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DBatchNormRelu", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DBatchNormRelu.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DBatchNormRelu.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">n_filters</span>,</span><span class=\"param\">\t<span class=\"n\">k_size</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">is_batchnorm</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DBatchNormRelu.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DBatchNormRelu.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DGroupNormRelu", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DGroupNormRelu", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DGroupNormRelu.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DGroupNormRelu.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">n_filters</span>,</span><span class=\"param\">\t<span class=\"n\">k_size</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span>,</span><span class=\"param\">\t<span class=\"n\">padding</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">n_groups</span><span class=\"o\">=</span><span class=\"mi\">16</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.conv2DGroupNormRelu.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "conv2DGroupNormRelu.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.deconv2DBatchNormRelu", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "deconv2DBatchNormRelu", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.deconv2DBatchNormRelu.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "deconv2DBatchNormRelu.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_channels</span>, </span><span class=\"param\"><span class=\"n\">n_filters</span>, </span><span class=\"param\"><span class=\"n\">k_size</span>, </span><span class=\"param\"><span class=\"n\">stride</span>, </span><span class=\"param\"><span class=\"n\">padding</span>, </span><span class=\"param\"><span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.deconv2DBatchNormRelu.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "deconv2DBatchNormRelu.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.unetConv2", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "unetConv2", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.unetConv2.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "unetConv2.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_size</span>, </span><span class=\"param\"><span class=\"n\">out_size</span>, </span><span class=\"param\"><span class=\"n\">is_batchnorm</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.unetConv2.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "unetConv2.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.unetUp", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "unetUp", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.unetUp.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "unetUp.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_size</span>, </span><span class=\"param\"><span class=\"n\">out_size</span>, </span><span class=\"param\"><span class=\"n\">is_deconv</span>, </span><span class=\"param\"><span class=\"n\">is_batchnorm</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.unetUp.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "unetUp.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs1</span>, </span><span class=\"param\"><span class=\"n\">inputs2</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetDown2", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetDown2", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetDown2.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetDown2.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_size</span>, </span><span class=\"param\"><span class=\"n\">out_size</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetDown2.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetDown2.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetDown3", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetDown3", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetDown3.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetDown3.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_size</span>, </span><span class=\"param\"><span class=\"n\">out_size</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetDown3.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetDown3.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetUp2", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetUp2", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetUp2.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetUp2.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_size</span>, </span><span class=\"param\"><span class=\"n\">out_size</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetUp2.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetUp2.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span>, </span><span class=\"param\"><span class=\"n\">indices</span>, </span><span class=\"param\"><span class=\"n\">output_shape</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetUp3", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetUp3", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetUp3.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetUp3.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_size</span>, </span><span class=\"param\"><span class=\"n\">out_size</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.segnetUp3.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "segnetUp3.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">inputs</span>, </span><span class=\"param\"><span class=\"n\">indices</span>, </span><span class=\"param\"><span class=\"n\">output_shape</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBlock", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBlock", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBlock.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBlock.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_channels</span>, </span><span class=\"param\"><span class=\"n\">n_filters</span>, </span><span class=\"param\"><span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">downsample</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBlock.expansion", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBlock.expansion", "type": "variable", "doc": "<p></p>\n", "default_value": " = 1"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBlock.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBlock.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBottleneck", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBottleneck", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBottleneck.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBottleneck.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_channels</span>, </span><span class=\"param\"><span class=\"n\">n_filters</span>, </span><span class=\"param\"><span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">downsample</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBottleneck.expansion", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBottleneck.expansion", "type": "variable", "doc": "<p></p>\n", "default_value": " = 4"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBottleneck.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBottleneck.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.linknetUp", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "linknetUp", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.linknetUp.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "linknetUp.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_channels</span>, </span><span class=\"param\"><span class=\"n\">n_filters</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.linknetUp.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "linknetUp.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.FRRU", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "FRRU", "type": "class", "doc": "<p>Full Resolution Residual Unit for FRRN</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.FRRU.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "FRRU.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">prev_channels</span>, </span><span class=\"param\"><span class=\"n\">out_channels</span>, </span><span class=\"param\"><span class=\"n\">scale</span>, </span><span class=\"param\"><span class=\"n\">group_norm</span><span class=\"o\">=</span><span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">n_groups</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.FRRU.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "FRRU.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">y</span>, </span><span class=\"param\"><span class=\"n\">z</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.RU", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "RU", "type": "class", "doc": "<p>Residual Unit for FRRN</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.RU.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "RU.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">channels</span>, </span><span class=\"param\"><span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span>, </span><span class=\"param\"><span class=\"n\">strides</span><span class=\"o\">=</span><span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">group_norm</span><span class=\"o\">=</span><span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">n_groups</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.RU.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "RU.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.residualConvUnit", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualConvUnit", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.residualConvUnit.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualConvUnit.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">channels</span>, </span><span class=\"param\"><span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.residualConvUnit.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualConvUnit.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.multiResolutionFusion", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "multiResolutionFusion", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.multiResolutionFusion.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "multiResolutionFusion.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">channels</span>, </span><span class=\"param\"><span class=\"n\">up_scale_high</span>, </span><span class=\"param\"><span class=\"n\">up_scale_low</span>, </span><span class=\"param\"><span class=\"n\">high_shape</span>, </span><span class=\"param\"><span class=\"n\">low_shape</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.multiResolutionFusion.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "multiResolutionFusion.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x_high</span>, </span><span class=\"param\"><span class=\"n\">x_low</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.chainedResidualPooling", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "chainedResidualPooling", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.chainedResidualPooling.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "chainedResidualPooling.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">channels</span>, </span><span class=\"param\"><span class=\"n\">input_shape</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.chainedResidualPooling.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "chainedResidualPooling.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.pyramidPooling", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "pyramidPooling", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.pyramidPooling.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "pyramidPooling.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">pool_sizes</span>,</span><span class=\"param\">\t<span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">&#39;pspnet&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">fusion_mode</span><span class=\"o\">=</span><span class=\"s1\">&#39;cat&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">is_batchnorm</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.pyramidPooling.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "pyramidPooling.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.bottleNeckPSP", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "bottleNeckPSP", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.bottleNeckPSP.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "bottleNeckPSP.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">mid_channels</span>,</span><span class=\"param\">\t<span class=\"n\">out_channels</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">is_batchnorm</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.bottleNeckPSP.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "bottleNeckPSP.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.bottleNeckIdentifyPSP", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "bottleNeckIdentifyPSP", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.bottleNeckIdentifyPSP.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "bottleNeckIdentifyPSP.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_channels</span>, </span><span class=\"param\"><span class=\"n\">mid_channels</span>, </span><span class=\"param\"><span class=\"n\">stride</span>, </span><span class=\"param\"><span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">is_batchnorm</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.bottleNeckIdentifyPSP.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "bottleNeckIdentifyPSP.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBlockPSP", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBlockPSP", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBlockPSP.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBlockPSP.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n_blocks</span>,</span><span class=\"param\">\t<span class=\"n\">in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">mid_channels</span>,</span><span class=\"param\">\t<span class=\"n\">out_channels</span>,</span><span class=\"param\">\t<span class=\"n\">stride</span>,</span><span class=\"param\">\t<span class=\"n\">dilation</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">include_range</span><span class=\"o\">=</span><span class=\"s1\">&#39;all&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">is_batchnorm</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.residualBlockPSP.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "residualBlockPSP.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.cascadeFeatureFusion", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "cascadeFeatureFusion", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "impaintingLib.model.layer.model_utils.cascadeFeatureFusion.__init__", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "cascadeFeatureFusion.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n_classes</span>,</span><span class=\"param\">\t<span class=\"n\">low_in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">high_in_channels</span>,</span><span class=\"param\">\t<span class=\"n\">out_channels</span>,</span><span class=\"param\">\t<span class=\"n\">is_batchnorm</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.model_utils.cascadeFeatureFusion.forward", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "cascadeFeatureFusion.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x_low</span>, </span><span class=\"param\"><span class=\"n\">x_high</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.get_interp_size", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "get_interp_size", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"nb\">input</span>, </span><span class=\"param\"><span class=\"n\">s_factor</span><span class=\"o\">=</span><span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">z_factor</span><span class=\"o\">=</span><span class=\"mi\">1</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.interp", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "interp", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"nb\">input</span>, </span><span class=\"param\"><span class=\"n\">output_size</span>, </span><span class=\"param\"><span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">&#39;bilinear&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.model_utils.get_upsampling_weight", "modulename": "impaintingLib.model.layer.model_utils", "qualname": "get_upsampling_weight", "type": "function", "doc": "<p>Make a 2D bilinear kernel suitable for upsampling</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_channels</span>, </span><span class=\"param\"><span class=\"n\">out_channels</span>, </span><span class=\"param\"><span class=\"n\">kernel_size</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.layer.partialConvo", "modulename": "impaintingLib.model.layer.partialConvo", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.model.layer.partialConvo.PartialConv2d", "modulename": "impaintingLib.model.layer.partialConvo", "qualname": "PartialConv2d", "type": "class", "doc": "<p>Applies a 2D convolution over an input signal composed of several input\nplanes.</p>\n\n<p>In the simplest case, the output value of the layer with input size\n\\( (N, C_{\\text{in}}, H, W) \\) and output \\( (N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}}) \\)\ncan be precisely described as:</p>\n\n<p>$$\\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n\\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)$$</p>\n\n<p>where \\( \\star \\) is the valid 2D <a href=\"https://en.wikipedia.org/wiki/Cross-correlation\">cross-correlation</a> operator,\n\\( N \\) is a batch size, \\( C \\) denotes a number of channels,\n\\( H \\) is a height of input planes in pixels, and \\( W \\) is\nwidth in pixels.</p>\n\n<p>This module supports :ref:<code>TensorFloat32&lt;tf32_on_ampere&gt;</code>.</p>\n\n<ul>\n<li><p><code>stride</code> controls the stride for the cross-correlation, a single\nnumber or a tuple.</p></li>\n<li><p><code>padding</code> controls the amount of padding applied to the input. It\ncan be either a string {'valid', 'same'} or a tuple of ints giving the\namount of implicit padding applied on both sides.</p></li>\n<li><p><code>dilation</code> controls the spacing between the kernel points; also\nknown as the \u00e0 trous algorithm. It is harder to describe, but this <a href=\"https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\">link</a>\nhas a nice visualization of what <code>dilation</code> does.</p></li>\n<li><p><code>groups</code> controls the connections between inputs and outputs.\n<code>in_channels</code> and <code>out_channels</code> must both be divisible by\n<code>groups</code>. For example,</p>\n\n<ul>\n<li>At groups=1, all inputs are convolved to all outputs.</li>\n<li>At groups=2, the operation becomes equivalent to having two conv\nlayers side by side, each seeing half the input channels\nand producing half the output channels, and both subsequently\nconcatenated.</li>\n<li>At groups= <code>in_channels</code>, each input channel is convolved with\nits own set of filters (of size\n\\( \\frac{\\text{out_channels}}{\\text{in_channels}} \\)).</li>\n</ul></li>\n</ul>\n\n<p>The parameters <code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> can either be:</p>\n\n<pre><code>- a single ``int`` -- in which case the same value is used for the height and width dimension\n- a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n  and the second `int` for the width dimension\n</code></pre>\n\n<p>Note:\n    When <code>groups == in_channels</code> and <code>out_channels == K * in_channels</code>,\n    where <code>K</code> is a positive integer, this operation is also known as a \"depthwise convolution\".</p>\n\n<pre><code>In other words, for an input of size \\\\( (N, C_{in}, L_{in}) \\\\),\na depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n\\\\( (C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in}) \\\\).\n</code></pre>\n\n<p>Note:\n    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting <code>torch.backends.cudnn.deterministic = True</code>. See :doc:<code>/notes/randomness</code> for more information.</p>\n\n<p>Note:\n    <code>padding='valid'</code> is the same as no padding. <code>padding='same'</code> pads\n    the input so the output has the shape as the input. However, this mode\n    doesn't support any stride values other than 1.</p>\n\n<p>Args:\n    in_channels (int): Number of channels in the input image\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int, tuple or str, optional): Padding added to all four sides of\n        the input. Default: 0\n    padding_mode (string, optional): <code>'zeros'</code>, <code>'reflect'</code>,\n        <code>'replicate'</code> or <code>'circular'</code>. Default: <code>'zeros'</code>\n    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n    groups (int, optional): Number of blocked connections from input\n        channels to output channels. Default: 1\n    bias (bool, optional): If <code>True</code>, adds a learnable bias to the\n        output. Default: <code>True</code></p>\n\n<p>Shape:\n    - Input: \\( (N, C_{in}, H_{in}, W_{in}) \\) or \\( (C_{in}, H_{in}, W_{in}) \\)\n    - Output: \\( (N, C_{out}, H_{out}, W_{out}) \\) or \\( (C_{out}, H_{out}, W_{out}) \\), where</p>\n\n<pre><code>  $$H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n      \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor$$\n\n  $$W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n      \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor$$\n</code></pre>\n\n<p>Attributes:\n    weight (Tensor): the learnable weights of the module of shape\n        \\( (\\text{out_channels}, \\frac{\\text{in_channels}}{\\text{groups}}, \\)\n        \\( \\text{kernel_size[0]}, \\text{kernel_size[1]}) \\).\n        The values of these weights are sampled from\n        \\( \\mathcal{U}(-\\sqrt{k}, \\sqrt{k}) \\) where\n        \\( k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel_size}[i]} \\)\n    bias (Tensor):   the learnable bias of the module of shape\n        (out_channels). If <code>bias</code> is <code>True</code>,\n        then the values of these weights are\n        sampled from \\( \\mathcal{U}(-\\sqrt{k}, \\sqrt{k}) \\) where\n        \\( k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel_size}[i]} \\)</p>\n\n<p>Examples:</p>\n\n<pre><code>&gt;&gt;&gt; # With square kernels and equal stride\n&gt;&gt;&gt; m = nn.Conv2d(16, 33, 3, stride=2)\n&gt;&gt;&gt; # non-square kernels and unequal stride and with padding\n&gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n&gt;&gt;&gt; # non-square kernels and unequal stride and with padding and dilation\n&gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n&gt;&gt;&gt; input = torch.randn(20, 16, 50, 100)\n&gt;&gt;&gt; output = m(input)\n</code></pre>\n", "bases": "torch.nn.modules.conv.Conv2d"}, {"fullname": "impaintingLib.model.layer.partialConvo.PartialConv2d.__init__", "modulename": "impaintingLib.model.layer.partialConvo", "qualname": "PartialConv2d.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "impaintingLib.model.layer.partialConvo.PartialConv2d.forward", "modulename": "impaintingLib.model.layer.partialConvo", "qualname": "PartialConv2d.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"nb\">input</span>, </span><span class=\"param\"><span class=\"n\">mask_in</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.model.pixelShuffle", "modulename": "impaintingLib.model.pixelShuffle", "type": "module", "doc": "<p>Utilisation : </p>\n\n<pre><code>model = SubPixelNetwork(in_channels, upscale_factor)\n</code></pre>\n\n<ul>\n<li><strong>in_channels</strong> : Nombre de channel en entr\u00e9e</li>\n<li><strong>upscale_factor</strong> : Facteur d'augmentation de la taille de l'image</li>\n</ul>\n\n<hr />\n"}, {"fullname": "impaintingLib.model.uNet", "modulename": "impaintingLib.model.uNet", "type": "module", "doc": "<p>Utilisation : </p>\n\n<pre><code>model = UNet(in_channels, out_channels, netType=\"default\", convType=\"conv2d\", doubleLayer=False)\n</code></pre>\n\n<ul>\n<li><strong>in_channels</strong> : Nombre de channel en entr\u00e9e</li>\n<li><strong>out_channels</strong> : Nombre de channel de sortie (en th\u00e9orie 3)</li>\n<li><strong>netType</strong> : \"partial\" pour que les convolutions soient partielles, sinon classique</li>\n<li><strong>convType</strong> : \"conv2d\" pour convolution classique, sinon gated conv</li>\n<li><strong>doubleLayer</strong> : Si <code>True</code> le r\u00e9seau sera plus profond, il apprendra plus lentement mais mieux en th\u00e9orie</li>\n</ul>\n\n<hr />\n"}, {"fullname": "impaintingLib.process", "modulename": "impaintingLib.process", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.process.train_inpainting", "modulename": "impaintingLib.process", "qualname": "train_inpainting", "type": "function", "doc": "<p>Voir le tutoriel pour une explication en d\u00e9tail</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">net</span>,</span><span class=\"param\">\t<span class=\"n\">optimizer</span>,</span><span class=\"param\">\t<span class=\"n\">loader</span>,</span><span class=\"param\">\t<span class=\"n\">alter</span>,</span><span class=\"param\">\t<span class=\"n\">losses</span>,</span><span class=\"param\">\t<span class=\"n\">runName</span><span class=\"o\">=</span><span class=\"s1\">&#39;bigRun&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">scale_factor</span><span class=\"o\">=</span><span class=\"mi\">4</span>,</span><span class=\"param\">\t<span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">simplify_seg</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">show_images</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">summary</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "impaintingLib.utils", "modulename": "impaintingLib.utils", "type": "module", "doc": "<p></p>\n"}, {"fullname": "impaintingLib.utils.plot_img", "modulename": "impaintingLib.utils", "qualname": "plot_img", "type": "function", "doc": "<p>Affiche les images fournies en entr\u00e9e</p>\n\n<ul>\n<li><strong>x</strong> : torch.Size([batch_size, <strong>3</strong>, w, h]) </li>\n<li><strong>title</strong> : Si title n'est pas null l'affiche au dessus de l'image</li>\n<li><strong>return</strong> : <code>None</code></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span>, </span><span class=\"param\"><span class=\"n\">title</span><span class=\"o\">=</span><span class=\"s1\">&#39;&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();